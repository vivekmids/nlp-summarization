{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do: \n",
    "- Decoder layers to incorporate 4 hidden layers\n",
    "- How to incorporate ROUGE metric into accuracy \n",
    "- research: how to save the models and keep them such that their training history + loss can be evaluated? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/envs/tensorflow_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful references: \n",
    "# https://github.com/PacktPublishing/Hands-On-Natural-Language-Processing-with-Python/blob/master/Chapter08/02_example.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. PreProcessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepdata = pd.read_csv('wikihowSep.csv', nrows = 10000)[['headline','text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\nSell yourself first.</td>\n",
       "      <td>Before doing anything else, stop and sum up y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\\nRead the classics before 1600.</td>\n",
       "      <td>Reading the classics is the very first thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\nJoin online artist communities.</td>\n",
       "      <td>Depending on what scale you intend to sell yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nMake yourself public.</td>\n",
       "      <td>Get yourself out there as best as you can by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\nBlog about your artwork.</td>\n",
       "      <td>Given the hundreds of free blogging websites,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            headline  \\\n",
       "0             \\nSell yourself first.   \n",
       "1   \\nRead the classics before 1600.   \n",
       "2  \\nJoin online artist communities.   \n",
       "3            \\nMake yourself public.   \n",
       "4         \\nBlog about your artwork.   \n",
       "\n",
       "                                                text  \n",
       "0   Before doing anything else, stop and sum up y...  \n",
       "1   Reading the classics is the very first thing ...  \n",
       "2   Depending on what scale you intend to sell yo...  \n",
       "3   Get yourself out there as best as you can by ...  \n",
       "4   Given the hundreds of free blogging websites,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata.head()\n",
    "# We only care about 'headline' and 'text' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepdata_v1 = sepdata.dropna(axis=0).reset_index(drop=True) \n",
    "# Get rid of any NA rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9686"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sepdata_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #for regex search purposes          \n",
    "from nltk.corpus import stopwords #stopwords that are provided to us via nltk \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of contractions that we will map to \n",
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes here: \n",
    "# Do not get rid of stopwords \n",
    "# Do not get rid of short words. \n",
    "\n",
    "def text_cleaner(text):\n",
    "    # Step 0: Convert to string in case a float or int is found.\n",
    "    newString = str(text)\n",
    "    # Step 1: Lower case the text \n",
    "    newString = newString.lower()\n",
    "    # Step 2: Get rid of commas\n",
    "    newString = re.sub(r'\\([^)]*\\)', \"\", newString)\n",
    "    # Step 3: Get rid of quotations \n",
    "    #newString = re.sub('\"',\"\", newString)\n",
    "    # Step 4: get rid of contractions with our contraction mapping \n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])  \n",
    "    # Step 5: get rid of the \\n stuff \n",
    "    newString = re.sub(r\"'s\\n\",\"\",newString)\n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    # Step 6: anything that is a number, get rid of it \n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    tokens = newString.split()\n",
    "    remaining = []\n",
    "    for i in tokens: \n",
    "        if len(i)>=1: \n",
    "            remaining.append(i)\n",
    "    # Step 7: Tokenize everything first and keep the words that are not stop words \n",
    "    # Also keep only words that are greater than or equal to 3 characters long \n",
    "    #tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    #long_words=[]\n",
    "    #for i in tokens:\n",
    "    #    if len(i)>=3: #removing short words\n",
    "    #        long_words.append(i)   \n",
    "    return (\" \".join(remaining)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'short stories are an incredible genre all their own and if you really want to be well read then you have to read the short stories of classic masters as well as some contemporary short stories for short stories it is more important to read the works of a particular author than a collection so here is a list of classic short story writers as well as more contemporary writers that you have to check out classic short story masters edgar allan poe anton chekhov ernest hemingway jorge luis borges kafka isaac babel john updike katherine mansfield eudora welty and ray bradbury contemporary short story masters flannery o connor raymond carver donald barthelme tim o brien george saunders jhumpa lahiri junot diaz z z packer joyce carol oates and denis johnson classic short story collections in our time by ernest hemingway a good man is hard to find by flannery o connor what we talk about when we talk about love by raymond carver jesus son by denis johnson interpreter of maladies by jhumpa lahiri'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata_v1['text'][20:25].apply(text_cleaner)[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes here: \n",
    "# keep all words (previously, I got rid of words that were only 1 character long) \n",
    "\n",
    "def headline_cleaner(text):\n",
    "    # Step 0: Convert to string in case a float or int is found.\n",
    "    newString = str(text)\n",
    "    # Step 1: remove quotations \n",
    "    newString = re.sub('\"','', newString)\n",
    "    # Step 2: look up contractions \n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")]) \n",
    "    # Step 3: Get rid of the \\n stuff \n",
    "    newString = re.sub(r\"'s\\n\",\"\",newString)\n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    # Step 4: Get rid of numbers or anything not in the alphabet\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    # Step 5: Lower case \n",
    "    newString = newString.lower()\n",
    "    tokens=newString.split()\n",
    "    # Step 6: keep words that are greater than 1 character long \n",
    "    remaining=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=1:                                 \n",
    "            remaining.append(i) \n",
    "    return (\" \".join(remaining)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read short stories'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata_v1['headline'][20:25].apply(headline_cleaner)[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = sepdata_v1['text'].apply(text_cleaner) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_y = sepdata_v1['headline'].apply(headline_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.concat([cleaned_data, cleaned_y], axis=1)\n",
    "clean_data.columns = ['text','headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>before doing anything else stop and sum up you...</td>\n",
       "      <td>sell yourself first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>reading the classics is the very first thing y...</td>\n",
       "      <td>read the classics before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>depending on what scale you intend to sell you...</td>\n",
       "      <td>join online artist communities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>get yourself out there as best as you can by a...</td>\n",
       "      <td>make yourself public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>given the hundreds of free blogging websites y...</td>\n",
       "      <td>blog about your artwork</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  before doing anything else stop and sum up you...   \n",
       "1  reading the classics is the very first thing y...   \n",
       "2  depending on what scale you intend to sell you...   \n",
       "3  get yourself out there as best as you can by a...   \n",
       "4  given the hundreds of free blogging websites y...   \n",
       "\n",
       "                         headline  \n",
       "0             sell yourself first  \n",
       "1        read the classics before  \n",
       "2  join online artist communities  \n",
       "3            make yourself public  \n",
       "4         blog about your artwork  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Functions to build encoder and decoder embeddings later \n",
    "##### \n",
    "\n",
    "# Building top vocab \n",
    "def count_words(words_dict, text):\n",
    "    for sentence in text:\n",
    "        for word in sentence.split():\n",
    "            if word not in words_dict:\n",
    "                words_dict[word] = 1\n",
    "            else:\n",
    "                words_dict[word] += 1\n",
    "\n",
    "def convert_text_to_ids(text, word2int_dict, eos=False): \n",
    "    # regular text (not summary)\n",
    "    output = []\n",
    "    for item in text:\n",
    "        item2int=[]\n",
    "        for word in item.split(): \n",
    "            if word in word2int_dict: \n",
    "                item2int.append(word2int_dict[word]) \n",
    "            else: \n",
    "                item2int.append(word2int_dict[TOKEN_UNK])\n",
    "#        if eos: \n",
    "#            item2int.append(word2int_dict[TOKEN_EOS])\n",
    "        output.append(item2int)\n",
    "    return output\n",
    "\n",
    "TOKEN_GO = '<GO>'\n",
    "TOKEN_EOS = '<EOS>'\n",
    "TOKEN_PAD = '<PAD>'\n",
    "TOKEN_UNK = '<UNK>'\n",
    "# These are special tokens \n",
    "\n",
    "def summary_convert_text_to_ids(text, word2int_dict): \n",
    "    # summaries only \n",
    "    output = []\n",
    "    for item in text: \n",
    "        item2int = []\n",
    "        for word in item.split(): \n",
    "            if word in word2int_dict: \n",
    "                item2int.append(word2int_dict[word])\n",
    "            else: \n",
    "                item2int.append(word2int_dict[TOKEN_UNK])\n",
    "        output.append([word2int_dict[TOKEN_GO]]+item2int+[word2int_dict[TOKEN_EOS]])\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained embeddings and build word vector matrix \n",
    "\n",
    "def build_word_vector_matrix(vector_file):\n",
    "    embedding_index = {}\n",
    "    f = open(vector_file)\n",
    "    for line in f: \n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype = 'float32') \n",
    "        embedding_index[word] = coefs\n",
    "    f.close() \n",
    "    return embedding_index\n",
    "\n",
    "# Replace the path here to point to the glove.6B.50d.txt vectors file on your system\n",
    "embeddings_index = build_word_vector_matrix('glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(texts, MAX_NB_WORDS, EMBEDDING_DIM): \n",
    "    # -- Build word count dictionary: \n",
    "    word_counts_dict = {}\n",
    "    count_words(word_counts_dict, texts) \n",
    "    print(\"Total words in Vocabulary:\", len(word_counts_dict))\n",
    "    \n",
    "    # -- sort and return top MAX_NB_WORDS \n",
    "    sorted_x = sorted(word_counts_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    sorted_dict_test = collections.OrderedDict(sorted_x)\n",
    "    d = collections.Counter(sorted_dict_test)\n",
    "    word_dict = dict(d.most_common(VOCAB_SIZE))\n",
    "    \n",
    "    # -- Build word to int dictionary \n",
    "    word2int = {} \n",
    "    value = 0\n",
    "    #for word, count in word_dict.items(): \n",
    "    #    if word in embeddings_index: \n",
    "    #        word2int[word] = value\n",
    "    #        value += 1\n",
    "    special_codes = [TOKEN_UNK,TOKEN_PAD,TOKEN_EOS,TOKEN_GO]\n",
    "    for code in special_codes:\n",
    "        word2int[code] = len(word2int)\n",
    "    value = 4 #force it to be 4 to be after our special tokens \n",
    "    for word, count in word_dict.items(): \n",
    "        if word in embeddings_index: \n",
    "            word2int[word] = value\n",
    "            value+=1 \n",
    "        \n",
    "    # -- Build int to word dictionary \n",
    "    int2word = {}\n",
    "    for word, value in word2int.items():\n",
    "        int2word[value] = word\n",
    "    \n",
    "    # -- Build word_emb_matrix \n",
    "    word_emb_matrix = np.zeros((len(word2int), EMBEDDING_DIM), dtype=np.float32) \n",
    "    for word, i in word2int.items():\n",
    "        if word in embeddings_index:\n",
    "            # put in the embedding for the word \n",
    "            word_emb_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            # if word is not found, put in a random embedding \n",
    "            new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "            word_emb_matrix[i] = new_embedding\n",
    "    print(\"Length of word embeddings: \", len(word_emb_matrix))\n",
    "    \n",
    "\n",
    "    # -- Finally, convert doc to the entire sequence \n",
    "    doc_as_ids = convert_text_to_ids(texts, word2int)\n",
    "    return (doc_as_ids, word_emb_matrix, word2int, int2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_text_to_seq(texts, MAX_NB_WORDS, EMBEDDING_DIM): \n",
    "    # -- Build word count dictionary: \n",
    "    word_counts_dict = {}\n",
    "    count_words(word_counts_dict, texts) \n",
    "    print(\"Total words in Vocabulary:\", len(word_counts_dict))\n",
    "    \n",
    "    # -- sort and return top MAX_NB_WORDS \n",
    "    sorted_x = sorted(word_counts_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    sorted_dict_test = collections.OrderedDict(sorted_x)\n",
    "    d = collections.Counter(sorted_dict_test)\n",
    "    word_dict = dict(d.most_common(VOCAB_SIZE))\n",
    "    \n",
    "    # -- Build word to int dictionary \n",
    "    word2int = {} \n",
    "    value = 0\n",
    "    #for word, count in word_dict.items(): \n",
    "    #    if word in embeddings_index: \n",
    "    #        word2int[word] = value\n",
    "    #        value += 1\n",
    "    special_codes = [TOKEN_UNK,TOKEN_PAD,TOKEN_EOS,TOKEN_GO]\n",
    "    for code in special_codes:\n",
    "        word2int[code] = len(word2int)\n",
    "    value = 4 #start with 4 to force it to come after our tokens \n",
    "    for word, count in word_dict.items(): \n",
    "        if word in embeddings_index: \n",
    "            word2int[word] = value\n",
    "            value+=1 \n",
    "        \n",
    "    # -- Build int to word dictionary \n",
    "    int2word = {}\n",
    "    for word, value in word2int.items():\n",
    "        int2word[value] = word\n",
    "    \n",
    "    # -- Build word_emb_matrix \n",
    "    word_emb_matrix = np.zeros((len(word2int), EMBEDDING_DIM), dtype=np.float32) \n",
    "    for word, i in word2int.items():\n",
    "        if word in embeddings_index:\n",
    "            # put in the embedding for the word \n",
    "            word_emb_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            # if word is not found, put in a random embedding \n",
    "            new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "            word_emb_matrix[i] = new_embedding\n",
    "    print(\"Length of word embeddings: \", len(word_emb_matrix))\n",
    "    \n",
    "    # -- Finally, convert doc to the entire sequence \n",
    "    doc_as_ids = summary_convert_text_to_ids(texts, word2int)\n",
    "    return (doc_as_ids, word_emb_matrix, word2int, int2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in Vocabulary: 6744\n",
      "Length of word embeddings:  6586\n",
      "Total words in Vocabulary: 18776\n",
      "Length of word embeddings:  18011\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 40000\n",
    "embedding_dim = 100 \n",
    "\n",
    "y_data, decoder_emb, y_word_index, y_index_word = summary_text_to_seq(clean_data['headline'], VOCAB_SIZE, embedding_dim)\n",
    "X_data, encoder_emb, x_word_index, x_index_word = text_to_seq(clean_data['text'], VOCAB_SIZE, embedding_dim)\n",
    "## make y_index_word \n",
    "## make x_index_word \n",
    "# (essentially reverse dictionary such that we can use this during inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " '<PAD>': 1,\n",
       " '<EOS>': 2,\n",
       " '<GO>': 3,\n",
       " 'the': 4,\n",
       " 'your': 5,\n",
       " 'a': 6,\n",
       " 'to': 7,\n",
       " 'of': 8,\n",
       " 'and': 9,\n",
       " 'you': 10,\n",
       " 'for': 11,\n",
       " 'with': 12,\n",
       " 'in': 13,\n",
       " 'or': 14,\n",
       " 'if': 15,\n",
       " 'that': 16,\n",
       " 'doctor': 17,\n",
       " 'get': 18,\n",
       " 'on': 19,\n",
       " 'is': 20,\n",
       " 'be': 21,\n",
       " 'use': 22,\n",
       " 'take': 23,\n",
       " 'have': 24,\n",
       " 'an': 25,\n",
       " 'are': 26,\n",
       " 'about': 27,\n",
       " 'try': 28,\n",
       " 'it': 29,\n",
       " 'avoid': 30,\n",
       " 'as': 31,\n",
       " 'eat': 32,\n",
       " 'consider': 33,\n",
       " 'know': 34,\n",
       " 'water': 35,\n",
       " 'out': 36,\n",
       " 'make': 37,\n",
       " 'at': 38,\n",
       " 'do': 39,\n",
       " 'ask': 40,\n",
       " 'from': 41,\n",
       " 'can': 42,\n",
       " 'keep': 43,\n",
       " 'up': 44,\n",
       " 'not': 45,\n",
       " 's': 46,\n",
       " 'any': 47,\n",
       " 'understand': 48,\n",
       " 'when': 49,\n",
       " 'yourself': 50,\n",
       " 'exercise': 51,\n",
       " 'pregnancy': 52,\n",
       " 'more': 53,\n",
       " 'find': 54,\n",
       " 'into': 55,\n",
       " 'other': 56,\n",
       " 'look': 57,\n",
       " 'time': 58,\n",
       " 'baby': 59,\n",
       " 'talk': 60,\n",
       " 'symptoms': 61,\n",
       " 'pain': 62,\n",
       " 'foods': 63,\n",
       " 'will': 64,\n",
       " 't': 65,\n",
       " 'drink': 66,\n",
       " 'what': 67,\n",
       " 'day': 68,\n",
       " 'check': 69,\n",
       " 'diet': 70,\n",
       " 'before': 71,\n",
       " 'help': 72,\n",
       " 'how': 73,\n",
       " 'test': 74,\n",
       " 'by': 75,\n",
       " 'see': 76,\n",
       " 'don': 77,\n",
       " 'go': 78,\n",
       " 'body': 79,\n",
       " 'some': 80,\n",
       " 'during': 81,\n",
       " 'after': 82,\n",
       " 'may': 83,\n",
       " 'blood': 84,\n",
       " 'birth': 85,\n",
       " 'medical': 86,\n",
       " 'learn': 87,\n",
       " 'apply': 88,\n",
       " 'choose': 89,\n",
       " 'clean': 90,\n",
       " 'wear': 91,\n",
       " 'stay': 92,\n",
       " 'healthy': 93,\n",
       " 'one': 94,\n",
       " 'determine': 95,\n",
       " 'vitamin': 96,\n",
       " 'all': 97,\n",
       " 'health': 98,\n",
       " 'feel': 99,\n",
       " 'remove': 100,\n",
       " 'plan': 101,\n",
       " 'watch': 102,\n",
       " 'add': 103,\n",
       " 'place': 104,\n",
       " 'possible': 105,\n",
       " 'reduce': 106,\n",
       " 'down': 107,\n",
       " 'attention': 108,\n",
       " 'work': 109,\n",
       " 'aware': 110,\n",
       " 'care': 111,\n",
       " 'weight': 112,\n",
       " 'rest': 113,\n",
       " 'first': 114,\n",
       " 'bowl': 115,\n",
       " 'support': 116,\n",
       " 'food': 117,\n",
       " 'back': 118,\n",
       " 'medication': 119,\n",
       " 'alcohol': 120,\n",
       " 'start': 121,\n",
       " 'risk': 122,\n",
       " 'sleep': 123,\n",
       " 'cut': 124,\n",
       " 'discuss': 125,\n",
       " 'home': 126,\n",
       " 'using': 127,\n",
       " 'supplements': 128,\n",
       " 'maintain': 129,\n",
       " 'medications': 130,\n",
       " 'smoking': 131,\n",
       " 'pay': 132,\n",
       " 'signs': 133,\n",
       " 'pipe': 134,\n",
       " 'prepare': 135,\n",
       " 'give': 136,\n",
       " 'sure': 137,\n",
       " 'right': 138,\n",
       " 'skin': 139,\n",
       " 'taking': 140,\n",
       " 'seek': 141,\n",
       " 'treatment': 142,\n",
       " 'monitor': 143,\n",
       " 'this': 144,\n",
       " 'good': 145,\n",
       " 'stop': 146,\n",
       " 'recognize': 147,\n",
       " 'follow': 148,\n",
       " 'over': 149,\n",
       " 'whether': 150,\n",
       " 'while': 151,\n",
       " 'stress': 152,\n",
       " 'her': 153,\n",
       " 'pregnant': 154,\n",
       " 'oil': 155,\n",
       " 'high': 156,\n",
       " 'side': 157,\n",
       " 'area': 158,\n",
       " 'has': 159,\n",
       " 'need': 160,\n",
       " 'wash': 161,\n",
       " 'treat': 162,\n",
       " 'family': 163,\n",
       " 'through': 164,\n",
       " 'off': 165,\n",
       " 'intake': 166,\n",
       " 'bleeding': 167,\n",
       " 'pressure': 168,\n",
       " 'them': 169,\n",
       " 'hospital': 170,\n",
       " 'each': 171,\n",
       " 'like': 172,\n",
       " 'daily': 173,\n",
       " 'partner': 174,\n",
       " 'therapy': 175,\n",
       " 'warm': 176,\n",
       " 'physical': 177,\n",
       " 'note': 178,\n",
       " 'exercises': 179,\n",
       " 'which': 180,\n",
       " 'want': 181,\n",
       " 'people': 182,\n",
       " 'schedule': 183,\n",
       " 'put': 184,\n",
       " 'notice': 185,\n",
       " 'small': 186,\n",
       " 'every': 187,\n",
       " 'there': 188,\n",
       " 'regularly': 189,\n",
       " 'plenty': 190,\n",
       " 'increase': 191,\n",
       " 'cold': 192,\n",
       " 'c': 193,\n",
       " 'tea': 194,\n",
       " 'track': 195,\n",
       " 'salt': 196,\n",
       " 'practice': 197,\n",
       " 'well': 198,\n",
       " 'around': 199,\n",
       " 'their': 200,\n",
       " 'massage': 201,\n",
       " 'set': 202,\n",
       " 'think': 203,\n",
       " 'who': 204,\n",
       " 'changes': 205,\n",
       " 'identify': 206,\n",
       " 'bring': 207,\n",
       " 'surgery': 208,\n",
       " 'appointment': 209,\n",
       " 'too': 210,\n",
       " 'change': 211,\n",
       " 'hands': 212,\n",
       " 'consult': 213,\n",
       " 'prenatal': 214,\n",
       " 'top': 215,\n",
       " 'least': 216,\n",
       " 'bottle': 217,\n",
       " 'cause': 218,\n",
       " 'let': 219,\n",
       " 'much': 220,\n",
       " 'decide': 221,\n",
       " 'two': 222,\n",
       " 'mouth': 223,\n",
       " 'rinse': 224,\n",
       " 'levels': 225,\n",
       " 'options': 226,\n",
       " 'limit': 227,\n",
       " 'labor': 228,\n",
       " 'create': 229,\n",
       " 'experience': 230,\n",
       " 'they': 231,\n",
       " 'between': 232,\n",
       " 'person': 233,\n",
       " 'hole': 234,\n",
       " 'light': 235,\n",
       " 'than': 236,\n",
       " 'regular': 237,\n",
       " 'lighter': 238,\n",
       " 'most': 239,\n",
       " 'teeth': 240,\n",
       " 'pack': 241,\n",
       " 'own': 242,\n",
       " 'only': 243,\n",
       " 'meals': 244,\n",
       " 'expect': 245,\n",
       " 'dry': 246,\n",
       " 'natural': 247,\n",
       " 'walk': 248,\n",
       " 'fill': 249,\n",
       " 'eating': 250,\n",
       " 'enough': 251,\n",
       " 'comfortable': 252,\n",
       " 'fertility': 253,\n",
       " 'visit': 254,\n",
       " 'necessary': 255,\n",
       " 'getting': 256,\n",
       " 'lower': 257,\n",
       " 'wait': 258,\n",
       " 'read': 259,\n",
       " 'write': 260,\n",
       " 'friends': 261,\n",
       " 'minutes': 262,\n",
       " 'weeks': 263,\n",
       " 'clothing': 264,\n",
       " 'low': 265,\n",
       " 'cycle': 266,\n",
       " 'iron': 267,\n",
       " 'important': 268,\n",
       " 'infection': 269,\n",
       " 'braces': 270,\n",
       " 'manage': 271,\n",
       " 'where': 272,\n",
       " 'so': 273,\n",
       " 'allow': 274,\n",
       " 'purchase': 275,\n",
       " 'smoke': 276,\n",
       " 'tobacco': 277,\n",
       " 'juice': 278,\n",
       " 'routine': 279,\n",
       " 'stretch': 280,\n",
       " 'hydrated': 281,\n",
       " 'bong': 282,\n",
       " 'temperature': 283,\n",
       " 'having': 284,\n",
       " 'breathing': 285,\n",
       " 'should': 286,\n",
       " 'life': 287,\n",
       " 'once': 288,\n",
       " 'products': 289,\n",
       " 'cigar': 290,\n",
       " 'bed': 291,\n",
       " 'no': 292,\n",
       " 'control': 293,\n",
       " 'child': 294,\n",
       " 'band': 295,\n",
       " 'things': 296,\n",
       " 'call': 297,\n",
       " 'include': 298,\n",
       " 'amount': 299,\n",
       " 'move': 300,\n",
       " 'brush': 301,\n",
       " 'different': 302,\n",
       " 'position': 303,\n",
       " 'sex': 304,\n",
       " 'prevent': 305,\n",
       " 'emergency': 306,\n",
       " 'away': 307,\n",
       " 'going': 308,\n",
       " 'activities': 309,\n",
       " 'such': 310,\n",
       " 'but': 311,\n",
       " 'common': 312,\n",
       " 'factors': 313,\n",
       " 'fluids': 314,\n",
       " 'condition': 315,\n",
       " 'ovulation': 316,\n",
       " 'loss': 317,\n",
       " 'until': 318,\n",
       " 'three': 319,\n",
       " 'new': 320,\n",
       " 'morning': 321,\n",
       " 'heart': 322,\n",
       " 'few': 323,\n",
       " 'days': 324,\n",
       " 'tell': 325,\n",
       " 'conditions': 326,\n",
       " 'close': 327,\n",
       " 'buy': 328,\n",
       " 'problems': 329,\n",
       " 'god': 330,\n",
       " 'week': 331,\n",
       " 'someone': 332,\n",
       " 'fish': 333,\n",
       " 'cool': 334,\n",
       " 'consume': 335,\n",
       " 'gather': 336,\n",
       " 'd': 337,\n",
       " 'face': 338,\n",
       " 'rich': 339,\n",
       " 'causes': 340,\n",
       " 'drugs': 341,\n",
       " 'perform': 342,\n",
       " 'non': 343,\n",
       " 'listen': 344,\n",
       " 'research': 345,\n",
       " 'times': 346,\n",
       " 'been': 347,\n",
       " 'feet': 348,\n",
       " 'history': 349,\n",
       " 'ice': 350,\n",
       " 'toilet': 351,\n",
       " 'activity': 352,\n",
       " 'cover': 353,\n",
       " 'contact': 354,\n",
       " 'fruit': 355,\n",
       " 'vaginal': 356,\n",
       " 'midwife': 357,\n",
       " 'delivery': 358,\n",
       " 'potential': 359,\n",
       " 'open': 360,\n",
       " 'positive': 361,\n",
       " 'also': 362,\n",
       " 'slowly': 363,\n",
       " 'mother': 364,\n",
       " 'hot': 365,\n",
       " 'caffeine': 366,\n",
       " 'hair': 367,\n",
       " 'certain': 368,\n",
       " 'risks': 369,\n",
       " 'results': 370,\n",
       " 'develop': 371,\n",
       " 'less': 372,\n",
       " 'children': 373,\n",
       " 'these': 374,\n",
       " 'others': 375,\n",
       " 'way': 376,\n",
       " 'lead': 377,\n",
       " 'trimester': 378,\n",
       " 'lots': 379,\n",
       " 'select': 380,\n",
       " 'vegetables': 381,\n",
       " 'drinking': 382,\n",
       " 'insert': 383,\n",
       " 'foil': 384,\n",
       " 'counter': 385,\n",
       " 'lemon': 386,\n",
       " 'early': 387,\n",
       " 'acid': 388,\n",
       " 'hand': 389,\n",
       " 'end': 390,\n",
       " 'self': 391,\n",
       " 'room': 392,\n",
       " 'relax': 393,\n",
       " 'feelings': 394,\n",
       " 'often': 395,\n",
       " 'antibiotics': 396,\n",
       " 'again': 397,\n",
       " 'treatments': 398,\n",
       " 'quit': 399,\n",
       " 'contractions': 400,\n",
       " 'severe': 401,\n",
       " 'birthing': 402,\n",
       " 'muscles': 403,\n",
       " 'name': 404,\n",
       " 'why': 405,\n",
       " 'music': 406,\n",
       " 'pick': 407,\n",
       " 'chart': 408,\n",
       " 'continue': 409,\n",
       " 'evaluate': 410,\n",
       " 'supplies': 411,\n",
       " 'part': 412,\n",
       " 'emotional': 413,\n",
       " 'immediately': 414,\n",
       " 'might': 415,\n",
       " 'night': 416,\n",
       " 'case': 417,\n",
       " 'could': 418,\n",
       " 'e': 419,\n",
       " 'anti': 420,\n",
       " 'nausea': 421,\n",
       " 'fruits': 422,\n",
       " 'areas': 423,\n",
       " 'benefits': 424,\n",
       " 'active': 425,\n",
       " 'period': 426,\n",
       " 'bottom': 427,\n",
       " 'testing': 428,\n",
       " 'fat': 429,\n",
       " 'stool': 430,\n",
       " 'ultrasound': 431,\n",
       " 'foot': 432,\n",
       " 'professional': 433,\n",
       " 'best': 434,\n",
       " 'screen': 435,\n",
       " 'personal': 436,\n",
       " 'stick': 437,\n",
       " 'questions': 438,\n",
       " 'normal': 439,\n",
       " 'done': 440,\n",
       " 'feeling': 441,\n",
       " 'patient': 442,\n",
       " 'safe': 443,\n",
       " 'friend': 444,\n",
       " 're': 445,\n",
       " 'journal': 446,\n",
       " 'habits': 447,\n",
       " 'level': 448,\n",
       " 'cotton': 449,\n",
       " 'healthcare': 450,\n",
       " 'frequently': 451,\n",
       " 'inside': 452,\n",
       " 'procedure': 453,\n",
       " 'tests': 454,\n",
       " 'ready': 455,\n",
       " 'undergo': 456,\n",
       " 'infections': 457,\n",
       " 'orthodontist': 458,\n",
       " 'goals': 459,\n",
       " 'paper': 460,\n",
       " 'instead': 461,\n",
       " 'mind': 462,\n",
       " 'pen': 463,\n",
       " 'many': 464,\n",
       " 'speak': 465,\n",
       " 'prescription': 466,\n",
       " 'protein': 467,\n",
       " 'training': 468,\n",
       " 'bag': 469,\n",
       " 'run': 470,\n",
       " 'bath': 471,\n",
       " 'whole': 472,\n",
       " 'stem': 473,\n",
       " 'second': 474,\n",
       " 'clinic': 475,\n",
       " 'loose': 476,\n",
       " 'assess': 477,\n",
       " 'group': 478,\n",
       " 'being': 479,\n",
       " 'something': 480,\n",
       " 'prepared': 481,\n",
       " 'begin': 482,\n",
       " 'break': 483,\n",
       " 'sit': 484,\n",
       " 'remember': 485,\n",
       " 'hours': 486,\n",
       " 'herbal': 487,\n",
       " 'air': 488,\n",
       " 'long': 489,\n",
       " 'sun': 490,\n",
       " 'exposure': 491,\n",
       " 'apple': 492,\n",
       " 'oral': 493,\n",
       " 'fluid': 494,\n",
       " 'vitamins': 495,\n",
       " 'disease': 496,\n",
       " 'shirt': 497,\n",
       " 'process': 498,\n",
       " 'would': 499,\n",
       " 'information': 500,\n",
       " 'method': 501,\n",
       " 'hold': 502,\n",
       " 'provide': 503,\n",
       " 'throughout': 504,\n",
       " 'spend': 505,\n",
       " 'environment': 506,\n",
       " 'tested': 507,\n",
       " 'together': 508,\n",
       " 'therapist': 509,\n",
       " 'ball': 510,\n",
       " 'ensure': 511,\n",
       " 'clothes': 512,\n",
       " 'heat': 513,\n",
       " 'pre': 514,\n",
       " 'effects': 515,\n",
       " 'fiber': 516,\n",
       " 'she': 517,\n",
       " 'receive': 518,\n",
       " 'milk': 519,\n",
       " 'provider': 520,\n",
       " 'complications': 521,\n",
       " 'retainer': 522,\n",
       " 'present': 523,\n",
       " 'leave': 524,\n",
       " 'turn': 525,\n",
       " 'does': 526,\n",
       " 'realize': 527,\n",
       " 'thumb': 528,\n",
       " 'protect': 529,\n",
       " 'repeat': 530,\n",
       " 'say': 531,\n",
       " 'another': 532,\n",
       " 'store': 533,\n",
       " 'soak': 534,\n",
       " 'large': 535,\n",
       " 'exam': 536,\n",
       " 'b': 537,\n",
       " 'abdominal': 538,\n",
       " 'legs': 539,\n",
       " 'discharge': 540,\n",
       " 'stroke': 541,\n",
       " 'examine': 542,\n",
       " 'record': 543,\n",
       " 'seat': 544,\n",
       " 'location': 545,\n",
       " 'focus': 546,\n",
       " 'techniques': 547,\n",
       " 'chest': 548,\n",
       " 'needs': 549,\n",
       " 'enjoy': 550,\n",
       " 'essential': 551,\n",
       " 'play': 552,\n",
       " 'several': 553,\n",
       " 'his': 554,\n",
       " 'system': 555,\n",
       " 'him': 556,\n",
       " 'both': 557,\n",
       " 'number': 558,\n",
       " 'touch': 559,\n",
       " 'gain': 560,\n",
       " 'date': 561,\n",
       " 'container': 562,\n",
       " 'oils': 563,\n",
       " 'shower': 564,\n",
       " 'bathroom': 565,\n",
       " 'careful': 566,\n",
       " 'recommended': 567,\n",
       " 'turmeric': 568,\n",
       " 'women': 569,\n",
       " 'cream': 570,\n",
       " 'yoga': 571,\n",
       " 'urine': 572,\n",
       " 'diagnosis': 573,\n",
       " 'hard': 574,\n",
       " 'cigars': 575,\n",
       " 'join': 576,\n",
       " 'list': 577,\n",
       " 'short': 578,\n",
       " 'last': 579,\n",
       " 'same': 580,\n",
       " 'materials': 581,\n",
       " 'strength': 582,\n",
       " 'spot': 583,\n",
       " 'replace': 584,\n",
       " 'appropriate': 585,\n",
       " 'clear': 586,\n",
       " 'dairy': 587,\n",
       " 'poke': 588,\n",
       " 'infected': 589,\n",
       " 'trying': 590,\n",
       " 'maternity': 591,\n",
       " 'developing': 592,\n",
       " 'inch': 593,\n",
       " 'base': 594,\n",
       " 'full': 595,\n",
       " 'bladder': 596,\n",
       " 'deep': 597,\n",
       " 'acupuncture': 598,\n",
       " 'relieve': 599,\n",
       " 'red': 600,\n",
       " 'cancer': 601,\n",
       " 'hernia': 602,\n",
       " 'cord': 603,\n",
       " 'points': 604,\n",
       " 'accept': 605,\n",
       " 'hygiene': 606,\n",
       " 'better': 607,\n",
       " 'result': 608,\n",
       " 'medicine': 609,\n",
       " 'ways': 610,\n",
       " 'tip': 611,\n",
       " 'just': 612,\n",
       " 'triggers': 613,\n",
       " 'additional': 614,\n",
       " 'proper': 615,\n",
       " 'sore': 616,\n",
       " 'plastic': 617,\n",
       " 'folic': 618,\n",
       " 'physician': 619,\n",
       " 'anxiety': 620,\n",
       " 'coffee': 621,\n",
       " 'object': 622,\n",
       " 'sodium': 623,\n",
       " 'woman': 624,\n",
       " 'kidney': 625,\n",
       " 'experiencing': 626,\n",
       " 'heavy': 627,\n",
       " 'pillow': 628,\n",
       " 'miscarriage': 629,\n",
       " 'prescribed': 630,\n",
       " 'mucus': 631,\n",
       " 'cervix': 632,\n",
       " 'ulcerative': 633,\n",
       " 'colitis': 634,\n",
       " 'point': 635,\n",
       " 'dental': 636,\n",
       " 'material': 637,\n",
       " 'specific': 638,\n",
       " 'big': 639,\n",
       " 'fun': 640,\n",
       " 'carefully': 641,\n",
       " 'lifestyle': 642,\n",
       " 'acknowledge': 643,\n",
       " 'emotions': 644,\n",
       " 'negative': 645,\n",
       " 'little': 646,\n",
       " 'then': 647,\n",
       " 'front': 648,\n",
       " 'very': 649,\n",
       " 'neck': 650,\n",
       " 'eye': 651,\n",
       " 'sickness': 652,\n",
       " 'piece': 653,\n",
       " 'still': 654,\n",
       " 'deal': 655,\n",
       " 'strengthen': 656,\n",
       " 'fresh': 657,\n",
       " 'needed': 658,\n",
       " 'fatty': 659,\n",
       " 'abdomen': 660,\n",
       " 'head': 661,\n",
       " 'balanced': 662,\n",
       " 'breath': 663,\n",
       " 'age': 664,\n",
       " 'role': 665,\n",
       " 'section': 666,\n",
       " 'grains': 667,\n",
       " 'tape': 668,\n",
       " 'lift': 669,\n",
       " 'types': 670,\n",
       " 'seconds': 671,\n",
       " 'push': 672,\n",
       " 'chronic': 673,\n",
       " 'upper': 674,\n",
       " 'ms': 675,\n",
       " 'rash': 676,\n",
       " 'properly': 677,\n",
       " 'lot': 678,\n",
       " 'book': 679,\n",
       " 'local': 680,\n",
       " 'finger': 681,\n",
       " 'easy': 682,\n",
       " 'improve': 683,\n",
       " 'methods': 684,\n",
       " 'shape': 685,\n",
       " 'used': 686,\n",
       " 'he': 687,\n",
       " 'factor': 688,\n",
       " 'immune': 689,\n",
       " 'network': 690,\n",
       " 'i': 691,\n",
       " 'form': 692,\n",
       " 'empty': 693,\n",
       " 'solution': 694,\n",
       " 'instructions': 695,\n",
       " 'thoroughly': 696,\n",
       " 'vision': 697,\n",
       " 'toothbrush': 698,\n",
       " 'soap': 699,\n",
       " 'eyes': 700,\n",
       " 'glasses': 701,\n",
       " 'familiarize': 702,\n",
       " 'urinate': 703,\n",
       " 'elevate': 704,\n",
       " 'appointments': 705,\n",
       " 'classes': 706,\n",
       " 'its': 707,\n",
       " 'chances': 708,\n",
       " 'minimize': 709,\n",
       " 'supplement': 710,\n",
       " 'months': 711,\n",
       " 'white': 712,\n",
       " 'holes': 713,\n",
       " 'adequate': 714,\n",
       " 'surgical': 715,\n",
       " 'cervical': 716,\n",
       " 'compress': 717,\n",
       " 'hour': 718,\n",
       " 'ivf': 719,\n",
       " 'childbirth': 720,\n",
       " 'lie': 721,\n",
       " 'affected': 722,\n",
       " 'fever': 723,\n",
       " 'underlying': 724,\n",
       " 'swelling': 725,\n",
       " 'breasts': 726,\n",
       " 'menstrual': 727,\n",
       " 'fatigue': 728,\n",
       " 'periods': 729,\n",
       " 'diarrhea': 730,\n",
       " 'powder': 731,\n",
       " 'sample': 732,\n",
       " 'hookah': 733,\n",
       " 'ear': 734,\n",
       " 'option': 735,\n",
       " 'become': 736,\n",
       " 'travel': 737,\n",
       " 'source': 738,\n",
       " 'soon': 739,\n",
       " 'fingers': 740,\n",
       " 'energy': 741,\n",
       " 'plans': 742,\n",
       " 'type': 743,\n",
       " 'even': 744,\n",
       " 'sign': 745,\n",
       " 'because': 746,\n",
       " 'under': 747,\n",
       " 'figure': 748,\n",
       " 'calm': 749,\n",
       " 'nose': 750,\n",
       " 'screening': 751,\n",
       " 'height': 752,\n",
       " 'drinks': 753,\n",
       " 'stomach': 754,\n",
       " 'scrub': 755,\n",
       " 'per': 756,\n",
       " 'flu': 757,\n",
       " 'soft': 758,\n",
       " 'length': 759,\n",
       " 'bandage': 760,\n",
       " 'virus': 761,\n",
       " 'pull': 762,\n",
       " 'posture': 763,\n",
       " 'obtain': 764,\n",
       " 'six': 765,\n",
       " 'floss': 766,\n",
       " 'tube': 767,\n",
       " 'locate': 768,\n",
       " 'shake': 769,\n",
       " 'metal': 770,\n",
       " 'postpartum': 771,\n",
       " 'calendar': 772,\n",
       " 'ob': 773,\n",
       " 'reach': 774,\n",
       " 'snacks': 775,\n",
       " 'sexual': 776,\n",
       " 'ginger': 777,\n",
       " 'general': 778,\n",
       " 'meal': 779,\n",
       " 'immediate': 780,\n",
       " 'inflammatory': 781,\n",
       " 'waist': 782,\n",
       " 'chemotherapy': 783,\n",
       " 'sitting': 784,\n",
       " 'measure': 785,\n",
       " 'belly': 786,\n",
       " 'count': 787,\n",
       " 'sudden': 788,\n",
       " 'services': 789,\n",
       " 'vaccine': 790,\n",
       " 'staph': 791,\n",
       " 'makes': 792,\n",
       " 'review': 793,\n",
       " 'equipment': 794,\n",
       " 'moderate': 795,\n",
       " 'based': 796,\n",
       " 'come': 797,\n",
       " 'following': 798,\n",
       " 'request': 799,\n",
       " 'rate': 800,\n",
       " 'wrist': 801,\n",
       " 'past': 802,\n",
       " 'multiple': 803,\n",
       " 'pieces': 804,\n",
       " 'balance': 805,\n",
       " 'cook': 806,\n",
       " 'future': 807,\n",
       " 'within': 808,\n",
       " 'longer': 809,\n",
       " 'comes': 810,\n",
       " 'heal': 811,\n",
       " 'fast': 812,\n",
       " 'school': 813,\n",
       " 'gently': 814,\n",
       " 'wet': 815,\n",
       " 'near': 816,\n",
       " 'seal': 817,\n",
       " 'show': 818,\n",
       " 'steam': 819,\n",
       " 'contain': 820,\n",
       " 'cells': 821,\n",
       " 'shoes': 822,\n",
       " 'along': 823,\n",
       " 'thyroid': 824,\n",
       " 'pads': 825,\n",
       " 'cap': 826,\n",
       " 'handle': 827,\n",
       " 'confirm': 828,\n",
       " 'kit': 829,\n",
       " 'available': 830,\n",
       " 'infertility': 831,\n",
       " 'smaller': 832,\n",
       " 'spicy': 833,\n",
       " 'intercourse': 834,\n",
       " 'dermatologist': 835,\n",
       " 'uterine': 836,\n",
       " 'car': 837,\n",
       " 'lose': 838,\n",
       " 'ease': 839,\n",
       " 'arms': 840,\n",
       " 'drug': 841,\n",
       " 'meet': 842,\n",
       " 'inflammation': 843,\n",
       " 'dehydration': 844,\n",
       " 'management': 845,\n",
       " 'center': 846,\n",
       " 'doctors': 847,\n",
       " 'sperm': 848,\n",
       " 'inhale': 849,\n",
       " 'bags': 850,\n",
       " 'humidifier': 851,\n",
       " 'zippo': 852,\n",
       " 'eczema': 853,\n",
       " 'cyst': 854,\n",
       " 'online': 855,\n",
       " 'five': 856,\n",
       " 'step': 857,\n",
       " 'pulse': 858,\n",
       " 'variety': 859,\n",
       " 'breaks': 860,\n",
       " 'now': 861,\n",
       " 'doing': 862,\n",
       " 'order': 863,\n",
       " 'chance': 864,\n",
       " 'trust': 865,\n",
       " 'dish': 866,\n",
       " 'supportive': 867,\n",
       " 'those': 868,\n",
       " 'especially': 869,\n",
       " 'processed': 870,\n",
       " 'consumption': 871,\n",
       " 'wipe': 872,\n",
       " 'twice': 873,\n",
       " 'share': 874,\n",
       " 'pool': 875,\n",
       " 'surfaces': 876,\n",
       " 'roll': 877,\n",
       " 'growth': 878,\n",
       " 'lay': 879,\n",
       " 'opt': 880,\n",
       " 'aromatherapy': 881,\n",
       " 'olive': 882,\n",
       " 'incorporate': 883,\n",
       " 'depression': 884,\n",
       " 'fit': 885,\n",
       " 'beverages': 886,\n",
       " 'green': 887,\n",
       " 'pad': 888,\n",
       " 'aluminum': 889,\n",
       " 'portion': 890,\n",
       " 'nail': 891,\n",
       " 'completely': 892,\n",
       " 'gyn': 893,\n",
       " 'affect': 894,\n",
       " 'causing': 895,\n",
       " 'serious': 896,\n",
       " 'uterus': 897,\n",
       " 'known': 898,\n",
       " 'remedies': 899,\n",
       " 'diagnosed': 900,\n",
       " 'pregnancies': 901,\n",
       " 'pelvic': 902,\n",
       " 'calcium': 903,\n",
       " 'hormone': 904,\n",
       " 'drops': 905,\n",
       " 'doula': 906,\n",
       " 'hcg': 907,\n",
       " 'obstetrician': 908,\n",
       " 'soda': 909,\n",
       " 'mg': 910,\n",
       " 'gender': 911,\n",
       " 'stand': 912,\n",
       " 'offer': 913,\n",
       " 'snack': 914,\n",
       " 'removed': 915,\n",
       " 'cough': 916,\n",
       " 'outside': 917,\n",
       " 'board': 918,\n",
       " 'floor': 919,\n",
       " 'relationship': 920,\n",
       " 'simple': 921,\n",
       " 'free': 922,\n",
       " 'mood': 923,\n",
       " 'made': 924,\n",
       " 'thing': 925,\n",
       " 'etc': 926,\n",
       " 'return': 927,\n",
       " 'kind': 928,\n",
       " 'diagnostic': 929,\n",
       " 'decrease': 930,\n",
       " 'flat': 931,\n",
       " 'cleaning': 932,\n",
       " 'motion': 933,\n",
       " 'issues': 934,\n",
       " 'always': 935,\n",
       " 'cleaner': 936,\n",
       " 'aim': 937,\n",
       " 'workout': 938,\n",
       " 'directly': 939,\n",
       " 'transmitted': 940,\n",
       " 'carry': 941,\n",
       " 'injury': 942,\n",
       " 'compression': 943,\n",
       " 'regimen': 944,\n",
       " 'class': 945,\n",
       " 'smile': 946,\n",
       " 'flavor': 947,\n",
       " 'third': 948,\n",
       " 'size': 949,\n",
       " 'bit': 950,\n",
       " 'rubber': 951,\n",
       " 'cup': 952,\n",
       " 'shoulder': 953,\n",
       " 'basal': 954,\n",
       " 'finish': 955,\n",
       " 'diary': 956,\n",
       " 'heartburn': 957,\n",
       " 'four': 958,\n",
       " 'likely': 959,\n",
       " 'skip': 960,\n",
       " 'wax': 961,\n",
       " 'wall': 962,\n",
       " 'rather': 963,\n",
       " 'complete': 964,\n",
       " 'acupressure': 965,\n",
       " 'pph': 966,\n",
       " 'tight': 967,\n",
       " 'relaxation': 968,\n",
       " 'mom': 969,\n",
       " 'moving': 970,\n",
       " 'leg': 971,\n",
       " 'cesarean': 972,\n",
       " 'leaves': 973,\n",
       " 'standing': 974,\n",
       " 'occur': 975,\n",
       " 'slow': 976,\n",
       " 'nutrients': 977,\n",
       " 'honey': 978,\n",
       " 'meat': 979,\n",
       " 'press': 980,\n",
       " 'eight': 981,\n",
       " 'cast': 982,\n",
       " 'damage': 983,\n",
       " 'gi': 984,\n",
       " 'dentist': 985,\n",
       " 'rub': 986,\n",
       " 'flint': 987,\n",
       " 'love': 988,\n",
       " 'strong': 989,\n",
       " 'workshop': 990,\n",
       " 'arrange': 991,\n",
       " 'flow': 992,\n",
       " 'drill': 993,\n",
       " 'ones': 994,\n",
       " 'cases': 995,\n",
       " 'had': 996,\n",
       " 'without': 997,\n",
       " 'reveal': 998,\n",
       " 'house': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        sell yourself first\n",
       "1                   read the classics before\n",
       "2             join online artist communities\n",
       "3                       make yourself public\n",
       "4                    blog about your artwork\n",
       "                        ...                 \n",
       "9681           have a culture test performed\n",
       "9682                   take oral antibiotics\n",
       "9683                      take hyaluronidase\n",
       "9684        inject the area with antibiotics\n",
       "9685    remove build up in the infected area\n",
       "Name: headline, Length: 9686, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2780, 50, 114, 2],\n",
       " [3, 259, 4, 1801, 71, 2],\n",
       " [3, 576, 855, 2781, 3756, 2],\n",
       " [3, 37, 50, 2187, 2],\n",
       " [3, 3757, 27, 5, 3758, 2]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0:5] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18011, 100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18011"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6586, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6586"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 100 \n",
    "max_summary_length = 30 \n",
    "# https://stackoverflow.com/questions/51089903/preprocessing-for-seq2seq-model\n",
    "# https://stackoverflow.com/questions/50662896/tensorflow-seq2seq-chatbot-always-give-the-same-outputs\n",
    "# also note that keras truncates with 'pre' as the default \n",
    "\n",
    "def pad_text(textids_seq, x_word_index, max_text_length): \n",
    "    padded_text = np.zeros(shape=(len(textids_seq),max_text_length))\n",
    "    for i in range(0, len(textids_seq)): \n",
    "        item = textids_seq[i]\n",
    "        itemlen = len(item) \n",
    "        if itemlen<max_text_length: \n",
    "            # meaning, sequence is shorter than max_text_length \n",
    "            padded_text[i] = item + [x_word_index[TOKEN_PAD]]*(max_text_length-itemlen)\n",
    "        else: \n",
    "            # meaning, sequence is longer than max_text_length \n",
    "            # There are multiple discussions on whether there should be EOS at the end, \n",
    "            # or if to just cut off the full text at the max text length \n",
    "            # If you cut off the full text at max text length, do we consider the default truncating of 'pre'? \n",
    "            padded_text[i] = item[:max_text_length]\n",
    "    return(padded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_padded = pad_text(X_data, x_word_index, max_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_padded[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'before'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_index_word[X_data_padded[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9686, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_summary(summaryids_seq, y_word_index, max_summary_length): \n",
    "    padded_text = np.zeros(shape=(len(summaryids_seq),max_summary_length))\n",
    "    for i in range(0, len(summaryids_seq)):\n",
    "        #print(i)\n",
    "        item = summaryids_seq[i] \n",
    "        itemlen = len(item) \n",
    "        if itemlen<max_summary_length: \n",
    "            padded_text[i] = item + [y_word_index[TOKEN_PAD]]*(max_summary_length - itemlen)\n",
    "        else: \n",
    "            # EOS MUST be at the end \n",
    "            # Truncating happens at the front according to keras (with 'pre' set as default)\n",
    "            padded_text[i] = item[(itemlen - max_summary_length):itemlen]\n",
    "    return(padded_text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_padded = pad_summary(y_data, y_word_index, max_summary_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9686, 30)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.882e+03, 7.000e+00, 4.000e+00, 2.839e+03, 1.400e+01, 1.824e+03,\n",
       "       1.000e+01, 2.400e+01, 1.200e+01, 1.585e+03, 2.000e+01, 2.840e+03,\n",
       "       7.000e+00, 4.000e+00, 2.841e+03, 2.390e+02, 1.820e+02, 2.600e+01,\n",
       "       1.559e+03, 7.000e+00, 7.800e+01, 7.000e+00, 1.440e+02, 2.000e+01,\n",
       "       2.390e+02, 3.910e+02, 2.842e+03, 1.300e+01, 3.883e+03, 2.000e+00])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_padded[232]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_data[232])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to deal with padding \n",
    "\n",
    "# Arbitrary lengths decided by exploratory work...can change this later as we see fit \n",
    "##max_text_length = 100\n",
    "#max_summary_length = 30\n",
    "\n",
    "#def pad_sequences(textids_seq, summaryids_seq, x_word_index, y_word_index, max_text_length, max_summary_length): \n",
    "#    padded_text = []\n",
    "#    for item in textids_seq: \n",
    "#        itemlen = len(item) \n",
    "#        if itemlen<max_text_length: \n",
    "#            # sequence is shorter than max_text_length \n",
    "#            padded_text.append(item + [x_word_index[TOKEN_PAD]]*(max_text_length - itemlen))\n",
    "#        else: \n",
    "#            # sequence is longer than max_text_length \n",
    "#            #sublist = item[:(max_text_length-1)]\n",
    "#            padded_text.append(item[:(max_text_length-1)] + [x_word_index[TOKEN_EOS]])\n",
    "#    padded_summary = []\n",
    "#    for item in summaryids_seq: \n",
    "#        itemlen = len(item)\n",
    "#        if itemlen<max_summary_length: \n",
    "#            # sequence is shorter than max_summary_length \n",
    "#            padded_summary.append(item + [y_word_index[TOKEN_PAD]]*(max_summary_length - itemlen))\n",
    "#        else: \n",
    "#            # sequence is longer than max_summary_length \n",
    "#            # also recall from previous: no EOS tag for summaries \n",
    "#            padded_summary.append(item[:(max_summary_length)])\n",
    "#    return(np.array(padded_text), np.array(padded_summary))\n",
    "\n",
    "#X_data_padded, y_data_padded = pad_sequences(X_data, y_data,x_word_index, y_word_index, max_text_length, max_summary_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_data_padded[0]\n",
    "#print(len(X_data_padded[0])) #!00 long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(X_data_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_word_index[TOKEN_EOS] #note the EOS tag at the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_data_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_data_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_word_index[TOKEN_PAD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_data_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a split for train, CV, test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Eventually here, we need to put in a test set that we do not touch \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_data_padded, y_data_padded, test_size=0.2, \n",
    "                                                    random_state=0, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7748"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to self: Most of these, trying to stay as close to Vivek's model naming so we can compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, Bidirectional, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from attention_keras.layers.attention import AttentionLayer\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "K.clear_session() \n",
    "\n",
    "hidden_units = 200 #Paper mentions 600 hidden units, but we can change this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_embedding_layer = Embedding(len(x_word_index),\n",
    "                            embedding_dim,\n",
    "                            weights=[encoder_emb],\n",
    "                            input_length=max_text_length,\n",
    "                            trainable=False,\n",
    "                            name='EncoderEmbeddingLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_embedding_layer = Embedding(len(y_word_index),\n",
    "                            embedding_dim,\n",
    "                            weights=[decoder_emb],\n",
    "                            input_length=max_summary_length,\n",
    "                            trainable=False,\n",
    "                            name='DecoderEmbeddingLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder \n",
    "\n",
    "# Encoder input \n",
    "# 2D (sequence_length, None), where sequence length is the MAX_LEN unified by padding in preprocessing\n",
    "encoder_inputs = Input(shape=(max_text_length,), name=\"EncoderInput\") \n",
    "enc_emb = enc_embedding_layer(encoder_inputs) \n",
    "\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM1') \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM2') \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM3') \n",
    "encoder_output3, state_h3, state_c3= encoder_lstm3(encoder_output2) \n",
    "\n",
    "#LSTM 4 \n",
    "encoder_lstm4=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM4') \n",
    "encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder \n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name = 'DecoderInput') \n",
    "#dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_embedding_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name='DecLSTM1') \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "# dump in extra LSTM for decoders here \n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(len(y_word_index)+1, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "#decoder_outputs = TimeDistributed(Dense(len(y_word_index)+1, activation='softmax'))(decoder_concat_input) \n",
    "# should be same as above without renaming 'decoder_outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "EncoderInput (InputLayer)       [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncoderEmbeddingLayer (Embeddin (None, 100, 100)     1801100     EncoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM1 (LSTM)                 [(None, 100, 200), ( 240800      EncoderEmbeddingLayer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM2 (LSTM)                 [(None, 100, 200), ( 320800      EncLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM3 (LSTM)                 [(None, 100, 200), ( 320800      EncLSTM2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderEmbeddingLayer (Embeddin (None, None, 100)    658600      DecoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM4 (LSTM)                 [(None, 100, 200), ( 320800      EncLSTM3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecLSTM1 (LSTM)                 [(None, None, 200),  240800      DecoderEmbeddingLayer[0][0]      \n",
      "                                                                 EncLSTM4[0][1]                   \n",
      "                                                                 EncLSTM4[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 200),  80200       EncLSTM4[0][0]                   \n",
      "                                                                 DecLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 400)    0           DecLSTM1[0][0]                   \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 6587)   2641387     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,625,287\n",
      "Trainable params: 4,165,587\n",
      "Non-trainable params: 2,459,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7748 samples, validate on 1938 samples\n",
      "Epoch 1/15\n",
      "7748/7748 [==============================] - 195s 25ms/sample - loss: 5.1735 - val_loss: 2.0530\n",
      "Epoch 2/15\n",
      "7748/7748 [==============================] - 193s 25ms/sample - loss: 1.9261 - val_loss: 1.8367\n",
      "Epoch 3/15\n",
      "7748/7748 [==============================] - 202s 26ms/sample - loss: 1.7686 - val_loss: 1.7586\n",
      "Epoch 4/15\n",
      "7748/7748 [==============================] - 235s 30ms/sample - loss: 1.7056 - val_loss: 1.7170\n",
      "Epoch 5/15\n",
      "7748/7748 [==============================] - 223s 29ms/sample - loss: 1.6638 - val_loss: 1.6886\n",
      "Epoch 6/15\n",
      "7748/7748 [==============================] - 220s 28ms/sample - loss: 1.6361 - val_loss: 1.6713\n",
      "Epoch 7/15\n",
      "7748/7748 [==============================] - 220s 28ms/sample - loss: 1.6171 - val_loss: 1.6586\n",
      "Epoch 8/15\n",
      "7748/7748 [==============================] - 221s 29ms/sample - loss: 1.6021 - val_loss: 1.6496\n",
      "Epoch 9/15\n",
      "7748/7748 [==============================] - 221s 28ms/sample - loss: 1.5884 - val_loss: 1.6403\n",
      "Epoch 10/15\n",
      "7748/7748 [==============================] - 220s 28ms/sample - loss: 1.5744 - val_loss: 1.6310\n",
      "Epoch 11/15\n",
      "7748/7748 [==============================] - 218s 28ms/sample - loss: 1.5616 - val_loss: 1.6219\n",
      "Epoch 12/15\n",
      "7748/7748 [==============================] - 194s 25ms/sample - loss: 1.5495 - val_loss: 1.6138\n",
      "Epoch 13/15\n",
      "7748/7748 [==============================] - 194s 25ms/sample - loss: 1.5370 - val_loss: 1.6051\n",
      "Epoch 14/15\n",
      "7748/7748 [==============================] - 211s 27ms/sample - loss: 1.5237 - val_loss: 1.5963\n",
      "Epoch 15/15\n",
      "7748/7748 [==============================] - 193s 25ms/sample - loss: 1.5106 - val_loss: 1.5885\n"
     ]
    }
   ],
   "source": [
    "#model.fit([X_data_padded[0:2000],y_data_padded[0:2000]], \n",
    "#                  y_data_padded[0:2000],\n",
    "#                  epochs=1,\n",
    "#                  batch_size=100)\n",
    "\n",
    "\n",
    "# history=model.fit([x_tr,y_tr[:,:-1]],\n",
    "# y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,\n",
    "# epochs=50,\n",
    "# callbacks=[es],\n",
    "# batch_size=512, \n",
    "# validation_data=([x_val,y_val[:,:-1]], \n",
    "# y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n",
    "\n",
    "# do a mini sample \n",
    "#x_mini_train = x_train[:5000] \n",
    "#y_mini_train = y_train[:5000]\n",
    "#x_mini_test = x_test[:500] \n",
    "#y_mini_test = y_test[:500]\n",
    "\n",
    "#history=model.fit([x_mini_train,np.hstack((np.zeros((y_mini_train.shape[0],1)), y_mini_train[:, :-1]))], \n",
    "#                  y_mini_train,\n",
    "#                  epochs=2,\n",
    "#                  batch_size=100, \n",
    "#                  validation_data=([x_mini_test,np.hstack((np.zeros((y_mini_test.shape[0],1)), y_mini_test[:, :-1]))], y_mini_test)\n",
    "#                 )\n",
    "\n",
    "history=model.fit([x_train,y_train[:,:-1]], \n",
    "                  y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,\n",
    "                  epochs=15,\n",
    "                  batch_size=512, \n",
    "                  validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))\n",
    "\n",
    "\n",
    "#history=model.fit([x_train,np.hstack((np.zeros((y_train.shape[0],1)), y_train[:, :-1]))], \n",
    "#                  y_train,\n",
    "#                  epochs=1,\n",
    "#                  batch_size=100, \n",
    "#                  validation_data=([x_test,np.hstack((np.zeros((y_test.shape[0],1)), y_test[:, :-1]))], y_test)\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "%matplotlib inline\n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_word_index['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_length,hidden_units))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_embedding_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "#decoder_outputs2=TimeDistributed(Dense(len(y_word_index)+1, activation='softmax'))(decoder_inf_concat)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Edit this such that it deals with EOS \n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the '<GO>' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = y_word_index['<GO>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = y_index_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='<EOS>'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == '<EOS>' or len(decoded_sentence.split()) >= (max_summary_length-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=y_word_index['<GO>']) and i!=y_word_index['<EOS>']):\n",
    "            newString=newString+y_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+x_index_word[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: do not cut your toenails to follow the line of your toes as this can lead to ingrown toenails try not to cut them too short or leave them too long <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: cut your toenails straight across <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: play relaxing music or use scents that soothe the laboring woman so her labor continues to progress many women find that the stress of traveling to the hospital causes the labor to stall or temporarily stop consider spritzing a little perfume or essential oils in the car and turn on soft music these can relax her and help her labor progress it s alright if her labor slows down a little this just means that it may take more time for her labor to pick back up at the hospital some laboring women prefer quiet so ask the woman if \n",
      "Original summary: play soothing music <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: cover it with foil poke holes in the foil light your coals and place the coals on the foil enjoy your homemade hookah <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: fill the fruit bowl with tobacco <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: this can lead to dry skin and irritation affecting your beauty while pregnant <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: avoid long showers and baths or excessive hand washing <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: as previously noted most home births occur without a hitch however complications are always a small possibility during childbirth if you notice any of the following signs proceed to a hospital immediately as these may signify serious pregnancy complications which require the technology and expertise available at a hospital traces of feces appear in your amniotic fluid when your water breaks the umbilical cord drops into your vagina before the baby does you have vaginal bleeding not involved with your bloody show or if your bloody show contains an especially large amount of blood you do not deliver the placenta \n",
      "Original summary: look for signs of complications <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: if you visited a number of different hospitals and birthing centers you should make notes on each one then assess the pros and cons and make a decision that fits the needs of your family for example would your family prioritize location over length of visiting hours in that case you may choose the closest hospital even though they have limited visiting hours alternatively you may really want a private room and choose a hospital solely based on the facilities <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: compare facilities <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: if you cannot quite get the hang of it just from urinating you can also try this trick remember that you are also trying to stop yourself from urinating as well you should be feeling both at the same time <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: practice stopping yourself from having gas <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: the first day of the last menstrual cycle is actually considered the first day of pregnancy marking this date on your calendar will also help you determine the date of conception fertilization is most likely to occur about weeks after your last menstrual cycle you are unlikely to experience symptoms until about to weeks after week <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: keep track of the date of your last menstrual cycle <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: pregnancy is a big step toward more responsibility raising a child requires maturity if you are planning to have the child and the baby s father is not involved think about what child care may look like in the future do you plan to raise your child where will you live who will you live with are the people who you are planning to stay with responsible and willing to participate in child care how do you plan to support your child talk with your relatives about the challenges that they may have faced with child care understand what supports \n",
      "Original summary: consider the responsibilities of child care <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: helping other people is obviously beneficial to those people but it also has many positive impacts on you helping other people can increase your level of happiness make you feel lucky to be who you are provide you with connections to other human beings make you feel needed and helpful reduce the amount of worrying you do and give you a sense of meaning or purpose to your life there is no shortage of charities and non profit organizations that need volunteers to help do just about any job you can think of but helping others doesn t have to \n",
      "Original summary: help others <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: grey discharge may indicate bv the other main symptom is a fishy odor especially after sex or during your period although bv can be sexually transmitted any disruption in the normal bacteria of your vagina can trigger it <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: examine your underwear for gray colored discharge <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: much like icing your jaw eating chilled foods will bring comfort directly to the aching parts of your mouth popular options for cold foods are popsicles ice cream frozen carrots smoothies <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: eat chilled foods <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: you should always eat a balanced diet aim for a variety of foods that will help you get your daily requirements of iron calcium folic acid and protein you can get these nutrients from raisins dark leafy greens legumes broccoli and fortified whole grain breads omega fatty acids are also important if you are vegan you do not have to start eating fish for omega s you can get them from flax seeds and walnuts <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: eat nutritious foods <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: these tend to get overlooked in the rush of packing while the hospital should have a shower or sponge bath available for you you should also bring your own personal products hospital will have basic hygiene items if you forget them but they will add a charge to your bill for these these can include deodorant dental care products feminine care products hair care products chapstick or lip balm makeup <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: don t forget hygiene products <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: if you are prepared to drive the woman to the hospital and there does not seem to be a medical emergency you can certainly do so but if it will take you more than minutes to get to the hospital and something seems to be unusual with the labor you should call an ambulance to call an ambulance give the woman s details address and phone number be calm and clear when giving the information explain the medical emergency and follow any directions that the emergency dispatcher gives you <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: call for an ambulance if it is a medical emergency <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: make an appointment to see your general practitioner or an endocrinologist a specialist who treats hormonal disorders they will ask you about your medical history and run a blood test for dhea levels bring a list of questions with you to get the most out of your appointment your doctor might suggest monitoring your dhea levels using saliva serum or urine tests these tests will also be used to rule out any larger issues with your adrenal glands such as addison disease your doctor will likely tell you that it is important to lower your dhea as high levels can \n",
      "Original summary: talk with your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: your length should be inches wide and your width should be approximately inches for a inch waist band if you want a smaller waist band double the waist band you would like and add inch for example if you want a inch waist band you will want a inch width <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: cut a length of waistband from your extra fabric <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: if you wear dentures you are probably going to need to find another solution for your sleep apnea such as a cpap mask most dental devices will not hold properly when the person is wearing dentures though the mandibular repositioning kind will be particularly difficult <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: skip these devices with dentures <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: tree stumps that haven t been fully removed can collect standing water that may not be readily apparent instead of allowing a stump to slowly decompose continue chopping it until you can till it into the surrounding soil or remove it entirely <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: remove stumps <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: there are certain drugs that are given to mothers to trigger labor that are forms of oxytocin which stimulates contraction of the uterus if these medications are given in high amounts the uterus may contract beyond the normal leading to rupture this leads to vaginal bleeding as the body removes excess blood and begin the healing process <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: check to see if the mother took any medications to induce labor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: it is used as a method to confirm a pregnancy or it is also used as a dating ultrasound for those women who cannot remember when their last menstrual period was and are unsure of how far along their pregnancy is what your doctor will look for during this first trimester ultrasound is a heartbeat as well as the presence of your baby inside the uterus to assess what is called the crown to rump length which is used to date the pregnancy not everyone receives a first trimester ultrasound rather it is reserved for those patients whose doctors have \n",
      "Original summary: know that the first trimester ultrasound is done anywhere between and weeks <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: use a lip scrub to buff away any dead skin on your lips for a diy lip scrub you can either use a damp toothbrush in gentle circular motions or mix together caster sugar and any oil of your choice until you reach your desired consistency once you have scrubbed the lips apply a lip balm to seal in the moisture you can even make your own lip balm right at home <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: exfoliate your lips <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: having braces is awesome not because of the way they look or how they feel but because of the results they will give you when you have braces it shows other people that you care about your appearance and that you are trying to improve it remember that when your treatment is done you will have a straight smile <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: embrace your braces <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: in addition to getting fiber from your foods there are also fiber supplements that you can purchase at your local pharmacy that may help treat your constipation many fiber supplements work by adding soft bulk to your stool so it is easier to go occasionally there are other supplements that will stimulate your gi system as well to speed up the transit time many fiber supplements are sold in powder form that you can sprinkle into beverages to help add in more fiber there are also supplements that are sold as gummy supplements or in capsule form <PAD> <PAD> <PAD> \n",
      "Original summary: add in a fiber supplement <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: results from ingestion of uncooked or inadequately cooked and inadequately prepared fish and other seafood including inadequate cold cure smoke cure or acidic cure when in doubt about the safety of the fish in a restaurant or public or private place do not consume it <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: avoid eating inadequately cooked fish and other seafood <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: if dehydration is a side effect of heat exposure remove excess clothing to cool off you can also use damp towels and spray misters to help cool your body do not use ice water or ice packs these can cause the blood vessels to constrict and can actually increase heat retention use a spray bottle to mist lukewarm water onto the skin the evaporation will help cool your body place damp cloths on areas of your body with thinner skin such as the neck and face wrists collarbone upper arms and armpits and inner thighs <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: cool your body <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: if your body temperature is dropping dramatically you need to get out of the cold if you are outdoors find a warm room or shelter even getting out of the path of the wind can help try taking cover behind a wall or other large object if you cannot get into a building <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: get out of the cold <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: you may be able to get promotions within your organization if there are enough opportunities if there are not enough advancement opportunities and you no longer feel challenged you can look for higher level positions with other companies after spending a few years in an entry level position check the job posting descriptions to determine whether or not you are qualified for a higher level position <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: seek promotions and pay raises <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: many smokers find the left over smoke stale and prefer not to smoke it instead blow lightly through the to force the remaining stem up and out the mouthpiece of the bong do not ever exhale back into the top of a bong as this usually spills the water out the or carb and can wet the bowl ruining any extra smoking material <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: clear any remaining smoke from the water bong before passing it on <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: this is to avoid dehydration constant vertigo can impair your daily life and provoke anxiety you may become careless about food and fluid intake dehydration may concentrate the infected fluid in the inner ear making the condition worse <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: drink plenty of fluids <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: notice the gaps in between your contractions to see if they vary in length braxton hicks contractions will be inconsistent and will ebb and flow while real labor contractions will steadily build for example you may notice that you re having pains every few minutes for half an hour but then the pain stops for an hour alternatively you may realize that the pain is happening at odd intervals such as every minute for a few minutes but then every five minutes for the next half hour <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: check if they re irregular <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: many commercial body washes contain sulfates which can dry out your skin and reduce its elasticity over time choose a cleanser made with natural oils that will hydrate your skin rather than making it lose too much moisture coconut oil can act as a healthy skin cleanser rub it over your skin rinse with warm water and pat your skin dry with a soft towel it may not be necessary to use a cleanser on your skin especially if it is prone to becoming dry wash your skin with lukewarm water and pat it dry <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: don t use harsh chemicals on your skin <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: although at home pregnancy tests rarely give false positives they can give false negatives if it is early in the pregnancy if you feel you are within a week or two of implantation you should test twice take the home pregnancy test first thing in the morning when your urine is concentrated drinking too much fluid before taking a home pregnancy test can result in a false negative a false positive result can occur in cases where hormonal changes with menopause are occurring or if you are receiving hcg injections as part of infertility treatment <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: repeat the test in a week or opt to go to the doctor for a test <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: the bulk of orthodontic brace pain will happen in the first to hours after braces are put on your teeth during the first few days eat very soft foods that don t require much chewing until you are more accustomed to eating with braces foods like soups applesauce and mashed potatoes are good choices <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Original summary: eat soft foods for the first few days <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "Review: talk to god similarly as you would if a physical person were standing in front of you you can talk to god about your daily troubles your thoughts at the moment your hopes and dreams and even tell him the things for which you re thankful you can tell god about casual or hard topics just as you would with a concerned friend let s say for example you were having an ongoing argument with a friend you could say god i m not sure what else to say to charlie we ve been arguing for almost two weeks now \n",
      "Original summary: have a talk with god <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "Predicted summary:  take your doctor <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1900,1935):\n",
    "    print(\"Review:\",seq2text(x_test[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_test[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_test[i].reshape(1,max_text_length)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make sure you drink several glasses of water before you exercise you can also have a water bottle close by so you can take small sips of water while you exercise then have several more glasses of water after you are done exercising to ensure you stay hydrated if you experience any signs of dehydration such as dizziness a racing heart and urine that is dark yellow while working out drink water right away if you aren t into drinking plain water add fresh lemon or lime slices to your water to help you drink more of it you may '"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2text(x_test[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1_14",
   "language": "python",
   "name": "tensorflow_1_14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
