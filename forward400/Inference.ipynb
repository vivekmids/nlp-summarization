{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pickle.load(open( 'history.pkl' , \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pyplot.plot(hist['loss'], label='train') \n",
    "pyplot.plot(hist['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data.\n",
      "Training data loaded. Shape is (1387290, 2)\n",
      "Starting to build the embedding index.\n",
      "Built embeddings index. Found 400000 word vectors.\n",
      "Building text\n",
      "Found 212813 unique tokens.\n",
      "Text built. Lengths of x_data, encoder_emb, x_word_index, x_index_word are [1387290, 212814, 212813, 212813]\n",
      "Building headlines \n",
      "Found 78682 unique tokens.\n",
      "Headlines built. Lengths of y_data, decoder_emb, y_word_index, y_index_word are [1387290, 78683, 78682, 78682]\n",
      "Test Train Dev split done. Length of x_train, y_train,x_dev, y_dev, x_test, y_test are [971103, 971103, 278845, 278845, 137342, 137342]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#cleanfilename = 'cleandatamini.pkl'\n",
    "cleanfilename = 'cleandata.pkl'\n",
    "modelfilename = 'model.json'\n",
    "weightsfilename = 'model.h5'\n",
    "historyfilename = 'history.pkl'\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "print('Loading training data.')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "clean_data = pickle.load( open( cleanfilename , \"rb\" ) )\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "print('Training data loaded. Shape is', clean_data.shape)\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "print('Starting to build the embedding index.')\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('data/glove/glove.6B/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "print('Built embeddings index. Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def doc2seq(texts, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM):\n",
    "    tokenizer = Tokenizer(filters='\"#$%&()*+-/<=>@[\\\\]^_`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    index_word = tokenizer.index_word\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding = 'post')\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return data, embedding_matrix, word_index, index_word\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "print('Building text')\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "MAX_TEXT_LENGTH = 100\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.text\n",
    "\n",
    "x_data, encoder_emb, x_word_index, x_index_word = doc2seq(data, MAX_TEXT_LENGTH, EMBEDDING_DIM)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "print('Text built. Lengths of x_data, encoder_emb, x_word_index, x_index_word are', \n",
    "      list(map(lambda a:len(a), [x_data, encoder_emb, x_word_index, x_index_word ])))\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "print('Building headlines ')\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "MAX_HEADLINE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.headline\n",
    "\n",
    "y_data, decoder_emb, y_word_index, y_index_word = doc2seq(data, MAX_HEADLINE_LENGTH, EMBEDDING_DIM)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "print('Headlines built. Lengths of y_data, decoder_emb, y_word_index, y_index_word are', \n",
    "      list(map(lambda a:len(a), [y_data, decoder_emb, y_word_index, y_index_word])))\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "x_train, x_test_temp, y_train, y_test_temp = train_test_split(x_data, y_data, \n",
    "                                                            test_size=0.3, random_state=0) \n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "x_dev, x_test, y_dev, y_test = train_test_split(x_test_temp, y_test_temp, \n",
    "                                                            test_size=0.33, random_state=0) \n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "print('Test Train Dev split done. Length of x_train, y_train,x_dev, y_dev, x_test, y_test are', \n",
    "     list(map(len, [x_train, y_train,x_dev, y_dev, x_test, y_test])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from attention_keras.layers.attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEXT_LENGTH = 100\n",
    "MAX_HEADLINE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300\n",
    "hidden_units = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    enc_embedding_layer = Embedding(len(x_word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[encoder_emb],\n",
    "                                input_length=MAX_TEXT_LENGTH,\n",
    "                                trainable=False,\n",
    "                                name='EncoderEmbeddingLayer')\n",
    "\n",
    "\n",
    "    dec_embedding_layer = Embedding(len(y_word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[decoder_emb],\n",
    "                                input_length=MAX_HEADLINE_LENGTH,\n",
    "                                trainable=False,\n",
    "                                name='DecoderEmbeddingLayer')\n",
    "\n",
    "\n",
    "    # Encoder \n",
    "\n",
    "    # Encoder input \n",
    "    # 2D (sequence_length, None), where sequence length is the MAX_LEN unified by padding in preprocessing\n",
    "    encoder_inputs = Input(shape=(MAX_TEXT_LENGTH,), name=\"EncoderInput\") \n",
    "    enc_emb = enc_embedding_layer(encoder_inputs) \n",
    "\n",
    "\n",
    "    #LSTM 1 \n",
    "    encoder_lstm1 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM1') \n",
    "    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "    #LSTM 2 \n",
    "    encoder_lstm2 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM2') \n",
    "    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "    #LSTM 3 \n",
    "    encoder_lstm3=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM3') \n",
    "    encoder_output3, state_h3, state_c3= encoder_lstm3(encoder_output2) \n",
    "\n",
    "    #LSTM 4 \n",
    "    encoder_lstm4=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM4') \n",
    "    encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3) \n",
    "\n",
    "    # Decoder \n",
    "\n",
    "    decoder_inputs = Input(shape=(None,), name = 'DecoderInput') \n",
    "    #dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "    dec_emb = dec_embedding_layer(decoder_inputs) \n",
    "\n",
    "    #LSTM using encoder_states as initial state\n",
    "    decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name='DecLSTM1') \n",
    "    decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "    #Attention Layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer') \n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "    # Concat attention output and decoder LSTM output \n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "    #Dense layer\n",
    "    decoder_dense = TimeDistributed(Dense(len(y_word_index)+1, activation='softmax')) \n",
    "    decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "    return Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "EncoderInput (InputLayer)       [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncoderEmbeddingLayer (Embeddin (None, 100, 300)     63844200    EncoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM1 (LSTM)                 [(None, 100, 400), ( 1121600     EncoderEmbeddingLayer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM2 (LSTM)                 [(None, 100, 400), ( 1281600     EncLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM3 (LSTM)                 [(None, 100, 400), ( 1281600     EncLSTM2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderEmbeddingLayer (Embeddin (None, None, 300)    23604900    DecoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM4 (LSTM)                 [(None, 100, 400), ( 1281600     EncLSTM3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecLSTM1 (LSTM)                 [(None, None, 400),  1121600     DecoderEmbeddingLayer[0][0]      \n",
      "                                                                 EncLSTM4[0][1]                   \n",
      "                                                                 EncLSTM4[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 400),  320400      EncLSTM4[0][0]                   \n",
      "                                                                 DecLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 800)    0           DecLSTM1[0][0]                   \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 78683)  63025083    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 156,882,583\n",
      "Trainable params: 69,433,483\n",
      "Non-trainable params: 87,449,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    parallel_model = create_model() \n",
    "    parallel_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "parallel_model.load_weights(\"model_fd_111519_300units_punct.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = parallel_model.input[0]\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = parallel_model.get_layer('EncLSTM4').output)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_hidden_state_input = Input(shape=(MAX_TEXT_LENGTH,hidden_units))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= parallel_model.get_layer('DecoderEmbeddingLayer')(parallel_model.input[1])\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = parallel_model.get_layer('DecLSTM1')(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = parallel_model.get_layer('attention_layer')([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = parallel_model.layers[-1](decoder_inf_concat) #This is the time distributed layer\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[parallel_model.input[1]] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0 ):\n",
    "            newString=newString+y_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+x_index_word[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_beam_search_sentences(input_seq, beam=3):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    top_sentences = {}\n",
    "    \n",
    "    def top_tokens(last_token, out, h, c):\n",
    "        output_tokens, h_new, c_new = decoder_model.predict([[last_token]] + [out, h, c])\n",
    "        top_token_indexes = np.argsort(output_tokens[0, -1, :])[-beam:]\n",
    "        top_probabilities = output_tokens[0,-1, top_token_indexes]\n",
    "        return top_token_indexes, top_probabilities, h_new, c_new\n",
    "        \n",
    "    #first set of tokens when feeding encoder states and 0 as the first token to the decoder.\n",
    "    first_tokens, first_probabilities, h, c = top_tokens(0, e_out, e_h, e_c)\n",
    "    for first_token, first_probability in zip(first_tokens, first_probabilities):\n",
    "        #initialize top sentences, their corresponding probabilities and states\n",
    "        top_sentences[y_index_word.get(first_token, '')] = (first_probability, h, c)\n",
    "    \n",
    "    \n",
    "    #loop to iterate over next tokens\n",
    "    len = 1\n",
    "    while len < MAX_HEADLINE_LENGTH:\n",
    "        candidate_sentences = {}\n",
    "        for sentence, (probability, h, c) in top_sentences.items():\n",
    "            last_word = sentence.split()[-1] #pick the last word in the sentence as next word\n",
    "            if(last_word != '.'):\n",
    "                token = y_word_index.get(last_word, 0) \n",
    "                next_tokens, next_probabilities, h_next, c_next = top_tokens(token, e_out, h, c)\n",
    "                for next_token, next_probability in zip(next_tokens, next_probabilities):\n",
    "                    new_sentence = sentence.strip() + ' ' + y_index_word.get(next_token, '')\n",
    "                    candidate_sentences[new_sentence.strip()] = (probability * next_probability, h_next, c_next)\n",
    "            else:\n",
    "                candidate_sentences[sentence] = (probability, h, c)\n",
    "\n",
    "        #print('Candidate sentences')\n",
    "        #print(candidate_sentences.keys())\n",
    "        \n",
    "        #remove low probability candidates\n",
    "        low_probability_candidates = sorted(candidate_sentences, key=lambda k: candidate_sentences.get(k)[0])[:-beam]\n",
    "        for low_probability_candidate in low_probability_candidates:\n",
    "            candidate_sentences.pop(low_probability_candidate)\n",
    "        \n",
    "        #Now all candidates left have highest probabilities.\n",
    "        top_sentences = candidate_sentences\n",
    "        len = len + 1\n",
    "        #print('Sentences at the bottom of the loop')\n",
    "        #print(top_sentences.keys())\n",
    "        \n",
    "\n",
    "    return top_sentences\n",
    "\n",
    "def decode_sequence(input_seq, beam=3):\n",
    "    top_sentences_obj = get_top_beam_search_sentences(input_seq.reshape(1,-1), beam)\n",
    "    l = [(sen, prob) for sen, (prob, _, _) in top_sentences_obj.items()]\n",
    "    return sorted(l, key = lambda x:-x[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import rouge_n_sentence_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_decode(x): \n",
    "    gen_output = decode_sequence(x.reshape(1,-1)).split()\n",
    "    candidate = [item for item in gen_output if (item!=\".\" and item!=\"\")] \n",
    "    return(candidate)\n",
    "\n",
    "def return_summary(x): \n",
    "    gen_summary = seq2summary(x).split()\n",
    "    reference =  [item for item in gen_summary if (item!=\".\" and item!=\"\")] \n",
    "    return(reference)\n",
    "\n",
    "# Other useful links to keep in mind: \n",
    "# https://stackoverflow.com/questions/38045290/text-summarization-evaluation-bleu-vs-rouge\n",
    "\n",
    "def calc_indiv_rouge(id_text, text_df, headline_df, rouge_n): \n",
    "    # This function will take the following as inputs: \n",
    "    # id_text: the index you are interested in \n",
    "    # gen_text_df: the sequences that hold the full text \n",
    "    # headline_df: the sequences that hold the headline text \n",
    "    \n",
    "    # -- Step 1: generate the decoded sequence from a given sample of text\n",
    "    gen_output = decode_sequence(text_df[id_text].reshape(1,-1))\n",
    "    split_output = gen_output.split(\" \")\n",
    "    candidate = [item for item in split_output if (item!=\".\" and item!=\"\")] #get rid of empty spaces and periods \n",
    "    # -- Step 2: generate the true headline summary from our labelled headline text\n",
    "    gen_ref = seq2summary(headline_df[id_text])\n",
    "    split_ref = gen_ref.split(\" \")\n",
    "    #get rid of empty spaces and periods (there shouldn't be any as we already cleaned the headline, but just in case)\n",
    "    reference = [item for item in split_ref if (item!=\".\" and item!=\"\")] \n",
    "    # -- Step 3: calculate rouge\n",
    "    recall, precision, rouge = rouge_n_sentence_level(candidate, reference, rouge_n)\n",
    "    # rouge is actually an f-score of the recall and precision \n",
    "    return(recall, precision, rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************"
     ]
    }
   ],
   "source": [
    "chunkholder = list(chunks(range(0, 10000), 100))\n",
    "\n",
    "result = []\n",
    "cumulative_list=list(range(100,10100,100))\n",
    "cumulative_avg = []\n",
    "for chunk in chunkholder: \n",
    "#    -- change the function return_decode to whatever function you need (i.e. beam search)\n",
    "   decode_machine_summary = [return_decode(item) for item in x_test[chunk]]\n",
    "#    -- for beamsearch, I used: decode_machine_summary = [beam_decode_sequence(item).split(' ') for item in x_test[chunk]]\n",
    "   decode_ref_summary = [return_summary(item) for item in y_test[chunk]]\n",
    "   testset = pd.concat([pd.Series(decode_machine_summary), pd.Series(decode_ref_summary)], axis=1)\n",
    "   testset.columns = ['gen_summary','ref_summary']\n",
    "   testset['rouge_cols']=testset.apply(lambda x: rouge_n_sentence_level(x['gen_summary'], x['ref_summary'], 1), axis=1)\n",
    "   allrouge = testset['rouge_cols'].apply(pd.Series)\n",
    "   allrouge.columns = ['recall','precision','f1score']\n",
    "   final = pd.concat([testset,allrouge],axis=1) \n",
    "   result.append(final)\n",
    "   print('*', end = '')\n",
    "\n",
    "\n",
    "result_df = pd.concat(result).reset_index(drop=True) #this holds the decoded sequences up to 10,000\n",
    "\n",
    "\n",
    "\n",
    "for i in cumulative_list: \n",
    "#   -- calculate the average from every 100 chunk (i.e. 0 to 100, 0 to 200, 0 to 300, etc)\n",
    "   temp = result_df.loc[0:i,'recall':'f1score'].apply(lambda x: np.nanmean(x), axis=0)\n",
    "   cumulative_avg.append({'recall': temp['recall'],'precision': temp['precision'],'f1score': temp['f1score']})\n",
    "\n",
    "cumulative_avg_df = pd.DataFrame(cumulative_avg) # This holds the cumulative sample averages up to 10,000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.208132</td>\n",
       "      <td>0.259218</td>\n",
       "      <td>0.213810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203636</td>\n",
       "      <td>0.263188</td>\n",
       "      <td>0.211918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.189033</td>\n",
       "      <td>0.248933</td>\n",
       "      <td>0.197744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192547</td>\n",
       "      <td>0.252777</td>\n",
       "      <td>0.201850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.193522</td>\n",
       "      <td>0.246659</td>\n",
       "      <td>0.201689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.187269</td>\n",
       "      <td>0.252648</td>\n",
       "      <td>0.198163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.187499</td>\n",
       "      <td>0.253086</td>\n",
       "      <td>0.198510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.187768</td>\n",
       "      <td>0.253570</td>\n",
       "      <td>0.198776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.187919</td>\n",
       "      <td>0.253856</td>\n",
       "      <td>0.198936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.187950</td>\n",
       "      <td>0.254068</td>\n",
       "      <td>0.199056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recall  precision   f1score\n",
       "0   0.208132   0.259218  0.213810\n",
       "1   0.203636   0.263188  0.211918\n",
       "2   0.189033   0.248933  0.197744\n",
       "3   0.192547   0.252777  0.201850\n",
       "4   0.193522   0.246659  0.201689\n",
       "..       ...        ...       ...\n",
       "95  0.187269   0.252648  0.198163\n",
       "96  0.187499   0.253086  0.198510\n",
       "97  0.187768   0.253570  0.198776\n",
       "98  0.187919   0.253856  0.198936\n",
       "99  0.187950   0.254068  0.199056\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#greedy\n",
    "cumulative_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166538</td>\n",
       "      <td>0.266007</td>\n",
       "      <td>0.186382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.177433</td>\n",
       "      <td>0.283665</td>\n",
       "      <td>0.198705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.174399</td>\n",
       "      <td>0.279130</td>\n",
       "      <td>0.196851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.181962</td>\n",
       "      <td>0.282020</td>\n",
       "      <td>0.202711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.184925</td>\n",
       "      <td>0.280657</td>\n",
       "      <td>0.205810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.172760</td>\n",
       "      <td>0.272836</td>\n",
       "      <td>0.196485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.172981</td>\n",
       "      <td>0.273225</td>\n",
       "      <td>0.196789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.173111</td>\n",
       "      <td>0.273417</td>\n",
       "      <td>0.196891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.173048</td>\n",
       "      <td>0.273487</td>\n",
       "      <td>0.196820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.173054</td>\n",
       "      <td>0.273554</td>\n",
       "      <td>0.196867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recall  precision   f1score\n",
       "0   0.166538   0.266007  0.186382\n",
       "1   0.177433   0.283665  0.198705\n",
       "2   0.174399   0.279130  0.196851\n",
       "3   0.181962   0.282020  0.202711\n",
       "4   0.184925   0.280657  0.205810\n",
       "..       ...        ...       ...\n",
       "95  0.172760   0.272836  0.196485\n",
       "96  0.172981   0.273225  0.196789\n",
       "97  0.173111   0.273417  0.196891\n",
       "98  0.173048   0.273487  0.196820\n",
       "99  0.173054   0.273554  0.196867\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#beam\n",
    "cumulative_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Beam Search-------------------------- 4000\n",
      "put your horse in the saddle .\n",
      "------------Greedy Search------------------------\n",
      "keep your horse in the saddle .\n",
      "------------Ground Truth-------------------------\n",
      "keep your legs handing close to your horse s side , without gripping at the knee . \n",
      "------------Document-----------------------------\n",
      "your legs will hold you in the saddle , and give your horse cues . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4001\n",
      "use a utility knife to cut the thinset into a circular saw .\n",
      "------------Greedy Search------------------------\n",
      "cut the blade into the jamb .\n",
      "------------Ground Truth-------------------------\n",
      "turn on the saw and let the blade do the work cutting the tile . \n",
      "------------Document-----------------------------\n",
      "the cut will be cleaner if you do not force the tile into the blade . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4002\n",
      "wrap the ends of the string around the headband .\n",
      "------------Greedy Search------------------------\n",
      "cut the ends of the string .\n",
      "------------Ground Truth-------------------------\n",
      "spread the frosting over the surface of the rolled yule log . \n",
      "------------Document-----------------------------\n",
      "remember to cover the ends . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4003\n",
      "be loyal .\n",
      "------------Greedy Search------------------------\n",
      "show your personality .\n",
      "------------Ground Truth-------------------------\n",
      "look for inspiration from the greats . \n",
      "------------Document-----------------------------\n",
      "consider hilary swank s oscar acceptance speech for boys do not cry in . swank accepted her award gratefully , doling out thanks to all of her supporters , with the major exception of her husband , whom the cameras famously caught crying tears of joy during swank s speech . as an oddball example , consider joe pesci’s oscar acceptance speech . after taking the podium at the oscars for his work in goodfellas , pesci said simply , it is my privilege . thank you . pesci was both praised and lampooned for his five word speech . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4004\n",
      "add shading .\n",
      "------------Greedy Search------------------------\n",
      "use chalk to trace .\n",
      "------------Ground Truth-------------------------\n",
      "make highlights and deepen shadows . \n",
      "------------Document-----------------------------\n",
      "add texture and light or “shiny” areas with a white pencil . use the white pencil in diagonal strokes to develop the background . add more shadowing under your objects , if desired , with black and or light blue . for example , define the pores of a lemon with bits of white . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4005\n",
      "read the rules .\n",
      "------------Greedy Search------------------------\n",
      "read the english guidelines .\n",
      "------------Ground Truth-------------------------\n",
      "familiarize yourself with best practices . \n",
      "------------Document-----------------------------\n",
      "you must familiarize yourself with and abide by subtitling best practices . you can find a list of best practices at http www . ted . com participate translate guidelines h subtitling . some important ones to be aware of include putting the proper number of lines and characters in each subtitle . making sure the reading speed for each line is not too fast or too slow . compressing the written material while preserving the meaning . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4006\n",
      "look for mismanagement .\n",
      "------------Greedy Search------------------------\n",
      "look for a certificate of authenticity .\n",
      "------------Ground Truth-------------------------\n",
      "use central bank resources . \n",
      "------------Document-----------------------------\n",
      "most countries or customs unions have central banks that provide information on their currency . if you are looking for information about elements such as specific placement of face or back plate numbers or even want to see up close examples of how to review standard authentication features , you can draw upon the resources that central banks or currency issuers provide . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4007\n",
      "be consistent .\n",
      "------------Greedy Search------------------------\n",
      "set realistic expectations .\n",
      "------------Ground Truth-------------------------\n",
      "model good behavior . \n",
      "------------Document-----------------------------\n",
      "needs to observe good behavior to know what it looks like . no matter how old your child is , they will notice how you respond and behave in all kinds of situations . make sure that you are modeling the kinds of behavior that you want your child to display . for example , if you want your child to use good manners , then make sure that you model this behavior for your child . this might be as simple as saying “please” and “thank you , ” or waiting patiently in line at the grocery store . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4008\n",
      "clean the disks .\n",
      "------------Greedy Search------------------------\n",
      "clean up your computer .\n",
      "------------Ground Truth-------------------------\n",
      "keep your disk safe and clean . \n",
      "------------Document-----------------------------\n",
      "day , the massive amounts of files can dramatically slow down your computer to a crawl and lead to the sluggish system performance , spyware attack and serious data loss . use the disk cleanup utility to help you keep the disk space clean and safe , and speed up windows xp easily and quickly . windows xp comes with disk cleanup utility that is built to offer you absolutely helpful service to clean out the system and application localization resources , os temp files , video format files in your hard disk which dramatically slow down your computer . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4009\n",
      "cut a strip of fabric .\n",
      "------------Greedy Search------------------------\n",
      "cut the fabric into a inch .\n",
      "------------Ground Truth-------------------------\n",
      "put the sheer fabric in an embroidery hoop , making sure that the fabric is smooth and pulled tightly . \n",
      "------------Document-----------------------------\n",
      "there should be at least inch . cm of fabric outside of the embroidery hoop . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4010\n",
      "listen to your friend .\n",
      "------------Greedy Search------------------------\n",
      "listen to your friend .\n",
      "------------Ground Truth-------------------------\n",
      "listen to their response . \n",
      "------------Document-----------------------------\n",
      "if you are nervous , you may feel overwhelmed . push through the anxiety and pay attention to their response . try not to color their response with your own emotions . let them speak as long as they need to , and pay attention . active listening shows your friend that you really do care about them . give them the courtesy to speak because you love them , even if their answer is disappointing . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4011\n",
      "be patient .\n",
      "------------Greedy Search------------------------\n",
      "help your child understand their feelings .\n",
      "------------Ground Truth-------------------------\n",
      "support those around you , especially the autistic people who need it . \n",
      "------------Document-----------------------------\n",
      "supporting autistics . reach out , accept them as they are , and show them that you care . autistic advocates may have trouble reading their own emotions . if you noticed that they are becoming over stressed with activism , gently suggest a break to stim or do something fun . look out for the autistic people in your life , at all ages . even if young children are kept away from autism speaks , they may still absorb negative attitudes about autism from the people around them . remind them that you love and value them . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4012\n",
      "cut out the cutter .\n",
      "------------Greedy Search------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut the cutter into the cutter .\n",
      "------------Ground Truth-------------------------\n",
      "locate the leading cutter as your starting point . \n",
      "------------Document-----------------------------\n",
      "shortest cutter on the chain . if all of the cutters seem to be the same length , you may start anywhere . the main concern is that you file each cutter so that the flat edge on top of each cutter is very nearly the same length . that way each will slice away the same amount of wood as they pass through the kerf of your cut . it also may help to mark the first tooth you file with a dab of paint or a permanent marker so you will be sure of where you started . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4013\n",
      "get a pillow .\n",
      "------------Greedy Search------------------------\n",
      "consider the benefits of a pillow .\n",
      "------------Ground Truth-------------------------\n",
      "understand the pillow is not for everyone . \n",
      "------------Document-----------------------------\n",
      "fussy or difficult to nurse when using the pillow . nursing pillows are bulky and can be difficult to take from place to place . some others also report having to lean over the pillows and experiencing back aches because of this . remember , a nursing pillow is designed to provide you added comfort . some women find the pillow to be helpful to them and their babies , but if a breastfeeding pillow causes you discomfort it is not a necessity . old fashioned breastfeeding is fine if you do not feel comfortable with a breastfeeding pillow . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4014\n",
      "pour the mixture into the prepared pan .\n",
      "------------Greedy Search------------------------\n",
      "pour the mixture into the prepared pan .\n",
      "------------Ground Truth-------------------------\n",
      "place your flour tortilla into a bowl . \n",
      "------------Document-----------------------------\n",
      "make sure that the tortilla overlaps the edges of the bowl . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4015\n",
      "bring a camera .\n",
      "------------Greedy Search------------------------\n",
      "bring a video camera .\n",
      "------------Ground Truth-------------------------\n",
      "consider banning the electronic gadgets . \n",
      "------------Document-----------------------------\n",
      "! get wild and leave the electronic gear at home . rediscover conversations , story telling , drawing in the sand soil , and stargazing . none of these activities require complex gear . a cell phone for safety is okay but turn it off . it is out of bounds for games , work emails , and internet access unless you are looking up how to put up your tent . a camera is probably the one exception documenting the beauty of all you see and the happiness and tribulations of your fellow camp companions is definitely worthwhile . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4016\n",
      "keep your hands up .\n",
      "------------Greedy Search------------------------\n",
      "keep your hands up .\n",
      "------------Ground Truth-------------------------\n",
      "crawl fast . \n",
      "------------Document-----------------------------\n",
      "if you are not crawling , then hunch over and put your hands out in front of you . try to hold your fingers as if they were mangled in an accident . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4017\n",
      "double crochet into the next stitch .\n",
      "------------Greedy Search------------------------\n",
      "work the first half of the first half of the first half of the first stitch .\n",
      "------------Ground Truth-------------------------\n",
      "use a half double crochet hdc stitch next . \n",
      "------------Document-----------------------------\n",
      "follow the slipstitch with a half double crochet stitch . the half double crochet stitch is a bit more complex than a slipstitch , but it is easy after you do it a few times . to do an hdc stitch , loop the yarn over the hook , then insert the hook through the next stitch . then , loop the yarn over the hook again and pull through the first loop . then , loop the yarn over again and pull the hook through all three stitches that are on the hook . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4018\n",
      "if you do not want to use your smartphone , you will need to see if you can use it .\n",
      "------------Greedy Search------------------------\n",
      "if you are not looking for a good looking look , you can use the mugger s name , and then tap it .\n",
      "------------Ground Truth-------------------------\n",
      "login to yelp with your existing credentials or create a new account . \n",
      "------------Document-----------------------------\n",
      "note that yelp is not available in some countries . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4019\n",
      "join a support group .\n",
      "------------Greedy Search------------------------\n",
      "join a support group .\n",
      "------------Ground Truth-------------------------\n",
      "become friends with other people who are on the raw food diet . \n",
      "------------Document-----------------------------\n",
      "meet people in your area who are also doing the diet by joining a local support group . if there are no support groups in your area created for people who are doing the raw food diet , consider starting one up ! just having a few people to lean on during your adjustment period can make a tremendous difference in your ability to stay on track . people who share the same goal as you will help you keep to your diet and will also offer an excellent example showing you the benefits of what you are doing . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4020\n",
      "do something you love .\n",
      "------------Greedy Search------------------------\n",
      "make a list of things you love .\n",
      "------------Ground Truth-------------------------\n",
      "take care of yourself . . . first . \n",
      "------------Document-----------------------------\n",
      "add something to your life . . . your existence . you are going to be eliminating something very central to your existence . prepare for that , by adding to your life . find a different hobby other than baking those sweets exercise volunteer \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4021\n",
      "check the results .\n",
      "------------Greedy Search------------------------\n",
      "check the results .\n",
      "------------Ground Truth-------------------------\n",
      "scrutinize the username . \n",
      "------------Document-----------------------------\n",
      "a username with three or more numbers at the end is probably an automated bot . particularly if you see multiple reviews for the same product from reviewers with usernames like this , you will not be able to trust these reviews . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4022\n",
      "create a detailed business plan .\n",
      "------------Greedy Search------------------------\n",
      "create a detailed business plan .\n",
      "------------Ground Truth-------------------------\n",
      "set up your website with plenty of details . \n",
      "------------Document-----------------------------\n",
      "your website should be a detailed advertisement of your business that affords customers the convenience of getting all the required information without having to go through the trouble of making telephone calls or email inquiries . provide detailed information about your van and all the packages you can offer . make sure your website clearly displays the costs , time , and hours of operation of each job as well . add pictures of your van , yourself , and any other employees to help your customers get to know your company . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4023\n",
      "go to the chrome webstore .\n",
      "------------Greedy Search------------------------\n",
      "open the chrome menu .\n",
      "------------Ground Truth-------------------------\n",
      "download the tampermonkey extension . \n",
      "------------Document-----------------------------\n",
      "go to the chrome store and search for tampermonkey . then click on add to chrome . tampermonkey is a popular tool used to customize the way a web page displays or behaves . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play the game .\n",
      "------------Greedy Search------------------------\n",
      "continue adding cards .\n",
      "------------Ground Truth-------------------------\n",
      "set aside pairs . \n",
      "------------Document-----------------------------\n",
      "when you have found two cards that are a match , set that pair aside so that your game board becomes smaller . continue playing until every card has been turned over and you have created matches for each game piece . when you are finished playing , you can simply shuffle your cards and redistribute them to create your game board and play again . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4025\n",
      "cook the pancakes .\n",
      "------------Greedy Search------------------------\n",
      "cook the pancakes .\n",
      "------------Ground Truth-------------------------\n",
      "cook the pancakes . \n",
      "------------Document-----------------------------\n",
      "on a hot griddle , cook the pancakes of your desired size until golden brown on each side . lay each pancake on a plate . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4026\n",
      "check the status of the death .\n",
      "------------Greedy Search------------------------\n",
      "use the death of a spouse s death .\n",
      "------------Ground Truth-------------------------\n",
      "guard against identity theft if your spouse has died . \n",
      "------------Document-----------------------------\n",
      "of the recently deceased on the social security administration’s website in order to prevent welfare fraud . but identity thieves need only to download this excel file from the website . some genealogy websites publish social security numbers and maiden names of the deceased . it can take up to a year to settle the affairs of a person who has died . during this time , bills continue to come in and creditors are notified of the death . identity thieves think a few extra credit card bills in the person’s name are not likely to get noticed . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4027\n",
      "write a cover letter .\n",
      "------------Greedy Search------------------------\n",
      "write a cover letter .\n",
      "------------Ground Truth-------------------------\n",
      "mail a more formal thank you letter . \n",
      "------------Document-----------------------------\n",
      "interest in the position and reiterate how you would be an asset to the company . add information that the interviewer might be interested in , or some useful information that the company could use profitably . this will help the interviewer to remember you , as most people follow up after a job interview with only information about themselves . close the letter with the valediction yours sincerely and proofread it thoroughly for grammar , spelling and punctuation . a poorly worded or misspelled thank you letter can be all it takes to disqualify you as a candidate . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4028\n",
      "draw your pattern .\n",
      "------------Greedy Search------------------------\n",
      "draw the pattern .\n",
      "------------Ground Truth-------------------------\n",
      "finalize the template . \n",
      "------------Document-----------------------------\n",
      "have been accounted for and adjust their sizes or proportions as necessary . whenever you have matching pieces e . g . two shin plates , gauntlets , etc . , choose the nicer version and scrap the other one that way , you can use the nice one as the pattern for the other to keep your armor symmetrical . when you’re happy with your pieces , clean up and smooth out the lines , label both your original sketch and the corresponding pieces making note of any that will be duplicated , and cut all the shapes . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4029\n",
      "be creative .\n",
      "------------Greedy Search------------------------\n",
      "be creative .\n",
      "------------Ground Truth-------------------------\n",
      "analyze lead dancers principles , soloists from corps de ballet members background dancers in a company and students and see what makes them different . \n",
      "------------Document-----------------------------\n",
      "to do things single handedly . there are tons of things you can learn from . don t be afraid to develop your own ideas and opinions about your art form . besides knowing these things , you also have to put it into practice . stay after class to do this if you will . while the other people dance and you are waiting for your turn , instead of talking or drilling , ask yourself what you can do to be better , more beautiful , more artistic . . . whatever . know , then apply . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4030\n",
      "know when to see a doctor .\n",
      "------------Greedy Search------------------------\n",
      "know when to get vaccinated .\n",
      "------------Ground Truth-------------------------\n",
      "watch for side effects . \n",
      "------------Document-----------------------------\n",
      "the chickenpox vaccine include seizures , pneumonia , loss of balance , and severe allergic reactions . people who have received the chickenpox immunization may get a mild form of the virus and can still spread the disease to those who are not protected , but this too is rare . a high fever , behavioral changes , or an allergic reaction hives , swelling of the face or throat , arrhythmia , or dizziness should be reported to your doctor immediately . if the reaction is severe or the person experiences difficulty breathing , call for emergency services . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4031\n",
      "talk to your friends .\n",
      "------------Greedy Search------------------------\n",
      "ask your friends and family for advice .\n",
      "------------Ground Truth-------------------------\n",
      "practice in front of friends and family . \n",
      "------------Document-----------------------------\n",
      "this is important because they can provide you with criticism and things you did good . please be aware that they are not pros . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4032\n",
      "use a heating pad .\n",
      "------------Greedy Search------------------------\n",
      "use a heating pad .\n",
      "------------Ground Truth-------------------------\n",
      "choose a cycle on the autoclave machine . \n",
      "------------Document-----------------------------\n",
      "autoclaves use high temperature steam omitted at a high pressure over a certain period of time to sterilize medical objects . this works by killing the microorganisms through time , heat , steam , and pressure . there are different settings on an autoclave machine that work for different things . since you have bags of instruments , you should use the fast exhaust and dry cycle . this works best for wrapped items like instruments . autoclaving fast exhaust will also sterilize glassware . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4033\n",
      "show your baby funny faces .\n",
      "------------Greedy Search------------------------\n",
      "use your baby s body language .\n",
      "------------Ground Truth-------------------------\n",
      "make your face entertaining . \n",
      "------------Document-----------------------------\n",
      "your baby will be delighted by your funny faces , and may try to imitate you if she can . making funny sounds , sticking out your tongue , or twisting your face into a funny shape will be entertaining for a baby . babies love to be talked to and have their attention focused on you . you are likely your newborn baby’s favorite toy . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4034\n",
      "make eye contact .\n",
      "------------Greedy Search------------------------\n",
      "make eye contact .\n",
      "------------Ground Truth-------------------------\n",
      "gaze into her eyes . \n",
      "------------Document-----------------------------\n",
      "of attraction between two people . if you are trying to win her over , try looking into her eyes with a penetrating gaze . just keep in mind that she may break the gaze if she is not interested . if she is interested , she will most likely give you some encouraging looks and smiles , even if she takes her eyes away from yours now and then . if a long gaze does not seem appropriate yet or you are just too nervous to hold a long gaze , try giving her frequent , quick glances . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if you can pay taxes .\n",
      "------------Greedy Search------------------------\n",
      "check if you can pay taxes .\n",
      "------------Ground Truth-------------------------\n",
      "take care of payroll . \n",
      "------------Document-----------------------------\n",
      "payroll system that accounts for employee hours and pay rates . you must withhold the proper amounts for federal , state and local taxes , and deposit those as required with the taxing authorities . establish a consistent system for payment , whether weekly or bi weekly . for help with federal tax requirements , the irs has put out two publications , the employer’s tax guide , publication , and the employer’s supplemental tax guide , publication a . you can find both publications at the irs publications page , at www . irs . gov forms pubs . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4036\n",
      "go to route .\n",
      "------------Greedy Search------------------------\n",
      "find a cave .\n",
      "------------Ground Truth-------------------------\n",
      "go to the southern part of the route near the dark grass and use surf . \n",
      "------------Document-----------------------------\n",
      "go south and then west until you find a waterfall . use waterfall and go west until you reach a fork . go south , then west until you find a cave . enter it . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4037\n",
      "smile .\n",
      "------------Greedy Search------------------------\n",
      "smile .\n",
      "------------Ground Truth-------------------------\n",
      "remember to smile ! \n",
      "------------Document-----------------------------\n",
      "a smile will help put your audience and you at ease . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4038\n",
      "complete the form .\n",
      "------------Greedy Search------------------------\n",
      "complete the form .\n",
      "------------Ground Truth-------------------------\n",
      "choose the right form to file . \n",
      "------------Document-----------------------------\n",
      "using a form ez , a , or . the form you file will depend on a variety of factors . consider the following form ez . this is the easiest to complete . generally , you can choose this form if you aren’t claiming dependents and your taxable income is less than , . however , you can’t choose ez if you are filing married filing separately . form a . you can use this form if your taxable income is less than , and you don’t itemize deductions . form . all others must use this form . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4039\n",
      "fry the bacon .\n",
      "------------Greedy Search------------------------\n",
      "fry the bacon .\n",
      "------------Ground Truth-------------------------\n",
      "cut the bacon into thin strips , then cook it in a large , heavy bottomed pot over medium heat until it browns . \n",
      "------------Document-----------------------------\n",
      "select , thick slices of bacon , and cut them crosswise into ¼ inch . centimeter wide strips . place the bacon into a large , heavy bottomed pot , then turn the heat up to medium . cook the bacon until it is lightly browned , then set it aside on a stack of paper towels so that it can drain . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4040\n",
      "focus on your goals .\n",
      "------------Greedy Search------------------------\n",
      "focus on the positive outcomes .\n",
      "------------Ground Truth-------------------------\n",
      "accept things for what they are . \n",
      "------------Document-----------------------------\n",
      "instead of stressing yourself about why or how you got into or were on the receiving end of the problem , focus on solving rather than perpetuating the problem . acceptance can help by allowing you to just deal with the fact it has happened and now it is time to move upward and onward . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4041\n",
      "talk to your professors .\n",
      "------------Greedy Search------------------------\n",
      "go to the pokémon center and press x to get the pokémon you want to go .\n",
      "------------Ground Truth-------------------------\n",
      "jump into the wario portrait . \n",
      "------------Document-----------------------------\n",
      "this will take you to a secret area where you can unlock wario . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4042\n",
      "sand the wall .\n",
      "------------Greedy Search------------------------\n",
      "use a drywall sander to remove any baseboards .\n",
      "------------Ground Truth-------------------------\n",
      "perforate the wall . \n",
      "------------Document-----------------------------\n",
      "it is important that you do not score the wall , as this will damage the wall and cause the paper to come off in small strips . specialized tools are available at your local hardware store . look for tools which have spur like wheels on them . these tools will perforate the wall with thousands of little dots , so that the dif can soak in . make sure you do a thorough job of perforating the wall . you will notice that areas with less perforation are harder to remove \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4043\n",
      "keep swinging .\n",
      "------------Greedy Search------------------------\n",
      "keep your momentum .\n",
      "------------Ground Truth-------------------------\n",
      "relax your swing . \n",
      "------------Document-----------------------------\n",
      "this is the best thing you can do to get more power on the ball quickly . you want your arms and knees to be slightly bent and loose , not tensed . work on swinging naturally and smoothly , avoiding jerky movements meant to hit the ball hard . remember , good mechanics and a smooth swing are more important than trying to force as much power on your swing as you can . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4044\n",
      "get a t shirt .\n",
      "------------Greedy Search------------------------\n",
      "get a new shirt .\n",
      "------------Ground Truth-------------------------\n",
      "sell merchandise . \n",
      "------------Document-----------------------------\n",
      "but only do this as you have received a big fanbase . if you got the money already it is fine . try to find manufacturers to make shirts . this is only when you are getting known pretty well . if you would like to , try making a iphone app . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4045\n",
      "end the call .\n",
      "------------Greedy Search------------------------\n",
      "call your phone call .\n",
      "------------Ground Truth-------------------------\n",
      "finish . \n",
      "------------Document-----------------------------\n",
      "the point at which you decide to stop is up to you . there is no need to wait for orgasm or , indeed , to stop just because you have both come . there s no rule as to how quickly you should end the call after finishing . some people prefer ending the call as soon as their breathing has gone back to normal , whereas others prefer to stay on the line and chat . let your partner know how much you enjoyed yourself before you end the call . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4046\n",
      "apply the cream .\n",
      "------------Greedy Search------------------------\n",
      "apply the cream to your skin .\n",
      "------------Ground Truth-------------------------\n",
      "test your skin to see if the cream will cause irritation . \n",
      "------------Document-----------------------------\n",
      "place small dab of the cream on the back or your hand or some other place . leave it on for as long as the box directs you to this will generally be two minutes . wash off the cream . if your skin is very red or irritated , it is probably best if you do not use the cream on your face . if it is only mildly red or there is no reaction , go ahead and use it ! \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4047\n",
      "study for a study guide .\n",
      "------------Greedy Search------------------------\n",
      "study for the place you are studying .\n",
      "------------Ground Truth-------------------------\n",
      "be well prepared . \n",
      "------------Document-----------------------------\n",
      "set up in a suitable place where you can study without being distracted . this helps the retention of information with greater ease and gives you a mind s eye view of where you were when you learned the information , making it easier to recall the information . it really helps to avoid moving around study locations while studying , unless each of those locations is distinct to a subject and remains the same to that subject . for example , math study only on the library room , english study only at your home desk , etc . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4048\n",
      "get your child comfortable .\n",
      "------------Greedy Search------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy your child s clothing .\n",
      "------------Ground Truth-------------------------\n",
      "consider stimming opportunities . \n",
      "------------Document-----------------------------\n",
      "both opportunities built into the clothes , and big pockets where they can put stim toys and comfort objects . here are some ways autistic kids like to stim with clothes long skirts are fun for spinning . strings and zippers present fun fidgeting opportunities . fur is good for petting . chunky bracelets or bracelets with big beads can be twirled and spun in the hands . if your child is putting their clothes in their mouth , get them some chewy necklaces or bracelets from a special needs store . these can be found online as well . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 4049\n",
      "prune the roots .\n",
      "------------Greedy Search------------------------\n",
      "prune the roots .\n",
      "------------Ground Truth-------------------------\n",
      "let the cutting dry out in a lightly shaded location . \n",
      "------------Document-----------------------------\n",
      "direct sunlight , and check on the cut end regularly . the cut should dry out , making the new plant less susceptible to rot . stem cuttings can be planted after one or two days of drying . leaf cuttings undergo a more visible change , growing a callous over the cut surface . this can take anywhere from two to seven days . if a leaf shrivels significantly during this time , you may need to plant it early . this has a lower success rate , but the leaf may die if it dries out completely . \n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range (4000, 4050):\n",
    "    print('------------Beam Search--------------------------', i)\n",
    "    print(decode_sequence(x_test[i].reshape(1,-1), 3))\n",
    "    print('------------Greedy Search------------------------')\n",
    "    print(decode_sequence(x_test[i].reshape(1,-1), 1))\n",
    "    print('------------Ground Truth-------------------------')\n",
    "    print(seq2summary(y_test[i]))\n",
    "    print('------------Document-----------------------------')    \n",
    "    print(seq2text(x_test[i]))\n",
    "    print('=================================================')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
