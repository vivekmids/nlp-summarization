{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pickle.load(open( 'history.pkl' , \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pyplot.plot(hist['loss'], label='train') \n",
    "pyplot.plot(hist['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data.\n",
      "Training data loaded. Shape is (1387290, 2)\n",
      "Starting to build the embedding index.\n",
      "Built embeddings index. Found 400000 word vectors.\n",
      "Building text\n",
      "Found 212813 unique tokens.\n",
      "Text built. Lengths of x_data, encoder_emb, x_word_index, x_index_word are [1387290, 212814, 212813, 212813]\n",
      "Building headlines \n",
      "Found 78682 unique tokens.\n",
      "Headlines built. Lengths of y_data, decoder_emb, y_word_index, y_index_word are [1387290, 78683, 78682, 78682]\n",
      "Test Train Dev split done. Length of x_train, y_train,x_dev, y_dev, x_test, y_test are [971103, 971103, 278845, 278845, 137342, 137342]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#cleanfilename = 'cleandatamini.pkl'\n",
    "cleanfilename = 'cleandata.pkl'\n",
    "modelfilename = 'model.json'\n",
    "weightsfilename = 'model.h5'\n",
    "historyfilename = 'history.pkl'\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "print('Loading training data.')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "clean_data = pickle.load( open( cleanfilename , \"rb\" ) )\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "print('Training data loaded. Shape is', clean_data.shape)\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "print('Starting to build the embedding index.')\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('data/glove/glove.6B/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "print('Built embeddings index. Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def doc2seq(texts, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM):\n",
    "    tokenizer = Tokenizer(filters='\"#$%&()*+-/<=>@[\\\\]^_`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    index_word = tokenizer.index_word\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding = 'post')\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return data, embedding_matrix, word_index, index_word\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "print('Building text')\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "MAX_TEXT_LENGTH = 100\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.text\n",
    "\n",
    "x_data, encoder_emb, x_word_index, x_index_word = doc2seq(data, MAX_TEXT_LENGTH, EMBEDDING_DIM)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "print('Text built. Lengths of x_data, encoder_emb, x_word_index, x_index_word are', \n",
    "      list(map(lambda a:len(a), [x_data, encoder_emb, x_word_index, x_index_word ])))\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "print('Building headlines ')\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "MAX_HEADLINE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.headline\n",
    "\n",
    "y_data, decoder_emb, y_word_index, y_index_word = doc2seq(data, MAX_HEADLINE_LENGTH, EMBEDDING_DIM)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "print('Headlines built. Lengths of y_data, decoder_emb, y_word_index, y_index_word are', \n",
    "      list(map(lambda a:len(a), [y_data, decoder_emb, y_word_index, y_index_word])))\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "x_train, x_test_temp, y_train, y_test_temp = train_test_split(x_data, y_data, \n",
    "                                                            test_size=0.3, random_state=0) \n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "x_dev, x_test, y_dev, y_test = train_test_split(x_test_temp, y_test_temp, \n",
    "                                                            test_size=0.33, random_state=0) \n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "print('Test Train Dev split done. Length of x_train, y_train,x_dev, y_dev, x_test, y_test are', \n",
    "     list(map(len, [x_train, y_train,x_dev, y_dev, x_test, y_test])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from attention_keras.layers.attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEXT_LENGTH = 100\n",
    "MAX_HEADLINE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300\n",
    "hidden_units = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    enc_embedding_layer = Embedding(len(x_word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[encoder_emb],\n",
    "                                input_length=MAX_TEXT_LENGTH,\n",
    "                                trainable=False,\n",
    "                                name='EncoderEmbeddingLayer')\n",
    "\n",
    "\n",
    "    dec_embedding_layer = Embedding(len(y_word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[decoder_emb],\n",
    "                                input_length=MAX_HEADLINE_LENGTH,\n",
    "                                trainable=False,\n",
    "                                name='DecoderEmbeddingLayer')\n",
    "\n",
    "\n",
    "    # Encoder \n",
    "\n",
    "    # Encoder input \n",
    "    # 2D (sequence_length, None), where sequence length is the MAX_LEN unified by padding in preprocessing\n",
    "    encoder_inputs = Input(shape=(MAX_TEXT_LENGTH,), name=\"EncoderInput\") \n",
    "    enc_emb = enc_embedding_layer(encoder_inputs) \n",
    "\n",
    "\n",
    "    #LSTM 1 \n",
    "    encoder_lstm1 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM1') \n",
    "    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "    #LSTM 2 \n",
    "    encoder_lstm2 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM2') \n",
    "    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "    #LSTM 3 \n",
    "    encoder_lstm3=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM3') \n",
    "    encoder_output3, state_h3, state_c3= encoder_lstm3(encoder_output2) \n",
    "\n",
    "    #LSTM 4 \n",
    "    encoder_lstm4=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM4') \n",
    "    encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3) \n",
    "\n",
    "    # Decoder \n",
    "\n",
    "    decoder_inputs = Input(shape=(None,), name = 'DecoderInput') \n",
    "    #dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "    dec_emb = dec_embedding_layer(decoder_inputs) \n",
    "\n",
    "    #LSTM using encoder_states as initial state\n",
    "    decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name='DecLSTM1') \n",
    "    decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "    #Attention Layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer') \n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "    # Concat attention output and decoder LSTM output \n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "    #Dense layer\n",
    "    decoder_dense = TimeDistributed(Dense(len(y_word_index)+1, activation='softmax')) \n",
    "    decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "    return Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "EncoderInput (InputLayer)       [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncoderEmbeddingLayer (Embeddin (None, 100, 300)     63844200    EncoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM1 (LSTM)                 [(None, 100, 600), ( 2162400     EncoderEmbeddingLayer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM2 (LSTM)                 [(None, 100, 600), ( 2882400     EncLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM3 (LSTM)                 [(None, 100, 600), ( 2882400     EncLSTM2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderEmbeddingLayer (Embeddin (None, None, 300)    23604900    DecoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM4 (LSTM)                 [(None, 100, 600), ( 2882400     EncLSTM3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecLSTM1 (LSTM)                 [(None, None, 600),  2162400     DecoderEmbeddingLayer[0][0]      \n",
      "                                                                 EncLSTM4[0][1]                   \n",
      "                                                                 EncLSTM4[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 600),  720600      EncLSTM4[0][0]                   \n",
      "                                                                 DecLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1200)   0           DecLSTM1[0][0]                   \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 78683)  94498283    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 195,639,983\n",
      "Trainable params: 108,190,883\n",
      "Non-trainable params: 87,449,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    parallel_model = create_model() \n",
    "    parallel_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "parallel_model.load_weights(\"model_fd_111519_300units_punct.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = parallel_model.input[0]\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = parallel_model.get_layer('EncLSTM4').output)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_hidden_state_input = Input(shape=(MAX_TEXT_LENGTH,hidden_units))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= parallel_model.get_layer('DecoderEmbeddingLayer')(parallel_model.input[1])\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = parallel_model.get_layer('DecLSTM1')(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = parallel_model.get_layer('attention_layer')([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = parallel_model.layers[-1](decoder_inf_concat) #This is the time distributed layer\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[parallel_model.input[1]] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0 ):\n",
    "            newString=newString+y_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+x_index_word[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_beam_search_sentences(input_seq, beam=3):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    top_sentences = {}\n",
    "    \n",
    "    def top_tokens(last_token, out, h, c):\n",
    "        output_tokens, h_new, c_new = decoder_model.predict([[last_token]] + [out, h, c])\n",
    "        top_token_indexes = np.argsort(output_tokens[0, -1, :])[-beam:]\n",
    "        top_probabilities = output_tokens[0,-1, top_token_indexes]\n",
    "        return top_token_indexes, top_probabilities, h_new, c_new\n",
    "        \n",
    "    #first set of tokens when feeding encoder states and 0 as the first token to the decoder.\n",
    "    first_tokens, first_probabilities, h, c = top_tokens(0, e_out, e_h, e_c)\n",
    "    for first_token, first_probability in zip(first_tokens, first_probabilities):\n",
    "        #initialize top sentences, their corresponding probabilities and states\n",
    "        top_sentences[y_index_word.get(first_token, '')] = (first_probability, h, c)\n",
    "    \n",
    "    \n",
    "    #loop to iterate over next tokens\n",
    "    len = 1\n",
    "    while len < MAX_HEADLINE_LENGTH:\n",
    "        candidate_sentences = {}\n",
    "        for sentence, (probability, h, c) in top_sentences.items():\n",
    "            last_word = sentence.split()[-1] #pick the last word in the sentence as next word\n",
    "            if(last_word != '.'):\n",
    "                token = y_word_index.get(last_word, 0) \n",
    "                next_tokens, next_probabilities, h_next, c_next = top_tokens(token, e_out, h, c)\n",
    "                for next_token, next_probability in zip(next_tokens, next_probabilities):\n",
    "                    new_sentence = sentence.strip() + ' ' + y_index_word.get(next_token, '')\n",
    "                    candidate_sentences[new_sentence.strip()] = (probability * next_probability, h_next, c_next)\n",
    "            else:\n",
    "                candidate_sentences[sentence] = (probability, h, c)\n",
    "\n",
    "        #print('Candidate sentences')\n",
    "        #print(candidate_sentences.keys())\n",
    "        \n",
    "        #remove low probability candidates\n",
    "        low_probability_candidates = sorted(candidate_sentences, key=lambda k: candidate_sentences.get(k)[0])[:-beam]\n",
    "        for low_probability_candidate in low_probability_candidates:\n",
    "            candidate_sentences.pop(low_probability_candidate)\n",
    "        \n",
    "        #Now all candidates left have highest probabilities.\n",
    "        top_sentences = candidate_sentences\n",
    "        len = len + 1\n",
    "        #print('Sentences at the bottom of the loop')\n",
    "        #print(top_sentences.keys())\n",
    "        \n",
    "\n",
    "    return top_sentences\n",
    "\n",
    "def decode_sequence(input_seq, beam=3):\n",
    "    top_sentences_obj = get_top_beam_search_sentences(input_seq.reshape(1,-1), beam)\n",
    "    l = [(sen, prob) for sen, (prob, _, _) in top_sentences_obj.items()]\n",
    "    return sorted(l, key = lambda x:-x[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat probiotics .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(x_test[3456])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "##### helpful functions to help with formatting when printing: \n",
    "############\n",
    "def printmd(string):\n",
    "    display(Markdown(string)) #just a pretty print \n",
    "\n",
    "############\n",
    "##### function for BLEU \n",
    "#############\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "# reference: https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "\n",
    "def calc_indiv_BLEU(id_text, text_df, headline_df): \n",
    "    # This function will take the following as inputs: \n",
    "    # id_text: the index you are interested in \n",
    "    # gen_text_df: the sequences that hold the full text \n",
    "    # headline_df: the sequences that hold the headline text \n",
    "    \n",
    "    # -- Step 1: generate the decoded sequence from a given sample of text\n",
    "    gen_output = decode_sequence(text_df[id_text].reshape(1,-1))\n",
    "    split_output = gen_output.split(\" \")\n",
    "    candidate = [item for item in split_output if (item!=\".\" and item!=\"\")] #get rid of empty spaces and periods \n",
    "    # -- Step 2: generate the true headline summary from our labelled headline text\n",
    "    gen_ref = seq2summary(headline_df[id_text])\n",
    "    split_ref = gen_ref.split(\" \")\n",
    "    #get rid of empty spaces and periods (there shouldn't be any as we already cleaned the headline, but just in case)\n",
    "    reference = [item for item in split_ref if (item!=\".\" and item!=\"\")] \n",
    "    # -- Step 3: calculate BLEU \n",
    "    score = sentence_bleu(gen_ref, gen_output, weights=(1, 0, 0, 0))\n",
    "    # we can alternate weights for cumulative scores afterwards \n",
    "    # For now, BLEU is based on unigram counts \n",
    "    return(score)\n",
    "\n",
    "###############\n",
    "##### function for rouge \n",
    "############### \n",
    "# PULL METRICS.PY FILE!! \n",
    "from metrics import rouge_n_sentence_level\n",
    "# metrics.py is taken from https://github.com/neural-dialogue-metrics/rouge\n",
    "\n",
    "# Other useful links to keep in mind: \n",
    "# https://stackoverflow.com/questions/38045290/text-summarization-evaluation-bleu-vs-rouge\n",
    "\n",
    "def calc_indiv_rouge(id_text, text_df, headline_df, rouge_n): \n",
    "    # This function will take the following as inputs: \n",
    "    # id_text: the index you are interested in \n",
    "    # gen_text_df: the sequences that hold the full text \n",
    "    # headline_df: the sequences that hold the headline text \n",
    "    \n",
    "    # -- Step 1: generate the decoded sequence from a given sample of text\n",
    "    gen_output = decode_sequence(text_df[id_text].reshape(1,-1))\n",
    "    split_output = gen_output.split(\" \")\n",
    "    candidate = [item for item in split_output if (item!=\".\" and item!=\"\")] #get rid of empty spaces and periods \n",
    "    # -- Step 2: generate the true headline summary from our labelled headline text\n",
    "    gen_ref = seq2summary(headline_df[id_text])\n",
    "    split_ref = gen_ref.split(\" \")\n",
    "    #get rid of empty spaces and periods (there shouldn't be any as we already cleaned the headline, but just in case)\n",
    "    reference = [item for item in split_ref if (item!=\".\" and item!=\"\")] \n",
    "    # -- Step 3: calculate rouge\n",
    "    recall, precision, rouge = rouge_n_sentence_level(candidate, reference, rouge_n)\n",
    "    # rouge is actually an f-score of the recall and precision \n",
    "    return(recall, precision, rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Evaluation print-out example \n",
    "############# \n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,15):\n",
    "    printmd(\"**Generated summary:**\"+decode_sequence(x_train[i].reshape(1,-1)))\n",
    "    printmd(\"**Original summary:**\"+seq2summary(y_train[i]))\n",
    "    printmd(\"**Text:**\"+seq2text(x_train[i]))\n",
    "    printmd(\"**BLEU score(Unigram):** \"+str(calc_indiv_BLEU(i, x_train, y_train)))\n",
    "    rouge_n = 1 #this can be edited pending how we decide to evaluate ROUGE \n",
    "    printmd(\"**ROUGE-**\"+str(rouge_n)+\"**-Recall:** \"+str(calc_indiv_rouge(i,x_train,y_train,rouge_n)[0]))\n",
    "    printmd(\"**ROUGE-**\"+str(rouge_n)+\"**-Precision:** \"+str(calc_indiv_rouge(i,x_train,y_train,rouge_n)[1]))\n",
    "    printmd(\"**ROUGE-**\"+str(rouge_n)+\"**-Fscore:** \"+str(calc_indiv_rouge(i,x_train,y_train,rouge_n)[2]))\n",
    "    print('_________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_total= 0\n",
    "for i in range(len(x_train[:10])):\n",
    "    bleu_total += calc_indiv_BLEU(i, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLEU = bleu_total/len(x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1393015078330715\n"
     ]
    }
   ],
   "source": [
    "print(BLEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_recall_total, rouge_precision_total, rouge_f_total= 0,0,0\n",
    "for i in range(len(x_test[:20])):\n",
    "    rouge_recall, rouge_precision, rouge_f = calc_indiv_rouge(i, x_test, y_test,1)\n",
    "    rouge_recall_total += rouge_recall\n",
    "    rouge_precision_total += rouge_precision\n",
    "    rouge_f_total += rouge_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17671987734487735"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_recall_total/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23347222222222222"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_precision_total/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18876909038673745"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_f_total/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = decode_sequence_beam(x_test[199].reshape(1,-1), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(sen, prob) for sen, (prob, _, _) in res.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('choose the ingredients that you need for the recipe .', 0.29022956),\n",
       " ('choose the ingredients you need for the recipe .', 0.012860966),\n",
       " ('choose the ingredients that you need .', 0.012043308),\n",
       " ('choose the ingredients that you need for your recipe .', 0.011410826),\n",
       " ('choose the ingredients that need for the recipe .', 0.007939939),\n",
       " ('choose the recipe that you need for the recipe .', 0.0067652366),\n",
       " ('choose your ingredients that you need for the recipe .', 0.0055452096),\n",
       " ('choose the salmon that you need for the recipe .', 0.005466914),\n",
       " ('choose the cheese that you need for the recipe .', 0.005388176),\n",
       " ('choose your ingredients .', 0.0037132106),\n",
       " ('choose the utensil that you need for the recipe .', 0.003289203),\n",
       " ('choose the tomato that you need for the recipe .', 0.0030044427),\n",
       " ('choose the ingredients that you need for the recipe to be .', 0.0028947894),\n",
       " ('choose the ingredients that you need for the recipe to .', 0.0026848372),\n",
       " ('choose the correct ingredients that you need for the recipe .',\n",
       "  0.002670382)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l, key = lambda x:-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' choose the ingredients that you need for the recipe . . . . . . . . . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(x_test[199].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'choose the ingredients that you need for the recipe . '"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2summary(y_test[199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'press the a button again and start to make the dish . '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2text(x_test[199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Beam Search-------------------------- 3456\n",
      "eat probiotics .\n",
      "------------Greedy Search------------------------\n",
      "eat probiotics .\n",
      "------------Ground Truth-------------------------\n",
      "eat probiotics and prebiotics . \n",
      "------------Document-----------------------------\n",
      "they can also protect your gut from harmful bacteria that irritates your bowels . since it is hard to gauge how many colony forming units of probiotics cfus are in foods , eat a variety of foods known to contain probiotics and prebiotics . to get probiotics in your diet , eat leafy green vegetables kale , spinach , swiss chard , spinach , beet greens , collard greens , mustard greens , broccoli , cauliflower , and cabbage . to get prebiotics , eat chicory root jerusalem artichoke dandelion greens garlic leeks asparagus wheat bran baked wheat flour bananas \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3457\n",
      "install the fan motor assembly .\n",
      "------------Greedy Search------------------------\n",
      "attach the fan motor assembly .\n",
      "------------Ground Truth-------------------------\n",
      "secure the fan to the joists . \n",
      "------------Document-----------------------------\n",
      "use drywall screws to firmly secure each bracket end to the joist . now that the fan is secure , take the length of flexible duct pipe and attach one end to the degree duct elbow protruding from fan housing using foil duct tape . now is also a good time to run an existing or new electrical cable through the connector on the fan housing . you can secure the cable by tightening the screw on the connector . be aware that you will need to use a three wire cable if your new fan includes a light . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3458\n",
      "trust your gut .\n",
      "------------Greedy Search------------------------\n",
      "trust your gut .\n",
      "------------Ground Truth-------------------------\n",
      "trust your partner . \n",
      "------------Document-----------------------------\n",
      "when you do not trust him or her having trust takes two people , and without the other person building trust , too , it is like a fish without water . this is where you have the opportunity to practice vulnerability . trusting another person often comes down to how you feel on the inside . in other words , if you tend to be insecure about things , then this could fall over into your relationship in a negative way . you have every reason to trust until the person actually does something that shows you cannot . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3459\n",
      "make sure you have enough cash .\n",
      "------------Greedy Search------------------------\n",
      "have a cash amount of cash in your cash bag .\n",
      "------------Ground Truth-------------------------\n",
      "estimate the total amount of money you will spend on these items . \n",
      "------------Document-----------------------------\n",
      "only bring that amount with you in cash no credit cards , no checks . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3460\n",
      "allow your veterinarian to heal .\n",
      "------------Greedy Search------------------------\n",
      "allow the doctor to heal the infection .\n",
      "------------Ground Truth-------------------------\n",
      "treat the infected area . \n",
      "------------Document-----------------------------\n",
      "after your veterinarian has flushed out the abscess and cleansed the infected area , he or she will probably recommend further treatment to ensure optimal healing . if your veterinarian strongly suspects a bacterial infection , he or she may decide to coat the infected area with triple antibiotic ointment until the area is fully healed . ear abscesses are usually left open to heal closing it up could seal in the infection . leaving the abscess open will allow it to continue to drain . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3461\n",
      "add a bot .\n",
      "------------Greedy Search------------------------\n",
      "add a contact .\n",
      "------------Ground Truth-------------------------\n",
      "send messages to add contacts . \n",
      "------------Document-----------------------------\n",
      "users to whom you have sent a message . you will find your contact list in this message bar . if the user replies to your message , you can chat with him or her . remember , you can only add up to contacts in a day . however , there is a paid feature of badoo to allow you add more contacts in a day . you need credits to activate this feature and it costs only . you cannot send messages to a user more than times if the user does not reply to your message . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3462\n",
      "be aware of the risks .\n",
      "------------Greedy Search------------------------\n",
      "report all suspicious infected to the illness .\n",
      "------------Ground Truth-------------------------\n",
      "cooperate with home isolation or quarantines as necessary . \n",
      "------------Document-----------------------------\n",
      "the cdc may ask that infected people be isolated from others during treatment . this can occur in the home or in a medical facility , depending on the severity of the illness . comply with all instructions given by community leaders . as noted , it is generally a good idea to keep infected persons away from healthy ones . in a pandemic situation , however , the cdc may provide additional instructions for keeping infected persons isolated . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3463\n",
      "take a sheet of aluminum foil .\n",
      "------------Greedy Search------------------------\n",
      "take a small amount of glue and cut it in half .\n",
      "------------Ground Truth-------------------------\n",
      "fill in the spaces that you feel need to be filled to make the heart look fuller . \n",
      "------------Document-----------------------------\n",
      "this depends on how big or small you prefer the heart to be . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3464\n",
      "keep your room clean .\n",
      "------------Greedy Search------------------------\n",
      "be nice to everyone .\n",
      "------------Ground Truth-------------------------\n",
      "be a good listener . \n",
      "------------Document-----------------------------\n",
      "do not always shower your family members with advice just hear them out at times . that is all they need . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3465\n",
      "choose a size .\n",
      "------------Greedy Search------------------------\n",
      "choose the size of the blanket sleeper .\n",
      "------------Ground Truth-------------------------\n",
      "choose a size . \n",
      "------------Document-----------------------------\n",
      "to make a square blanket , you can choose a size that fits the size of the baby . for example , if it is a newborn , make a blanket that is inches . m square , and if the baby is older , make a inch . m square blanket . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3466\n",
      "make your bed .\n",
      "------------Greedy Search------------------------\n",
      "make sure you have a box that is compatible with your bed .\n",
      "------------Ground Truth-------------------------\n",
      "bring all of your furniture out and bring it into a separate room so it is out of the way . \n",
      "------------Document-----------------------------\n",
      "this could include your bed , dresser , desk , drawers . . . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3467\n",
      "if you do not want to use an existing site , go to a reputable website .\n",
      "------------Greedy Search------------------------\n",
      "if you do not have a web site , go to the website that reads website .\n",
      "------------Ground Truth-------------------------\n",
      "evaluate the website for duplicate content , especially duplicate content accessible via multiple urls . \n",
      "------------Document-----------------------------\n",
      "many e commerce websites have this problem , which can result in a google penalty . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3468\n",
      "blow on the camera .\n",
      "------------Greedy Search------------------------\n",
      "blow on your camera .\n",
      "------------Ground Truth-------------------------\n",
      "play the note g . play an a , then add your ring finger . \n",
      "------------Document-----------------------------\n",
      "this note requires less air pressure than previous notes , so make sure that you do not blow too hard . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click the star icon .\n",
      "------------Greedy Search------------------------\n",
      "click the star icon .\n",
      "------------Ground Truth-------------------------\n",
      "click on the field next to default web browser . \n",
      "------------Document-----------------------------\n",
      "this should be at the top of the general tab . you can select your preferred web browser from here . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3470\n",
      "use dialogue .\n",
      "------------Greedy Search------------------------\n",
      "use dialogue and dialogue .\n",
      "------------Ground Truth-------------------------\n",
      "include stream of consciousness and or dialogue . \n",
      "------------Document-----------------------------\n",
      "when little direct action is taking place , recording the character s thoughts or conversations keeps the reader engaged . when using dialogue , note the speaker’s tone or inflection , any pauses or tics , or unusual words choices . do they gesture while they speak or use meaningful body language are they saying what they really think or hiding their true nature \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3471\n",
      "set realistic goals .\n",
      "------------Greedy Search------------------------\n",
      "set realistic goals .\n",
      "------------Ground Truth-------------------------\n",
      "discover your motivation type . \n",
      "------------Document-----------------------------\n",
      "the two most common motivation types are promotion focused and prevention focused . you are promotion focused if you are creative , impulsive , and enjoy trying new things . consider fast paced and evolving fields like social media and the tech sector . you are prevention focused if you prefer planning ahead of time and always paying attention to detail . consider a job with set hours in fields like law or data analysis . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3472\n",
      "fill the bottle with water .\n",
      "------------Greedy Search------------------------\n",
      "fill a bucket with warm water .\n",
      "------------Ground Truth-------------------------\n",
      "fill the bottle with warm water and soap . \n",
      "------------Document-----------------------------\n",
      "brita water bottles can withstand high temperatures , but be sure not to use water that is nearly boiling . hot water from the faucet is sufficient . use a few drops of mild dishwashing detergent , such as dawn or palmolive to wash the bottle . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3473\n",
      "smile .\n",
      "------------Greedy Search------------------------\n",
      "smile ! !\n",
      "------------Ground Truth-------------------------\n",
      "be polite and friendly to all customers , whether they are playing , parents of players , or just enquiring . \n",
      "------------Document-----------------------------\n",
      "remember that a smile can go a long way . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3474\n",
      "provide support .\n",
      "------------Greedy Search------------------------\n",
      "provide a team with questions .\n",
      "------------Ground Truth-------------------------\n",
      "offer recommendations . \n",
      "------------Document-----------------------------\n",
      "if you are a consulting professional , ensure that the team has a direction to move in once the assessment is complete . provide suggestions and or alternatives to treatment planning and development . \n",
      "=================================================\n",
      "------------Beam Search-------------------------- 3475\n",
      "write a monologue .\n",
      "------------Greedy Search------------------------\n",
      "write a monologue .\n",
      "------------Ground Truth-------------------------\n",
      "master transitions within the monologue . \n",
      "------------Document-----------------------------\n",
      "a good monologue will have a clear narrative arc , with at least one transition between its parts . instead of ranting or shouting for the entire piece , make a clear transition between the angry part of the monologue , for example , and the calmer , more introspective part of the piece . \n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range (3456, 3476):\n",
    "    print('------------Beam Search--------------------------', i)\n",
    "    print(decode_sequence(x_test[i].reshape(1,-1), 3))\n",
    "    print('------------Greedy Search------------------------')\n",
    "    print(decode_sequence(x_test[i].reshape(1,-1), 1))\n",
    "    print('------------Ground Truth-------------------------')\n",
    "    print(seq2summary(y_test[i]))\n",
    "    print('------------Document-----------------------------')    \n",
    "    print(seq2text(x_test[i]))\n",
    "    print('=================================================')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
