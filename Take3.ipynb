{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# Packages\n",
    "##### \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Read in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepdatafull = pd.read_csv('wikihowSep.csv')\n",
    "sepdata = pd.read_csv('wikihowSep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepdata = sepdatafull[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1585695, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine for NAs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>sectionLabel</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nSell yourself first.</td>\n",
       "      <td>Before doing anything else, stop and sum up y...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you want to be well-read, then, in the wor...</td>\n",
       "      <td>\\nRead the classics before 1600.</td>\n",
       "      <td>Reading the classics is the very first thing ...</td>\n",
       "      <td>Reading the Classics</td>\n",
       "      <td>How to Be Well Read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nJoin online artist communities.</td>\n",
       "      <td>Depending on what scale you intend to sell yo...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nMake yourself public.</td>\n",
       "      <td>Get yourself out there as best as you can by ...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nBlog about your artwork.</td>\n",
       "      <td>Given the hundreds of free blogging websites,...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0   So you're a new or aspiring artist and your c...   \n",
       "1   If you want to be well-read, then, in the wor...   \n",
       "2   So you're a new or aspiring artist and your c...   \n",
       "3   So you're a new or aspiring artist and your c...   \n",
       "4   So you're a new or aspiring artist and your c...   \n",
       "\n",
       "                            headline  \\\n",
       "0             \\nSell yourself first.   \n",
       "1   \\nRead the classics before 1600.   \n",
       "2  \\nJoin online artist communities.   \n",
       "3            \\nMake yourself public.   \n",
       "4         \\nBlog about your artwork.   \n",
       "\n",
       "                                                text          sectionLabel  \\\n",
       "0   Before doing anything else, stop and sum up y...                 Steps   \n",
       "1   Reading the classics is the very first thing ...  Reading the Classics   \n",
       "2   Depending on what scale you intend to sell yo...                 Steps   \n",
       "3   Get yourself out there as best as you can by ...                 Steps   \n",
       "4   Given the hundreds of free blogging websites,...                 Steps   \n",
       "\n",
       "                         title  \n",
       "0  How to Sell Fine Art Online  \n",
       "1          How to Be Well Read  \n",
       "2  How to Sell Fine Art Online  \n",
       "3  How to Sell Fine Art Online  \n",
       "4  How to Sell Fine Art Online  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata.head(5)\n",
    "# Notice how we have 4 columns: \n",
    "# 'overview': the full summary based on the wikihow article \n",
    "# 'headline': the \"summary\" for the paragraph in 'text' column \n",
    "# 'text': the actual text of the paragraph \n",
    "# 'sectionLabel': section label of the paragraph \n",
    "# 'title': the title of which the paragraph belongs to. \n",
    "\n",
    "# wikihowSep (downloaded here: https://github.com/mahnazkoupaee/WikiHow-Dataset) is the same file as \n",
    "# wikihowAll, except separated by paragraph. \n",
    "\n",
    "# Given the length of the documents under wikihowAll, we opted for a shorter summary model to work with where we can \n",
    "# take paragraphs, and attempt to generate the headline for the paragraph instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1387289"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are there any NA's that we should drop? \n",
    "# Note here that we are only concerned about the 3 columns: headline, text, and title \n",
    "\n",
    "sepdata_v1 = sepdata.dropna(subset=['headline','text','title'], axis=0).reset_index(drop=True) \n",
    "len(sepdata_v1) #yes, we see some NA rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>sectionLabel</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nSell yourself first.</td>\n",
       "      <td>Before doing anything else, stop and sum up y...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you want to be well-read, then, in the wor...</td>\n",
       "      <td>\\nRead the classics before 1600.</td>\n",
       "      <td>Reading the classics is the very first thing ...</td>\n",
       "      <td>Reading the Classics</td>\n",
       "      <td>How to Be Well Read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nJoin online artist communities.</td>\n",
       "      <td>Depending on what scale you intend to sell yo...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nMake yourself public.</td>\n",
       "      <td>Get yourself out there as best as you can by ...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nBlog about your artwork.</td>\n",
       "      <td>Given the hundreds of free blogging websites,...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0   So you're a new or aspiring artist and your c...   \n",
       "1   If you want to be well-read, then, in the wor...   \n",
       "2   So you're a new or aspiring artist and your c...   \n",
       "3   So you're a new or aspiring artist and your c...   \n",
       "4   So you're a new or aspiring artist and your c...   \n",
       "\n",
       "                            headline  \\\n",
       "0             \\nSell yourself first.   \n",
       "1   \\nRead the classics before 1600.   \n",
       "2  \\nJoin online artist communities.   \n",
       "3            \\nMake yourself public.   \n",
       "4         \\nBlog about your artwork.   \n",
       "\n",
       "                                                text          sectionLabel  \\\n",
       "0   Before doing anything else, stop and sum up y...                 Steps   \n",
       "1   Reading the classics is the very first thing ...  Reading the Classics   \n",
       "2   Depending on what scale you intend to sell yo...                 Steps   \n",
       "3   Get yourself out there as best as you can by ...                 Steps   \n",
       "4   Given the hundreds of free blogging websites,...                 Steps   \n",
       "\n",
       "                         title  \n",
       "0  How to Sell Fine Art Online  \n",
       "1          How to Be Well Read  \n",
       "2  How to Sell Fine Art Online  \n",
       "3  How to Sell Fine Art Online  \n",
       "4  How to Sell Fine Art Online  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211825"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Therefore, how many true titles do we have? \n",
    "len(sepdata_v1['title'].unique()) #only 211,825 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5492222353357725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It doesn't quite matter for us since we are trying to predict headline and not the title, \n",
    "# but out of curiosity, how many paragraphs on average belong to each title? \n",
    "np.nanmean(sepdata_v1[['title','text']].groupby('title').agg('count')['text'].values) \n",
    "# Roughly 6-7 paragraphs per title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Paragraphs per Article (title)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAGDCAYAAAAYtQWTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxkZX33/c+3u3qf7p6VGWZjBoHIoII4MBpxiRqBxIBJQAETxWAwd0ISszwJyX3fxmiSJyZ5onkpScQNonIj0ZiHKIpGjFtkmBFFHIZlHGAWYLaepZfppap/9x/n1FDT9FLdXdVVXfV9v179mqpzrjrn19X0zJfruuq6FBGYmZmZWWk1VLoAMzMzs1rkkGVmZmZWBg5ZZmZmZmXgkGVmZmZWBg5ZZmZmZmXgkGVmZmZWBg5ZZjanJIWkMypdx1yQ9ApJjxTR7lpJ35nFfd4p6YOTnH+LpK9Ocv7VkvYUea/flvT+mdRpVm8cssyqkKQnJB2X1Cdpn6RbJC2odF31RtJ6SaOS/qnI9icFyIj4dkT8VPkqBEnNwP8C/jZ9vi6tI1NQx2ci4vUT1TlNHwXeIumU2dRtVg8cssyq1y9ExALgfGAjyT+k01L4D20plPp61WCK7+mtwGHgzZJaZniNcrsceDgi9s7FzSJiEPgyyXtjZpNwyDKrcuk/nl8GXgAg6e2StkvqlbRT0jvzbfPDPpL+WNIzwCclLZL0RUkHJB1OH68ueM16Sd9Kr/efkm6S9On0XL5X5DpJu4B70uP/KukZSUfT155TcL1bJP2zpK+l1/ympNPGfFuvk/SYpCPp/ZS+9oy0/VFJByV9drz3pKCu6yU9JelpSX9YcL5B0o2SfiLpkKQ7JC2e7Hsa5x4iCRL/CxgBfmHM+ZD0W5IeAx6T9K301ANpD+Sbxw7DSVoj6d/Sn8UhSR+e4N7PT9+/HkmPSHrTeO1SlwLfLHier+NIWsfLCocjx6tznPuvlPT5tM7HJf3OmCb/Bfz8JDWZGQ5ZZlVP0hrg54AfpIf2A28AuoC3Ax+QdH7BS1YAi4HTgOtJfs8/mT5fCxwHCv9xvw24D1gCvAf41XHKeBVwNnBx+vzLwJnAKcD9wGfGtH8L8D5gKfDDcc6/AbgAeBHwpoLrvg/4KrAIWA18aJxaCv1MWsfrgT+W9Lr0+G8Db0zrXknSG3XTFN/TWBelNdwO3AG8bZw2bwQ2ARsi4pXpsXMjYkFEnBQQJTUCXwSeBNYBq9JrM6ZdB/A1kp/LKcBVwD9K2jBBnS8ECud95etYmNbxvcLGRdTZAPwH8EBa42uBd0kqfJ+2A+dOUI+Z5UWEv/zlryr7Ap4A+oAjJP8o/yPQNkHbfwd+N338amAYaJ3k2ucBh9PHa4Es0F5w/tPAp9PH64AATp/kegvTNt3p81uA2wvOLwBywJr0eQAXFZy/A7gxffwvwM3A6inen3xdzy849jfAx9PH24HXFpw7laQ3KlPM95S+5mPAv6ePX5a+/pSC8wG8ZsxrAjij4PmrgT0F1zgAZMa517XAd9LHbwa+Peb8R4A/m6DOx4BLxnlvMuNdv4g6NwG7xtzjT4BPFjw/E8hV+vfEX/6q9i/3ZJlVrzdGxMKIOC0ifjMijgNIulTSvelQ0hGSXq6lBa87EMm8GdL27ZI+IulJScdIhpMWpj0rK4GeiBgoeP3ucWo5cUxSo6S/TofijpEEQsbUcKJ9RPQBPem98p4peDxAEsQA/ggQcJ+kbZJ+bcJ357m1Pllwj9OAL6TDkUdIQlcOWD7Ba08iqQ24krQHLpLeoF3ANZPcfyprgCcjIjtFu9OATfna0/rfQtJDOZ7DQOc06pjKacDKMff/U05+7zqBoyW8p1lNcsgym0eUTL7+PPB3wPKIWAjcRRJM8mLMy/4A+ClgU0R08exwkoCngcWS2gvarxnn1oXXvIZksvXrgG6SnpP89Z5zDSWfilwMPDXFt0dEPBMRvx4RK4F3kgyTTfYpuMJa1xbcYzdwaRpS81+tcfLk8LHvU6FfJBmO/cd07tkzJENnY4cMJ7vGWLuBtZp6kvxu4Jtjal8QEf9jgvY/As6aYU0T3f/xMffvjIifK2hzNslwoplNwiHLbH5pBlpIhp2yki4lmY80mU6SeVhH0snff5Y/ERFPAluB90hqlvQyxkzwnuB6Q8AhoB34q3Ha/Jyki5QsL/A+4N6ImLLXR9KVenZS/mGSwDA6yUv+d9pTdw7J/LT8/KJ/Bv4yP+Fe0jJJl091/wJvAz5BMt/pvPTr5cC5kl44yev2AadPcO4+klD715I6JLVKevk47b4InCXpVyU1pV8XSDp7guveRTK/LO8AyXs2UR3F1Nmr5MMTbWnP5QskXVDQ5lUk8/LMbBIOWWbzSET0Ar9DMo/pMEmv0p1TvOyDQBtwELgX+MqY828hmS90CPgLkqAyNMn1/oVkaG4v8FB6zbFuIwlzPcBLgF+Zosa8C4DNkvpIvq/fjYidk7T/JrAD+DrwdxGRX3DzH9LXf1VSb1rjpmIKkJSf7P3BtGct//V9kvduvAnwee8Bbk2H2U76RGBE5EgC7BkkQ497SOZfMaZdL0lwvoqkZ+4Z4P0k4Xo8/wE8X9LK9PUDwF8C303reOkM6nwDSbB8nOS/m4+R9FoiqZVkiPrWSd4HMwMUMdueZTOrJUqWTXg4Iv5sysbjv/4WkknU017Xaxr3WEcSAJqKmONU8yRdT/IJx3fNwb1+m+RDDH9U7nuZzXc1t7CgmU1POgzUQxJaXk8y3+qvK1qUTUtE3DyH95pqWQ0zSzlkmdkK4N9I1snaA/yPiPjB5C8xM7OpeLjQzMzMrAw88d3MzMysDByyzMzMzMqg6uZkLV26NNatW1fpMszMzMym9P3vf/9gRCwb71zVhax169axdevWSpdhZmZmNiVJT050zsOFZmZmZmXgkGVmZmZWBg5ZZmZmZmXgkGVmZmZWBg5ZZmZmZmXgkGVmZmZWBg5ZZmZmZmXgkGVmZmZWBg5ZZmZmZmXgkGVmZmZWBg5ZZmZmZmXgkGVmZmZWBg5ZZmZmZmWQqXQB89Vtm3cV1e6aTWvLXImZmZlVI/dkmZmZmZWBQ5aZmZlZGThkmZmZmZWBQ5aZmZlZGThkmZmZmZWBQ5aZmZlZGThkmZmZmZWBQ5aZmZlZGThkmZmZmZWBQ5aZmZlZGThkmZmZmZWBQ5aZmZlZGThkmZmZmZVBUSFL0iWSHpG0Q9KN45x/paT7JWUlXTHm3FpJX5W0XdJDktaVpnQzMzOz6jVlyJLUCNwEXApsAK6WtGFMs13AtcBt41ziX4C/jYizgQuB/bMp2MzMzGw+yBTR5kJgR0TsBJB0O3A58FC+QUQ8kZ4bLXxhGsYyEfG1tF1faco2MzMzq27FDBeuAnYXPN+THivGWcARSf8m6QeS/jbtGTMzMzOraeWe+J4BXgH8IXABcDrJsOJJJF0vaaukrQcOHChzSWZmZmblV0zI2gusKXi+Oj1WjD3ADyNiZ0RkgX8Hzh/bKCJujoiNEbFx2bJlRV7azMzMrHoVE7K2AGdKWi+pGbgKuLPI628BFkrKJ6fXUDCXy8zMzKxWTRmy0h6oG4C7ge3AHRGxTdJ7JV0GIOkCSXuAK4GPSNqWvjZHMlT4dUkPAgI+Wp5vxczMzKx6FPPpQiLiLuCuMcfeXfB4C8kw4niv/RrwolnUaGZmZjbveMV3MzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyDIzMzMrA4csMzMzszJwyCqR7OhopUswMzOzKuKQVQIP7D7CX921nZ7+4UqXYmZmZlXCIasE9vcOMTgyyhd/9FSlSzEzM7Mq4ZBVAgPDWQAefqaX7U8fq3A1ZmZmVg0cskpgYDjHovYmTuls4Ys/eorhrOdnmZmZ1TuHrBIYGM7S2drEZeet5PDACN989EClSzIzM7MKc8gqgYHhHO3NjZy+dAHnrVnItx47wMG+oUqXZWZmZhVUVMiSdImkRyTtkHTjOOdfKel+SVlJV4xzvkvSHkkfLkXR1SYfsgAufcEKMg3iPx54ioiocGVmZmZWKVOGLEmNwE3ApcAG4GpJG8Y02wVcC9w2wWXeB3xr5mVWt4HhLO3NGQA6W5t43dnLeWx/H9ue8iR4MzOzelVMT9aFwI6I2BkRw8DtwOWFDSLiiYj4EfCcGd+SXgIsB75agnqrzkhulJFcnOjJAnjp6UtY0dXKlx58msGRXAWrMzMzs0opJmStAnYXPN+THpuSpAbg/wP+cIp210vaKmnrgQPza9L4wHASotoKQlZjg3jN80/h6PERfrz3aKVKMzMzswoq98T33wTuiog9kzWKiJsjYmNEbFy2bFmZSyqt/BpZ+eHCvKWdLQA8fXRwzmsyMzOzystM3YS9wJqC56vTY8V4GfAKSb8JLACaJfVFxHMmz89X+Z6swuFCgO7WJgCeccgyMzOrS8WErC3AmZLWk4Srq4Brirl4RLwl/1jStcDGWgpY8GzI6hjTk9Xa1EBzpsE9WWZmZnVqyuHCiMgCNwB3A9uBOyJim6T3SroMQNIFkvYAVwIfkbStnEVXk2eHC0/uyZJEd2sTTx89XomyzMzMrMKK6ckiIu4C7hpz7N0Fj7eQDCNOdo1bgFumXWGVm2i4EKC7rck9WWZmZnXKK77P0sBQlubGBjKNz30ru9uaPCfLzMysTjlkzVLhau9jdbU1sb93kGzOG0abmZnVG4esWZosZHW3NTEasL/X+xiamZnVG4esWSrcUmes7rZkGQfPyzIzM6s/DlmzNDCcO2m190LPhix/wtDMzKzeOGTN0lTDheAFSc3MzOqRQ9YsjEYwOJKbcLiwtamB9uZGDxeamZnVIYesWRgczhFAR8v4PVmSWNHd6uFCMzOzOuSQNQuTLUSad2p3q3uyzMzM6lBRK77b+PpPbKkz8dt4fHiUnQf6uW3zrkmvdc2mtSWtzczMzCrLPVmzUExPVndbhmPHR8iNxlyVZWZmZlXAIWsWng1ZE/dkdbU1EUDfUHaOqjIzM7Nq4JA1CwMnhgsn7slamC7jcHRgeE5qMjMzs+rgkDULA8M5GgQtmYnfxq58yBp0T5aZmVk9cciahWS19wySJmyTX5D06PGRuSrLzMzMqoBD1iwk+xZOPFQI0NbUSFOjPFxoZmZWZxyyZmGyLXXyJNHd1uThQjMzszrjkDULx4dzdEzyycK87rYmjnm40MzMrK44ZM1CMcOFkIQsz8kyMzOrLw5ZMxQRRQ0XQvIJw95BL0hqZmZWTxyyZmg4N0p2NCZdiDSvu62J0fCCpGZmZvXEIWuGitlSJ8/LOJiZmdUfh6wZcsgyMzOzyThkzVB+S522IocLAX/C0MzMrI44ZM3QdHqyTixI6pBlZmZWNxyyZmg6IUsSXa1exsHMzKyeOGTNUH64sJhPFwJ0tztkmZmZ1ZOiQpakSyQ9ImmHpBvHOf9KSfdLykq6ouD4eZK+J2mbpB9JenMpi6+kgeEcrU0NNDZMvDl0oW73ZJmZmdWVKUOWpEbgJuBSYANwtaQNY5rtAq4FbhtzfAB4a0ScA1wCfFDSwtkWXQ2OD+eK7sWCZPJ77+AIo+EFSc3MzOpBMSnhQmBHROwEkHQ7cDnwUL5BRDyRnhstfGFEPFrw+ClJ+4FlwJFZV15hxW6pk9fdnixI2juYPfFpQzMzM6tdxQwXrgJ2Fzzfkx6bFkkXAs3AT6b72mrUP1Tcljp53a1exsHMzKyezMnEd0mnAp8C3h4Ro+Ocv17SVklbDxw4MBclzVrSk1X8cGGXFyQ1MzOrK8WErL3AmoLnq9NjRZHUBXwJ+J8Rce94bSLi5ojYGBEbly1bVuylK2pgOEfbNHqyFjpkmZmZ1ZViQtYW4ExJ6yU1A1cBdxZz8bT9F4B/iYjPzbzM6jKSG2UoOzqt4cK25kYyDV6Q1MzMrF5MGbIiIgvcANwNbAfuiIhtkt4r6TIASRdI2gNcCXxE0rb05W8CXglcK+mH6dd5ZflO5tCRgSQoTWe4UBLdbV7GwczMrF4UlRIi4i7grjHH3l3weAvJMOLY130a+PQsa6w6RwaGgeJWey/kkGVmZlY/vOL7DBw+0ZM1/ZDlTxeamZnVB4esGTh8oier+OFCSEOWFyQ1MzOrCw5ZM5AfLuyYZk9WV1uyIGnfYLYcZZmZmVkVcciagcMzmPgOnFjp3fOyzMzMap9D1gwcHhgm0yCaGovbHDrPIcvMzKx+OGTNwOH+YdqbG5GmF7Lyq773DjpkmZmZ1TqHrBk4PDAy7aFCSD6N2CA45jlZZmZmNc8hawaODAxPa0udvAaJzlYv42BmZlYPHLJmIOnJmn7IAuhqzdDrniwzM7Oa55A1A0cGhmc0XAjJvKxjnpNlZmZW8xyypikiODKLnqzOVocsMzOzeuCQNU29Q1myozGr4cLBkVGGs6MlrszMzMyqiUPWNB3pT3qhOmY6XNjqZRzMzMzqgUPWND27b+EMe7LStbK8jIOZmVltc8iaptmGrM7WpAfM87LMzMxqm0PWND0bsmY5XOi1sszMzGqaQ9Y0He7Pbw49s56s1qYGmhrl4UIzM7Ma55A1TUcGhpGgdYYhSxJdXsbBzMys5jlkTdPR4yN0tTbRMM3NoQslW+u4J8vMzKyWOWRNU99QjgUtM5uPldfVlvESDmZmZjXOIWua+oeydLTMbKgwLz9cGBElqsrMzMyqjUPWNPUPZ+mYZU9WZ2uGkVwwOOJV383MzGqVQ9Y09Q9lSzBcmF+Q1EOGZmZmtcoha5r6h3IzXr4h79mtdTz53czMrFY5ZE1T39Dshwu7vOq7mZlZzXPImqb+4dkPF3Z61XczM7Oa55A1TQNDuVn3ZDVnGmhtauCohwvNzMxqlkPWNAxnRxnOjdIxyzlZkMzL8lpZZmZmtauokCXpEkmPSNoh6cZxzr9S0v2SspKuGHPubZIeS7/eVqrCK6F/KOl5mm1PFqRrZXm40MzMrGZNGbIkNQI3AZcCG4CrJW0Y02wXcC1w25jXLgb+DNgEXAj8maRFsy+7MvpKGLI6WzP+dKGZmVkNK6Yn60JgR0TsjIhh4Hbg8sIGEfFERPwIGLu65sXA1yKiJyIOA18DLilB3RXRP5yEotlOfIdkrazewSyjXvXdzMysJhUTslYBuwue70mPFWM2r606/UM5gFmvkwXJMg65CAaGc7O+lpmZmVWfqpj4Lul6SVslbT1w4ECly5lQfk5WKXqy8ss4eF6WmZlZbSomZO0F1hQ8X50eK0ZRr42ImyNiY0RsXLZsWZGXnnslnfjell/13SHLzMysFhUTsrYAZ0paL6kZuAq4s8jr3w28XtKidML769Nj81JfCXuynl313ZPfzczMatGUISsissANJOFoO3BHRGyT9F5JlwFIukDSHuBK4COStqWv7QHeRxLUtgDvTY/NS/n5U6WYk+XhQjMzs9pWVJdMRNwF3DXm2LsLHm8hGQoc77WfAD4xixqrRimXcGhsEB0tGfdkmZmZ1aiqmPg+X/QPZck0iJZMad62rtaM52SZmZnVKIesaegfytLRkkFSSa7X1drEMYcsMzOzmuSQNQ39w7mS7FuY19maofe4hwvNzMxqkUPWNOR7skqlq62JvqEsuVGv+m5mZlZrHLKmoa/UIau1ieDZCfVmZmZWOxyypqF/KFuSNbLyTqyV5WUczMzMao5D1jQMDOdKskZWXqdXfTczM6tZDlnT0FeuniyvlWVmZlZzHLKmodQT3ztaMjTIw4VmZma1yCFrGvqHciUNWQ0Sna1N7skyMzOrQQ5ZRRrOjjKcGy3pOlmQrpXlOVlmZmY1xyGrSAPDpdu3sJBXfTczM6tNDllFyq9lVcqJ7wBdbRmOedV3MzOzmuOQVaT+oRxQnp6s4yM5BkdyJb2umZmZVZZDVpH60+HC9pZSz8lK1sraf2yopNc1MzOzynLIKlJ/uYYL07Wy9vUOlvS6ZmZmVlkOWUXKh6yO5lLPyUp6svYdc8gyMzOrJQ5ZRepL52SVvicrCVnPHHXIMjMzqyUOWUUaKNOcrNamBloyDew5fLyk1zUzM7PKcsgqUrmWcJDEovZmhywzM7Ma45BVpP6hLI0NoiVT+rdsYXsTe484ZJmZmdUSh6wi9Q/l6GhuRFLJr72wvZk9hwdKfl0zMzOrHIesIvUPZUu+EGneovYmegezHD3u7XXMzMxqhUNWkfqHyxmymgHcm2VmZlZDHLKK1DeUK1vIWtieLOOw15PfzczMaoZDVpH6h7IsKPHyDXnP9mQ5ZJmZmdUKh6wi9Q9laS/xau957c2NtDc3OmSZmZnVEIesIvUPZ0u+RlaeJFYvamPvEc/JMjMzqxVFhSxJl0h6RNIOSTeOc75F0mfT85slrUuPN0m6VdKDkrZL+pPSlj93+odydJRpuBBg1cI292SZmZnVkClDlqRG4CbgUmADcLWkDWOaXQccjogzgA8A70+PXwm0RMQLgZcA78wHsPmmr4xLOACsXtTukGVmZlZDiunJuhDYERE7I2IYuB24fEyby4Fb08efA16rZNXOADokZYA2YBg4VpLK59BIbpTh7CgdZZqTBbB6URtHj4/QO+i1sszMzGpBMSFrFbC74Pme9Ni4bSIiCxwFlpAErn7gaWAX8HcR0TP2BpKul7RV0tYDBw5M+5sot4GhHEBZe7JWLWoD8PY6ZmZmNaLcE98vBHLASmA98AeSTh/bKCJujoiNEbFx2bJlZS5p+vqG85tDl29O1upF7QDs6XHIMjMzqwXFhKy9wJqC56vTY+O2SYcGu4FDwDXAVyJiJCL2A98FNs626LnWP5SErPLOyXJPlpmZWS0pJmRtAc6UtF5SM3AVcOeYNncCb0sfXwHcExFBMkT4GgBJHcBLgYdLUfhcOhGyyjgna0lHM61NDd5ax8zMrEZMGbLSOVY3AHcD24E7ImKbpPdKuixt9nFgiaQdwO8D+WUebgIWSNpGEtY+GRE/KvU3UW79czAnS5KXcTAzM6shRaWGiLgLuGvMsXcXPB4kWa5h7Ov6xjs+3/SdGC4s35ws8DIOZmZmtcQrvhchP1xYrhXf81YtavOcLDMzsxrhkFWEgfTTheXauzBv9aI2evqHT4Q6MzMzm78csorQl87JKndPVn4ZB/dmmZmZzX8OWUXoH8rSIGhtKu/btWphuoyD52WZmZnNew5ZRcjvW5jsFFQ+a9K1sryMg5mZ2fznkFWEgeFsWdfIylu6oIXmTIM/YWhmZlYDHLKK0D+UK/vyDQANDelaWZ6TZWZmNu85ZBWhbyhb9knveasXeUFSMzOzWuCQVYT+dE7WXFi9qI29npNlZmY27zlkFaF/OFf2NbLyVi1s42DfMMeHc3NyPzMzMysPh6wi9A9lWTAHc7LAa2WZmZnVCoesIsz1cCF4GQczM7P5ziGrCHM58X3ViZDlniwzM7P5zCFrCtncKEPZ0Tmbk3VKZytNjfJwoZmZ2TznkDWF/nQC+lyskwXQ2CBWLvQyDmZmZvOdQ9YU+oeyQPk3hy6UrJXlOVlmZmbz2dwlh3kqH7LKPfH9ts27TjweHBllx/6+k47lXbNpbVnrMDMzs9JwT9YU5nq4EGBRexO9g1lGcqNzdk8zMzMrLYesKZzoyZqjie8Ai9qbATg6MDJn9zQzM7PScsiaQt8cDRcWWpiGrMPHh+fsnmZmZlZaDllTqMTE90XtTQAc6XdPlpmZ2XzlkDWF/Jys9jmck9XZ2kSDoGfAPVlmZmbzlUPWFCrRk9XYIBZ3tHCgd2jO7mlmZmal5ZA1hf6hLA2Ctqa568kCWN7Vwv7ewTm9p5mZmZWOQ9YU+oaydDRnkDSn913e1cqhvmEv42BmZjZPOWRNYWAoN6fzsfJO6WwhwEOGZmZm85RD1hT6hrNzunxD3vKuVgAPGZqZmc1TRYUsSZdIekTSDkk3jnO+RdJn0/ObJa0rOPciSd+TtE3Sg5JaS1d++fUPZed00nvekgXNNErsO+aeLDMzs/loypAlqRG4CbgU2ABcLWnDmGbXAYcj4gzgA8D709dmgE8DvxER5wCvBubV4k/96ZysuZZpaGDJgmb2HXNPlpmZ2XxUTE/WhcCOiNgZEcPA7cDlY9pcDtyaPv4c8FolM8VfD/woIh4AiIhDEZErTelzo38oN6f7FhZa3tXqkGVmZjZPFROyVgG7C57vSY+N2yYissBRYAlwFhCS7pZ0v6Q/mn3Jc6u/QnOyIFnG4fDACMNZf8LQzMxsvin3xPcMcBHwlvTPX5T02rGNJF0vaaukrQcOHChzSdPTP1S5kHVKpye/m5mZzVfFhKy9wJqC56vTY+O2SedhdQOHSHq9vhURByNiALgLOH/sDSLi5ojYGBEbly1bNv3vooz6KjTxHWBF+glDT343MzObf4oJWVuAMyWtl9QMXAXcOabNncDb0sdXAPdERAB3Ay+U1J6Gr1cBD5Wm9PLL5kYZHBmlvbkyc7IWL2gm0yD2e16WmZnZvDNlF01EZCXdQBKYGoFPRMQ2Se8FtkbEncDHgU9J2gH0kAQxIuKwpL8nCWoB3BURXyrT91JyAyPJHP1K9WQ1SCzrbGGfhwvNzMzmnaLSQ0TcRTLUV3js3QWPB4ErJ3jtp0mWcZh38ptDV2pOFiSfMHz8YH/F7m9mZmYz4xXfJ1ENIeuUzhaOHh9hcGRerXxhZmZW9xyyJtE3lASbjgrNyYKC7XU8L8vMzGxecciaxEAV9GTlQ9Y+bxRtZmY2rzhkTaIvDVmVmvgOsLC9iaZGeeV3MzOzeaZy6aFK3bZ514nHP9h1GIB7Ht7Pj/YcrUg9DRKndLay32tlmZmZzSvuyZrEULqdTXOmsm/T8i4v42BmZjbfOGRNIr9nYEvFQ1YrvYNZBoazFa3DzMzMiueQNYmh7CgCmhsr+zbl9zD09jpmZmbzh0PWJIazOZozDUiqaB3Lu1oAbxaT7p4AABowSURBVBRtZmY2nzhkTWIoO1rx+VgA3W1NtGQa/AlDMzOzeaTyCaKKDWVHKz4fC0ASy7taPVxoZmY2j1Q+QVSx3sEsHc3VscrFKZ0t7skyMzObRxyyJrG/d5BT0vlQlba8q5WB4RwH+9ybZWZmNh84ZE2gbyjLwHDuxCf7Ki2/vc6j+3orXImZmZkVwyFrAvkNmaulJytfx6PPOGSZmZnNBw5ZE9ifbshcLT1ZnS0Z2poaeWRfX6VLMTMzsyI4ZE1gf+8gLZkGulqrY+K7JNYsbuN7PzlIRFS6HDMzM5uCQ9YE9h0bYnlXa8UXIi109qldPHFogEfdm2VmZlb1HLImsL93iFM6q2M+Vt6GU7uQ4O5tz1S6FDMzM5uCQ9Y4+oey9A9lqy5kdbY2cf7aRXzlxw5ZZmZm1c4haxwnJr13Vcek90IXn7Och54+xu6egUqXYmZmZpNwyBpHfiPmauvJArj4nBWAhwzNzMyqnUPWOPYfG6I500B3W1OlS3mO05Z08PwVnXx1275Kl2JmZmaTcMgax77eQU7pbKmqTxYWuvicFWx5socDvd5ix8zMrFo5ZI3jwLEhllfJIqTjuficFUTAf253b5aZmVm1csgaY2A4S+9Qtmq20xnP2ad2smZxm+dlmZmZVTGHrDH2H8tvp1O9IUsSl5yzgv/ecYjewZFKl2NmZmbjcMgao9r2LJzIxeesYDg3yjceOVDpUszMzGwcRYUsSZdIekTSDkk3jnO+RdJn0/ObJa0bc36tpD5Jf1iasstnf+8gzY0NdLdX3ycLC52/dhFLF7RwtxcmNTMzq0pThixJjcBNwKXABuBqSRvGNLsOOBwRZwAfAN4/5vzfA1+efbnlt//YEMs6W2io0k8W5jU0iJ/dsJz/emQ/gyO5SpdjZmZmYxTTk3UhsCMidkbEMHA7cPmYNpcDt6aPPwe8Vun6B5LeCDwObCtNyeW1P12+YT645AUr6B/O8d0dBytdipmZmY1RTMhaBewueL4nPTZum4jIAkeBJZIWAH8M/PlkN5B0vaStkrYeOFC5OUZHj49wbDDL8ircTmc8Lzt9CZ2tGe9laGZmVoUyZb7+e4APRETfZAt7RsTNwM0AGzdujDLXNKEd+3uB6v5k4W2bd530/IxlC7jzgafYsLKLlkzjiePXbFo716WZmZlZgWJ6svYCawqer06PjdtGUgboBg4Bm4C/kfQE8C7gTyXdMMuay+axfX1AdW4MPZEL1y9mKDvKA7uPVroUMzMzK1BMyNoCnClpvaRm4CrgzjFt7gTelj6+ArgnEq+IiHURsQ74IPBXEfHhEtVeco/t76OpUSys8k8WFlq7uJ1Tu1u5d+chIirWCWhmZmZjTBmy0jlWNwB3A9uBOyJim6T3SrosbfZxkjlYO4DfB56zzMN88Oi+3nnxycJCkti0fgnPHBtkV89ApcsxMzOzVFFzsiLiLuCuMcfeXfB4ELhyimu8Zwb1zakd+/vmzaT3Queu6ebLP36azY/3cNqSjkqXY2ZmZnjF9xN6B0d4+uj8Wb6hUEumkfPXLuLBvUfpG8pWuhwzMzPDIeuEx/ank96rfDudiWxav5jcaPD9Jw9XuhQzMzPDIeuEHeknC5d3zb+eLEg+EXn60g7ue/wQo54Ab2ZmVnEOWanH9vfSnGlgUUdzpUuZsU2nL+HwwAiP7uutdClmZmZ1zyEr9ei+Pp63bMG8+mThWBtO7aKzNcPmnT2VLsXMzKzuOWSldh8eYP3S9kqXMSuNDeKCdYt5dF8vuw55OQczM7NKcshKHeobZknH/JyPVeiCdYuR4DP3PVnpUszMzOqaQxYwkhvl6PERFs/j+Vh53W1NnH1qF5/dstvLOZiZmVWQQxZweGAYgKUL5n/IAnjlmcs4MjDCrf/9RKVLMTMzq1sOWUBPfxKyFtfAcCHAmsXtvOb5p/DRb++kd3Ck0uWYmZnVJYcskvlYQE0MF+a963VnujfLzMysghyygENpT9aSGhkuBHjR6oW87uxT+Oi3H+eYe7PMzMzmnEMW0NM3BNRWTxbA7772LI4eH+GW7z5R6VLMzMzqjkMWyZwsCRa111bIeuHqbl539nI+9u2d7s0yMzObYw5ZwMH+YRa1N9PYMH9Xe5/Iu153JscGs3zyO09UuhQzM7O64pAF9PQN19xQYd4LVnXz+g3L+dh3dnL0uHuzzMzM5opDFslwYa2GLIB3ve4segezfOI7j1e6FDMzs7rhkAUc6h+qmYVIx7NhZReXnLOCj3/ncR7d11vpcszMzOqCQxbJEg613JMF8D9//mzamxu55qOb2bG/r9LlmJmZ1by6D1nZ3ChHBkZqZrX3iaxZ3M5tv/5SAK756L08frC/whWZmZnVtroPWYcHksngS2q8JwvgjFMWcNuvbyI3Glx98708echBy8zMrFzqPmT11OBq75M5a3knn37HJgazOa756GZ29wxUuiQzM7OaVPch61CNrvY+mbNP7eLT122id3CEaz52LwfT98DMzMxKxyEr35NV43OyxnrBqm4+dd0m9h8b4l23/5DcaFS6JDMzs5pS9yErP1xYTz1ZeeeuWcifX3YO39lxkA/fs6PS5ZiZmdWUTKULqLRDJ/YtbKp0KRWRGw3OW7OQD/7noxwbHOF5yxaM2+6aTWvnuDIzM7P5re57sg71DbGwrYlMY32+FZK4/LyVLF3Qwme37KbXG0mbmZmVRH0miwK1vqVOMVoyjVy9aS1D2Ryf3bKb0fD8LDMzs9kqKmRJukTSI5J2SLpxnPMtkj6bnt8saV16/GclfV/Sg+mfrylt+bN3qH+47ia9j2dFVyuXnbuKnQf7+fr2/ZUux8zMbN6bMmRJagRuAi4FNgBXS9owptl1wOGIOAP4APD+9PhB4Bci4oXA24BPlarwUunpH66bNbKm8pLTFnH+2kX81yP7+fHeo5Uux8zMbF4rpifrQmBHROyMiGHgduDyMW0uB25NH38OeK0kRcQPIuKp9Pg2oE1SVXUbHeobqvvhwkKXnbuSNYvbuX3LLrY/fazS5ZiZmc1bxYSsVcDugud70mPjtomILHAUWDKmzS8D90fEc1a+lHS9pK2Sth44cKDY2mctNxocOT5SF1vqFKs508C1P72OVQvbuG3zLh55xkHLzMxsJuZk4rukc0iGEN853vmIuDkiNkbExmXLls1FSQAcHhgmoj7XyJpMa1Mj1/70epZ3t/CZzbt4bF9vpUsyMzObd4oJWXuBNQXPV6fHxm0jKQN0A4fS56uBLwBvjYifzLbgUnp238KqGsGsCm3Njfzay9ezrLOFT937JP+942ClSzIzM5tXiglZW4AzJa2X1AxcBdw5ps2dJBPbAa4A7omIkLQQ+BJwY0R8t1RFl0p+zz4PF46vvTnD21++nsUdzVx361bue7yn0iWZmZnNG1OGrHSO1Q3A3cB24I6I2CbpvZIuS5t9HFgiaQfw+0B+mYcbgDOAd0v6Yfp1Ssm/ixk6saWOP104oQUtGa67aD0rF7by9k/exw93H6l0SWZmZvNCUXOyIuKuiDgrIp4XEX+ZHnt3RNyZPh6MiCsj4oyIuDAidqbH/yIiOiLivIKvqlmEqZ73LZyOztYmPvOOl7JkQQtv/fhmtj3l5R3MzMymUtd7Fx7qS0NWu0PWVO55eD9v3riGm7+9kyv/+Xv8+itOZ3lX60ltvL+hmZnZs+p6W52e/mEWttfvvoXTtaijmesuWk+jxCe++ziH+p6zGoeZmZml6jpdHOr3QqTTtXRBC7920Xpyo8HHv/M4hweGK12SmZlZVarvkNU37E8WzsDyrlZ+7eXrGczm+MR3Hqd3cKTSJZmZmVWdug5ZPd4cesZWLmzj2peto3cwyye++zgDQ9lKl2RmZlZV6nrie0//MBesr82erNs27yr7PdYu6eBXX3Yat/73E3zyv5/gzReuobO1qez3NTMzmw/qticrNxr0DHi4cLaet2wB11y4lqePHue6W7ZyfDhX6ZLMzMyqQt2GrCPet7Bknn9qF2/auIatT/bwzk9/n6Gsg5aZmVndhizvW1haL1q9kL/+pRfxrUcP8I5bt3LEnzo0M7M6V7ch61A+ZLknq2TedMEa/uaXX8TmnT284UPf4cd7vTK8mZnVr7qd+H5itXeHrJLJT7a/7qL13HbfLt5403e5/LyVvOS0xSe188rwZmZWD+q2J6unP1mt3D1ZpbdmcTu/9TNncNqSdj5//16+8IM9jORGK12WmZnZnKrbkJUfLlzkkFUWC1oyvP3l63nVWcvY8sRhbv7WzhPz4MzMzOpB3Yasnv5hutuaaPK+hWXTIHHxOSv4lU2ncah/iA9/4zEeeupYpcsyMzObE3WbMLylztzZsLKLG37mTJZ0tPDpzU/yl196yMOHZmZW8+o3ZHlz6Dm1uKOZd77ydF56+mI++u3Huerme3n66PFKl2VmZlY2dRuyevqHWbLAIWsuZRobuOzcVXzo6hfz8NPHuPgD3+K2zbsYHY1Kl2ZmZlZydbuEQ0//8HOWFrC50TuY5Z2veh5f+MFe/vQLD/LP3/wJl5+3klO7205q56UezMxsPqvLnqzR0Uh6sjxcWDFLF7TwjovWc8VLVnOwb4ibvrGDLz/4tLfkMTOzmlGXPVlHjo8w6n0LK04S569dxPNXdHL3tmf49o6DPLDnCC973lIuWLeo0uWZmZnNSl2GrBMLkXpOVlVob87wiy9ezflrF/G17fu4e9sz3PPwPnYe7OftP72OM5d3VrpEMzOzaavLkJXfUmdJhzeHrianLengHRedztNHj/O9nxzic9/fw22bd/GKM5dyxUtW8/oNK2hrbqx0mWZmZkWpz5DV730Lq9mp3W380vmref05K9jyRA/3Pd7Dtx87SHOmgXNO7eLFaxdx+rIOGiTAE+TNzKw61XXI8nBhdVvQkuFnfuoUXnXWMp441M8Pdx3hwb1H+cHuI3S2Zjj71C7OXtHF4EiO1ib3cJmZWXWpy5DVkw4XLmp3yJoPGiROX7qA05cu4BfOXcnDz/TywO4j/HDXEe57vId//f5uXnHmUl579nIuWLeY0xa309CgSpdtZmZ1rj5DVv8QXa0ZmjN1uYLFvNbU2MALV3XzwlXdjORG2Xmgn1yM8vXt+7l72z4g6QHbcGoXG1Z2cc7KLk5f1sGqhe0s62yh0eHLzMzmSF2GrIP9wyxZ4Env811TYwM/taKTazat5X2XBw8/08uDe46y7amj/PipY9yxdTcDw8+uu5VpECu6W1m5sI1VC9tY0d3Kqd2tnNrdxqndrSzrbKGzNUNbUyOSw5iZmc1OUSFL0iXAPwCNwMci4q/HnG8B/gV4CXAIeHNEPJGe+xPgOiAH/E5E3F2y6meop2/Yk95rjKRkjtapXcAaAHKjwROH+tnVM8BTR47z1W37OHp8hH3HBnl0Xy/H0vXSxso0iK62JrpaMyxZ0ML6pR2sX9rB6Us7WL+sg9MWd/hTjmZmNqUpQ5akRuAm4GeBPcAWSXdGxEMFza4DDkfEGZKuAt4PvFnSBuAq4BxgJfCfks6KiIou693TP8xpS9orWYKV0G2bd03ZRoiLz1lx0rHRCPqHshw9PsLR4yP0D+UYHMlxfCT5c3AkR0//MI/t6+XYYPak17ZkGli1sI2lC1pY1tnC4o5mWjINNGUaaGpsoLlRNGca6GjJsKAlQ1drEwtak8fdbU10tzXR3uweMzOzWlZMT9aFwI6I2Akg6XbgcqAwZF0OvCd9/Dngw0r+9bgcuD0ihoDHJe1Ir/e90pQ/M4f6hzn/tIWVLMGqQINEZ2sTna1NrJ5igfmhbI5DfcMc7Buip3+Y3qEsfYNZDvQNsfNgP/1DWXIR5EaTr2I0NYrutia62ppozTTSlEnCWaYhCWuNaf7KBzEBzZkGulqb6GrLpH820dbcSFOjaGxooKlBNKZf4+U3STQqOd+Q/plpFE0NDWQaRaZBZBobaJRoaEjeo4b08Qlx0h9EQBDEON92vgYhGgQN+ftKoOS80rqUtk+ul792FFzr2fdB4sQSHg3SSc8LXxdpfaMRJ/4cjTjpfcg0qKgPSkQ8+z1KOCCb2ZSKCVmrgN0Fz/cAmyZqExFZSUeBJenxe8e8dtWMqy2RV5y5lBev8bYtVryWTCMrF7axcmHblG0jgtGAbG6Uoewog9kcQyPJn4Mjo0lv2XDSY3Z8OMfASI5sbpSBoSy9BUGtMLREGjtGcsFQ2ts2kisuzFlxGsYJThFxIqiNJZGE0TTknWgSz/68ppJES0CFxwruP+Z6MSbgFr4mCaxpeGX8duPX8Oz3c1JNk71mTJPx3p9yvHYmZpuFx758vHKf/bmc/HMqrEHoxP9UFKPwf2LGrWuC/2ZqzWTv92Ty78/zli3gP377opLWNB1VMfFd0vXA9enTPkmPlPueHwTeDEuBg+W+l5WUf2bzi39e849/ZvOLf16T2A7od8p+m9MmOlFMyNpLfiZxYnV6bLw2eyRlgG6SCfDFvJaIuBm4uYhaSkrS1ojYONf3tZnzz2x+8c9r/vHPbH7xz6u6FbNQ1BbgTEnrJTWTTGS/c0ybO4G3pY+vAO6JZFLEncBVklokrQfOBO4rTelmZmZm1WvKnqx0jtUNwN0kSzh8IiK2SXovsDUi7gQ+DnwqndjeQxLESNvdQTJJPgv8VqU/WWhmZmY2FxTlnnVYxSRdnw5V2jzhn9n84p/X/OOf2fzin1d1q+uQZWZmZlYu3rzPzMzMrAzqNmRJukTSI5J2SLqx0vXYySStkfQNSQ9J2ibpd9PjiyV9TdJj6Z9e8KyKSGqU9ANJX0yfr5e0Of09+2z64RmrEpIWSvqcpIclbZf0Mv+OVTdJv5f+nfhjSf9HUqt/z6pXXYasgq2CLgU2AFenWwBZ9cgCfxARG4CXAr+V/oxuBL4eEWcCX0+fW/X4XZKlafLeD3wgIs4ADpNswWXV4x+Ar0TE84FzSX52/h2rUpJWAb8DbIyIF5B8GC2/lZ1/z6pQXYYsCrYKiohhIL9VkFWJiHg6Iu5PH/eS/OW/iuTndGva7FbgjZWp0MaStBr4eeBj6XMBryHZagv886oqkrqBV5J8OpyIGI6II/h3rNplgLZ0Tcp24Gn8e1a16jVkjbdVUMW3+7HxSVoHvBjYDCyPiKfTU88AyytUlj3XB4E/AkbT50uAIxGR313bv2fVZT1wAPhkOsT7MUkd+HesakXEXuDvgF0k4eoo8H38e1a16jVk2TwhaQHweeBdEXGs8Fy64K0/HlsFJL0B2B8R3690LVa0DHA+8E8R8WKgnzFDg/4dqy7p/LjLSQLySqADuKSiRdmk6jVkFbXdj1WWpCaSgPWZiPi39PA+Saem508F9leqPjvJy4HLJD1BMvz+GpL5PgvTYQ3w71m12QPsiYjN6fPPkYQu/45Vr9cBj0fEgYgYAf6N5HfPv2dVql5DVjFbBVkFpfN5Pg5sj4i/LzhVuIXT24D/f65rs+eKiD+JiNURsY7k9+meiHgL8A2SrbbAP6+qEhHPALsl/VR66LUku3P4d6x67QJeKqk9/Tsy/zPz71mVqtvFSCX9HMkckvxWQX9Z4ZKsgKSLgG8DD/LsHJ8/JZmXdQewFngSeFNE9FSkSBuXpFcDfxgRb5B0OknP1mLgB8CvRMRQJeuzZ0k6j+SDCs3ATuDtJP/z7d+xKiXpz4E3k3wC+wfAO0jmYPn3rArVbcgyMzMzK6d6HS40MzMzKyuHLDMzM7MycMgyMzMzKwOHLDMzM7MycMgyMzMzKwOHLDObM5L+X0k/I+mNkv5kgjbvkbRX0g8l/VjSZXNd53RJulbShytdh5lVF4csM5tLm4B7gVcB35qk3Qci4jzgSuATkor6u6pg1esZk9Q422uYmYFDlpnNAUl/K+lHwAXA90gWUPwnSe+e7HURsZ1k0cWlkn5B0uZ0M+P/lLQ8vfZ7JH1K0neBT0laJ+nbku5Pv346bdcg6R8lPSzpa5LuknRFeu4JSe+XdD9wpaRfl7RF0gOSPi+pPW13i6R/lrRV0qPpno15KyV9RdJjkv4mbd+YvubHkh6U9HslfWPNrKrN+v/6zMymEhH/j6Q7gLcCvw/8V0S8fKrXSdpEsuL/AeA7wEsjIiS9A/gj4A/SphuAiyLieBqIfjYiBiWdCfwfYCPwS8C6tO0pwHbgEwW3OxQR56f3XRIRH00f/wVwHfChtN064ELgecA3JJ2RHj8PeDEwBDwi6UPpfVZFxAvSay0s8i0zsxrgkGVmc+V84AHg+SQBZzK/J+lXgF7gzWmwWg18Nt20uBl4vKD9nRFxPH3cBHw43TImB5yVHr8I+NeIGAWekfSNMff8bMHjF6ThaiGwALi74Nwd6TUek7Qz/X4Avh4RRwEkPQScBmwDTk8D15eAr07xfZtZDXHIMrOySsPOLcBq4CDQnhzWD4GXFYSjQh+IiL8bc+xDwN9HxJ3p/ojvKTjXX/D494B9wLkkUyIGiyy18Bq3AG+MiAckXQu8uuDc2L3I8s8L94rLAZmIOCzpXOBi4DeANwG/VmQ9ZjbPeU6WmZVVRPwwncT+KMlQ3T3AxRFx3gQBayLdwN708dumaPd02tv0qySbwAN8F/jldG7Wck4OTmN1Ak9LagLeMubclek1ngecDjwy0UUkLQUaIuLzwP8i6c0zszrhniwzKztJy4DDETEq6fkR8dAMLvMe4F8lHSYJausnaPePwOclvRX4Cs/2UH0eeC3wELAbuB84OsE1/jewmWQu2GaS0JW3C7gP6AJ+I537NVHNq4BPFnw6ctxlK8ysNilibM+3mVltkrQgIvokLSEJSi+PiGem8fpbgC9GxOfKVaOZ1Q73ZJlZPfli+gm/ZuB90wlYZmbT5Z4sMzMzszLwxHczMzOzMnDIMjMzMysDhywzMzOzMnDIMjMzMysDhywzMzOzMnDIMjMzMyuD/wtsKD6W1f8lSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize = (10,6)) \n",
    "sns.distplot(sepdata_v1[['title','text']].groupby('title').agg('count')['text'].values, \n",
    "            ax=axes, axlabel = '# Paragraphs').set_title('Paragraphs per Article (title)')\n",
    "# majority of our paragarphsgenerally "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Begin cleaning text of paragraphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text cleaner \n",
    "# Drawn heavily with reference from here \n",
    "# https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #for regex search purposes          \n",
    "from nltk.corpus import stopwords #stopwords that are provided to us via nltk \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of contractions that we will map to \n",
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text):\n",
    "    # Step 0: Convert to string in case a float or int is found.\n",
    "    newString = str(text)\n",
    "    # Step 1: Lower case the text \n",
    "    newString = newString.lower()\n",
    "    # Step 2: Get rid of commas\n",
    "    #newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    # Step 3: Get rid of quotations \n",
    "    newString = re.sub('\"','', newString)\n",
    "    # Step 4: get rid of contractions with our contraction mapping \n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])  \n",
    "    # Step 5: get rid of the \\n stuff \n",
    "    newString = re.sub(r\"'s\\n\",\"\",newString)\n",
    "    # Step 6: anything that is a number, get rid of it \n",
    "    newString = re.sub(\"\\d\", \" \", newString) \n",
    "    # Step 7: separating punctuations so they are their own tokens\n",
    "    newString = re.sub(r'([,.!;:])', r' \\1', newString)\n",
    "\n",
    "    return newString.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the same step for the headlines, but with some variation on cleaning \n",
    "\n",
    "def headline_cleaner(text):\n",
    "    # Step 0: Convert to string in case a float or int is found.\n",
    "    newString = str(text)\n",
    "    # Step 1: remove quotations \n",
    "    newString = re.sub('\"','', newString)\n",
    "    # Step 2: look up contractions \n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")]) \n",
    "    # Step 3: Get rid of the \\n stuff \n",
    "    newString = re.sub(r\"'s\\n\",\"\",newString)\n",
    "    # Step 4: Get rid of numbers or anything not in the alphabet\n",
    "    newString = re.sub(\"\\d\", \"\", newString)\n",
    "    # Step 5: Lower case \n",
    "    newString = newString.lower()\n",
    "    # Step 7: separating punctuations so they are their own tokens\n",
    "    newString = re.sub(r'([,.!;:])', r' \\1', newString)\n",
    "    tokens=newString.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1387289, 5)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.DataFrame()\n",
    "\n",
    "clean_data['text'] = sepdata_v1['text'].apply(text_cleaner)\n",
    "\n",
    "clean_data['headline'] = sepdata_v1['headline'].apply(headline_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1387289, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sell', 'yourself', 'first', '.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['headline'][0]\n",
    "#Preprocessing has made the text difficult for humans to understand (let alone summarize). Maybe that's the language of the machine. Good luck buddy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('data/glove/glove.6B/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doc2seq(texts, MAX_NB_WORDS, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM):\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    index_word = tokenizer.index_word\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding = 'post')\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return data, embedding_matrix, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 489940 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 10000\n",
    "MAX_TEXT_LENGTH = 100\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.text\n",
    "\n",
    "x_data, encoder_emb, x_word_index, x_index_word = doc2seq(data, MAX_NB_WORDS, MAX_TEXT_LENGTH, EMBEDDING_DIM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129191 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 10000\n",
    "MAX_HEADLINE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.headline\n",
    "\n",
    "y_data, decoder_emb, y_word_index, y_index_word = doc2seq(data, MAX_NB_WORDS, MAX_HEADLINE_LENGTH, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test_temp, y_train, y_test_temp = train_test_split(x_data, y_data, \n",
    "                                                            test_size=0.3, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, x_test, y_dev, y_test = train_test_split(x_test_temp, y_test_temp, \n",
    "                                                            test_size=0.33, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129192, 300)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, Bidirectional, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from attention_keras.layers.attention import AttentionLayer\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "K.clear_session() \n",
    "hidden_units = 250 #this is 600 in the paper. To be changed later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_embedding_layer = Embedding(len(x_word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[encoder_emb],\n",
    "                            input_length=MAX_TEXT_LENGTH,\n",
    "                            trainable=False,\n",
    "                            name='EncoderEmbeddingLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_embedding_layer = Embedding(len(y_word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[decoder_emb],\n",
    "                            input_length=MAX_HEADLINE_LENGTH,\n",
    "                            trainable=False,\n",
    "                            name='DecoderEmbeddingLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder \n",
    "\n",
    "# Encoder input \n",
    "# 2D (sequence_length, None), where sequence length is the MAX_LEN unified by padding in preprocessing\n",
    "encoder_inputs = Input(shape=(MAX_TEXT_LENGTH,), name=\"EncoderInput\") \n",
    "enc_emb = enc_embedding_layer(encoder_inputs) \n",
    "\n",
    "\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM1') \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM2') \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM3') \n",
    "encoder_output3, state_h3, state_c3= encoder_lstm3(encoder_output2) \n",
    "\n",
    "#LSTM 4 \n",
    "encoder_lstm4=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM4') \n",
    "encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder \n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name = 'DecoderInput') \n",
    "#dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_embedding_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name='DecLSTM1') \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(len(y_word_index)+1, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "EncoderInput (InputLayer)       [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncoderEmbeddingLayer (Embeddin (None, 100, 300)     146982300   EncoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM1 (LSTM)                 [(None, 100, 250), ( 551000      EncoderEmbeddingLayer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM2 (LSTM)                 [(None, 100, 250), ( 501000      EncLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM3 (LSTM)                 [(None, 100, 250), ( 501000      EncLSTM2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderEmbeddingLayer (Embeddin (None, None, 300)    38757600    DecoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM4 (LSTM)                 [(None, 100, 250), ( 501000      EncLSTM3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecLSTM1 (LSTM)                 [(None, None, 250),  551000      DecoderEmbeddingLayer[0][0]      \n",
      "                                                                 EncLSTM4[0][1]                   \n",
      "                                                                 EncLSTM4[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 250),  125250      EncLSTM4[0][0]                   \n",
      "                                                                 DecLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 500)    0           DecLSTM1[0][0]                   \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 129192) 64725192    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 253,195,342\n",
      "Trainable params: 67,455,442\n",
      "Non-trainable params: 185,739,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "#model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 971102 samples, validate on 278845 samples\n",
      "Epoch 1/4\n",
      "971102/971102 [==============================] - 8042s 8ms/sample - loss: 1.2587 - val_loss: 1.0925\n",
      "Epoch 2/4\n",
      "971102/971102 [==============================] - 8062s 8ms/sample - loss: 1.0431 - val_loss: 1.0209\n",
      "Epoch 3/4\n",
      "971102/971102 [==============================] - 8084s 8ms/sample - loss: 0.9833 - val_loss: 0.9914\n",
      "Epoch 4/4\n",
      "971102/971102 [==============================] - 8086s 8ms/sample - loss: 0.9487 - val_loss: 0.9759\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_train,np.hstack((np.zeros((y_train.shape[0],1)), y_train[:, :-1]))], \n",
    "                  y_train,\n",
    "                  epochs=4,\n",
    "                  batch_size=160, \n",
    "                  validation_data=([x_dev,np.hstack((np.zeros((y_dev.shape[0],1)), y_dev[:, :-1]))], y_dev)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_hidden_state_input = Input(shape=(MAX_TEXT_LENGTH,hidden_units))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_embedding_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = y_word_index.get('START', 0)\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        #print(output_tokens)\n",
    "        #print(h)\n",
    "        #print(c)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        #print(sampled_token_index)\n",
    "        sampled_token = y_index_word.get(sampled_token_index, '.')\n",
    "\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (MAX_HEADLINE_LENGTH-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_beam(input_seq, beam=3):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    top_sentences = {}\n",
    "    \n",
    "    def top_tokens(last_token, out, h, c):\n",
    "        output_tokens, h_new, c_new = decoder_model.predict([[last_token]] + [out, h, c])\n",
    "        top_token_indexes = np.argsort(output_tokens[0, -1, :])[-beam:]\n",
    "        top_probabilities = output_tokens[0,-1, top_token_indexes]\n",
    "        return top_token_indexes, top_probabilities, h_new, c_new\n",
    "        \n",
    "    #first set of tokens when feeding encoder states and 0 as the first token to the decoder.\n",
    "    first_tokens, first_probabilities, h, c = top_tokens(0, e_out, e_h, e_c)\n",
    "    for first_token, first_probability in zip(first_tokens, first_probabilities):\n",
    "        #initialize top sentences, their corresponding probabilities and states\n",
    "        top_sentences[y_index_word.get(first_token, '')] = (first_probability, e_h, e_c)\n",
    "\n",
    "    #print('Initialized sentences')\n",
    "    #print(top_sentences.keys())\n",
    "    \n",
    "    #loop to iterate over next tokens\n",
    "    len = 1\n",
    "    while len < MAX_HEADLINE_LENGTH:\n",
    "        candidate_sentences = {}\n",
    "        for sentence, (probability, h, c) in top_sentences.items():\n",
    "            last_word = sentence.split()[-1] #pick the last word in the sentence as next word\n",
    "            if(last_word != '.'):\n",
    "                token = y_word_index.get(last_word, 0) \n",
    "                next_tokens, next_probabilities, h_next, c_next = top_tokens(token, e_out, h, c)\n",
    "                for next_token, next_probability in zip(next_tokens, next_probabilities):\n",
    "                    new_sentence = sentence.strip() + ' ' + y_index_word.get(next_token, '')\n",
    "                    candidate_sentences[new_sentence.strip()] = (probability * next_probability, h_next, c_next)\n",
    "\n",
    "        #print('Candidate sentences')\n",
    "        #print(candidate_sentences.keys())\n",
    "        \n",
    "        #remove low probability candidates\n",
    "        low_probability_candidates = sorted(candidate_sentences, key=lambda k: candidate_sentences.get(k)[0])[:-beam]\n",
    "        for low_probability_candidate in low_probability_candidates:\n",
    "            candidate_sentences.pop(low_probability_candidate)\n",
    "        \n",
    "        #Now all candidates left have highest probabilities.\n",
    "        top_sentences = candidate_sentences\n",
    "        len = len + 1\n",
    "        #print('Sentences at the bottom of the loop')\n",
    "        #print(top_sentences.keys())\n",
    "        \n",
    "\n",
    "    return top_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0 ):\n",
    "            newString=newString+y_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+x_index_word[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = decode_sequence_beam(x_test[2000].reshape(1,-1), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(sen, prob) for sen, (prob, _, _) in res.items()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pull the boat off the top of the boat with a fork and hold the boat up to the top of the boat and place it on the boat .',\n",
       "  5.5992517e-19),\n",
       " ('pull the boat off the top of the boat with a fork and hold the boat up to the top of the boat and place the boat on the boat',\n",
       "  2.8316683e-19),\n",
       " ('pull the boat off the top of the boat with a fork and hold the boat up to the top of the boat and place the boat on the ground',\n",
       "  2.31176e-19),\n",
       " ('pull the boat off the top of the boat with a fork and hold the boat up to the top of the boat and place the boat in the boat',\n",
       "  2.2558562e-19),\n",
       " ('pull the boat off the top of the boat with a fork and hold the boat up to the top of the boat and place it in the boat .',\n",
       "  1.7532938e-19)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l, key = lambda x:-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pour the mixture into the pan . . . . . . . . . . . . . . . . . . . . . . .\n",
      "when the pastry is cooked and the sugar is nice and golden , remove carefully from the oven and cool in dish . \n",
      "the filling will set as it cools . \n",
      "______________________________________\n",
      " click on the button . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "look for the contact info section . \n",
      "the previous step should land you on the about page of your account . you will not miss it as it will have the word displayed at the top , but just below your profile picture . scroll down slowly through the sections until you see info . \n",
      "______________________________________\n",
      " research your market . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "your textbooks . \n",
      "the year . however , prices there tend to be low . you can try your books on your own . you may get more money going this route .the website will give you an idea of how much a specific used book tends to sell for . you can then try to sell the book online for that price , or try to it to another student for a similar price . you can also go to local used . if you have a book that is in quality condition , you may be able to it there . \n",
      "______________________________________\n",
      " search for jobs . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "search the internet to find industry jobs . \n",
      "spending a good amount of time searching various job boards is way to find an airline business with potential job opportunities . try searching for a job on an employment hub website . \n",
      "______________________________________\n",
      " add a few drops of the colors . . . . . . . . . . . . . . . . . . . . . .\n",
      "consider using the rule of three . \n",
      "together an outfit , using the of can help you to create a quick but elegant in no time . when using the rule of three , pick out three colors : two that will be your base colors likely your shirt and pants or and one that will be your accent color . your base colors could be colors that go together well , such as navy blue shirt and skirt . your accent color should be a brighter color that makes the rest of your outfit pop , such as a red thin belt or a scarf . \n",
      "______________________________________\n",
      " get a referral . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "use online prenatal yoga videos . \n",
      ", so you can try a few at a time . always check that the yoga instructor is certified and specializes in prenatal yoga . this will ensure she has the necessary experience to teach prenatal yoga safely . often , online yoga videos will use a pregnant women to demonstrate the to show you the safe way to do them . if you feel at all uncomfortable with doing any of the , slowly ease out of them and take a deep breath . never do any if you feel any sharp pains or overwhelming discomfort in them . \n",
      "______________________________________\n",
      " read about the reading . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "read literature . \n",
      "obscure books and music . if you do not currently read for pleasure (and , today , many people do , try to get through a few good , obscure books per year . you will develop a rewarding new habit and impress people with your tastes . to learn about obscure books , try browsing a literature discussion site (like , for instance , . at these types of sites , you will usually find reviews , recommendations , and , often , a new releases section (or that can point you to the latest and greatest reads . \n",
      "______________________________________\n",
      " use a satin pillowcase . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "sleep on satin . \n",
      "if you have curly , , or otherwise hair , you may be waking up with rough hair because of your bedding . cotton the moisture from your hair , while silk and satin help maintain the moisture in your hair .if you do not have silk or satin pillow cases , wearing a silk scarf , or satin cap can help protect your hair as you sleep . \n",
      "______________________________________\n",
      " fill the pot with water . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "add some activated charcoal , or any other filter media . \n",
      "about inches ( . centimeters) should be enough .the charcoal will filter out bacteria and toxins . \n",
      "______________________________________\n",
      " preheat the grill . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "slowly add more pieces of charcoal to the fire you have made . \n",
      "have a large pile in the center of the grill . the inner , for now , will be the only hot ones . you should see smoke coming up from the center of your pile . depending on the size of your grill , you will need a different amount of : small , personal can usually get by with - pieces . medium size , like the most common grill , should have roughly . large may need anywhere from - bags of charcoal , and will take a long time to get hot using this method . \n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 110):\n",
    "    print(decode_sequence(x_test[i].reshape(1,-1)))\n",
    "    print(seq2summary(y_test[i]))\n",
    "    print(seq2text(x_test[i]))\n",
    "    print('______________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_fd_111319_250units_punct.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_fd_111319_250units_punct.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_full_data_111019.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "json_file = open('model_full_data_111019.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model_from_disk = model_from_json(loaded_model_json)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
