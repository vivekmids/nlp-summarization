{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Packages\n",
    "##### \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Read in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepdatafull = pd.read_csv('wikihowSep.csv')\n",
    "sepdata = pd.read_csv('wikihowSep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepdata = sepdatafull[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1585695, 5)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine for NAs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>sectionLabel</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nSell yourself first.</td>\n",
       "      <td>Before doing anything else, stop and sum up y...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you want to be well-read, then, in the wor...</td>\n",
       "      <td>\\nRead the classics before 1600.</td>\n",
       "      <td>Reading the classics is the very first thing ...</td>\n",
       "      <td>Reading the Classics</td>\n",
       "      <td>How to Be Well Read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nJoin online artist communities.</td>\n",
       "      <td>Depending on what scale you intend to sell yo...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nMake yourself public.</td>\n",
       "      <td>Get yourself out there as best as you can by ...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nBlog about your artwork.</td>\n",
       "      <td>Given the hundreds of free blogging websites,...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0   So you're a new or aspiring artist and your c...   \n",
       "1   If you want to be well-read, then, in the wor...   \n",
       "2   So you're a new or aspiring artist and your c...   \n",
       "3   So you're a new or aspiring artist and your c...   \n",
       "4   So you're a new or aspiring artist and your c...   \n",
       "\n",
       "                            headline  \\\n",
       "0             \\nSell yourself first.   \n",
       "1   \\nRead the classics before 1600.   \n",
       "2  \\nJoin online artist communities.   \n",
       "3            \\nMake yourself public.   \n",
       "4         \\nBlog about your artwork.   \n",
       "\n",
       "                                                text          sectionLabel  \\\n",
       "0   Before doing anything else, stop and sum up y...                 Steps   \n",
       "1   Reading the classics is the very first thing ...  Reading the Classics   \n",
       "2   Depending on what scale you intend to sell yo...                 Steps   \n",
       "3   Get yourself out there as best as you can by ...                 Steps   \n",
       "4   Given the hundreds of free blogging websites,...                 Steps   \n",
       "\n",
       "                         title  \n",
       "0  How to Sell Fine Art Online  \n",
       "1          How to Be Well Read  \n",
       "2  How to Sell Fine Art Online  \n",
       "3  How to Sell Fine Art Online  \n",
       "4  How to Sell Fine Art Online  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata.head(5)\n",
    "# Notice how we have 4 columns: \n",
    "# 'overview': the full summary based on the wikihow article \n",
    "# 'headline': the \"summary\" for the paragraph in 'text' column \n",
    "# 'text': the actual text of the paragraph \n",
    "# 'sectionLabel': section label of the paragraph \n",
    "# 'title': the title of which the paragraph belongs to. \n",
    "\n",
    "# wikihowSep (downloaded here: https://github.com/mahnazkoupaee/WikiHow-Dataset) is the same file as \n",
    "# wikihowAll, except separated by paragraph. \n",
    "\n",
    "# Given the length of the documents under wikihowAll, we opted for a shorter summary model to work with where we can \n",
    "# take paragraphs, and attempt to generate the headline for the paragraph instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1387289"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are there any NA's that we should drop? \n",
    "# Note here that we are only concerned about the 3 columns: headline, text, and title \n",
    "\n",
    "sepdata_v1 = sepdata.dropna(subset=['headline','text','title'], axis=0).reset_index(drop=True) \n",
    "len(sepdata_v1) #yes, we see some NA rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>sectionLabel</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nSell yourself first.</td>\n",
       "      <td>Before doing anything else, stop and sum up y...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you want to be well-read, then, in the wor...</td>\n",
       "      <td>\\nRead the classics before 1600.</td>\n",
       "      <td>Reading the classics is the very first thing ...</td>\n",
       "      <td>Reading the Classics</td>\n",
       "      <td>How to Be Well Read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nJoin online artist communities.</td>\n",
       "      <td>Depending on what scale you intend to sell yo...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nMake yourself public.</td>\n",
       "      <td>Get yourself out there as best as you can by ...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So you're a new or aspiring artist and your c...</td>\n",
       "      <td>\\nBlog about your artwork.</td>\n",
       "      <td>Given the hundreds of free blogging websites,...</td>\n",
       "      <td>Steps</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0   So you're a new or aspiring artist and your c...   \n",
       "1   If you want to be well-read, then, in the wor...   \n",
       "2   So you're a new or aspiring artist and your c...   \n",
       "3   So you're a new or aspiring artist and your c...   \n",
       "4   So you're a new or aspiring artist and your c...   \n",
       "\n",
       "                            headline  \\\n",
       "0             \\nSell yourself first.   \n",
       "1   \\nRead the classics before 1600.   \n",
       "2  \\nJoin online artist communities.   \n",
       "3            \\nMake yourself public.   \n",
       "4         \\nBlog about your artwork.   \n",
       "\n",
       "                                                text          sectionLabel  \\\n",
       "0   Before doing anything else, stop and sum up y...                 Steps   \n",
       "1   Reading the classics is the very first thing ...  Reading the Classics   \n",
       "2   Depending on what scale you intend to sell yo...                 Steps   \n",
       "3   Get yourself out there as best as you can by ...                 Steps   \n",
       "4   Given the hundreds of free blogging websites,...                 Steps   \n",
       "\n",
       "                         title  \n",
       "0  How to Sell Fine Art Online  \n",
       "1          How to Be Well Read  \n",
       "2  How to Sell Fine Art Online  \n",
       "3  How to Sell Fine Art Online  \n",
       "4  How to Sell Fine Art Online  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211825"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Therefore, how many true titles do we have? \n",
    "len(sepdata_v1['title'].unique()) #only 211,825 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5492222353357725"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It doesn't quite matter for us since we are trying to predict headline and not the title, \n",
    "# but out of curiosity, how many paragraphs on average belong to each title? \n",
    "np.nanmean(sepdata_v1[['title','text']].groupby('title').agg('count')['text'].values) \n",
    "# Roughly 6-7 paragraphs per title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Paragraphs per Article (title)')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize = (10,6)) \n",
    "sns.distplot(sepdata_v1[['title','text']].groupby('title').agg('count')['text'].values, \n",
    "            ax=axes, axlabel = '# Paragraphs').set_title('Paragraphs per Article (title)')\n",
    "# majority of our paragarphsgenerally "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Begin cleaning text of paragraphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text cleaner \n",
    "# Drawn heavily with reference from here \n",
    "# https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #for regex search purposes          \n",
    "from nltk.corpus import stopwords #stopwords that are provided to us via nltk \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of contractions that we will map to \n",
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text):\n",
    "    # Step 0: Convert to string in case a float or int is found.\n",
    "    newString = str(text)\n",
    "    # Step 1: Lower case the text \n",
    "    newString = newString.lower()\n",
    "    # Step 2: Get rid of commas\n",
    "    #newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    # Step 3: Get rid of quotations \n",
    "    newString = re.sub('\"','', newString)\n",
    "    # Step 4: get rid of contractions with our contraction mapping \n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])  \n",
    "    # Step 5: get rid of the \\n stuff \n",
    "    newString = re.sub(r\"'s\\n\",\"\",newString)\n",
    "    # Step 6: anything that is a number, get rid of it \n",
    "    newString = re.sub(\"\\d\", \" \", newString) \n",
    "    # Step 7: Tokenize everything first and keep the words that are not stop words \n",
    "    # Also keep only words that are greater than or equal to 3 characters long \n",
    "    #tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    '''    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3: #removing short words\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()'''\n",
    "\n",
    "    return newString.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the same step for the headlines, but with some variation on cleaning \n",
    "\n",
    "def headline_cleaner(text):\n",
    "    # Step 0: Convert to string in case a float or int is found.\n",
    "    newString = str(text)\n",
    "    # Step 1: remove quotations \n",
    "    newString = re.sub('\"','', newString)\n",
    "    # Step 2: look up contractions \n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")]) \n",
    "    # Step 3: Get rid of the \\n stuff \n",
    "    newString = re.sub(r\"'s\\n\",\"\",newString)\n",
    "    # Step 4: Get rid of numbers or anything not in the alphabet\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    # Step 5: Lower case \n",
    "    newString = newString.lower()\n",
    "    tokens=newString.split()\n",
    "    # Step 6: keep words that are greater than 1 character long \n",
    "    '''remaining=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            remaining.append(i) \n",
    "    return (\" \".join(remaining)).strip()'''\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1387289, 5)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepdata_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.DataFrame()\n",
    "\n",
    "clean_data['text'] = sepdata_v1['text'].apply(text_cleaner)\n",
    "\n",
    "clean_data['headline'] = sepdata_v1['headline'].apply(headline_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1387289, 2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sell', 'yourself', 'first']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['headline'][0]\n",
    "#Preprocessing has made the text difficult for humans to understand (let alone summarize). Maybe that's the language of the machine. Good luck buddy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('data/glove/glove.6B/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doc2seq(texts, MAX_NB_WORDS, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM):\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    index_word = tokenizer.index_word\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding = 'post')\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return data, embedding_matrix, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 973035 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 30000\n",
    "MAX_TEXT_LENGTH = 100\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.text\n",
    "\n",
    "x_data, encoder_emb, x_word_index, x_index_word = doc2seq(data, MAX_NB_WORDS, MAX_TEXT_LENGTH, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68630 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 30000\n",
    "MAX_HEADLINE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.headline\n",
    "\n",
    "y_data, decoder_emb, y_word_index, y_index_word = doc2seq(data, MAX_NB_WORDS, MAX_HEADLINE_LENGTH, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test_temp, y_train, y_test_temp = train_test_split(x_data, y_data, \n",
    "                                                            test_size=0.3, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, x_test, y_dev, y_test = train_test_split(x_test_temp, y_test_temp, \n",
    "                                                            test_size=0.33, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278845, 100)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278845, 30)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68631, 300)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, Bidirectional, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from attention_keras.layers.attention import AttentionLayer\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "K.clear_session() \n",
    "hidden_units = 400 #this is 600 in the paper. To be changed later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68631"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_embedding_layer = Embedding(len(x_word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[encoder_emb],\n",
    "                            input_length=MAX_TEXT_LENGTH,\n",
    "                            trainable=False,\n",
    "                            name='EncoderEmbeddingLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_embedding_layer = Embedding(len(y_word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[decoder_emb],\n",
    "                            input_length=MAX_HEADLINE_LENGTH,\n",
    "                            trainable=False,\n",
    "                            name='DecoderEmbeddingLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder \n",
    "\n",
    "# Encoder input \n",
    "# 2D (sequence_length, None), where sequence length is the MAX_LEN unified by padding in preprocessing\n",
    "encoder_inputs = Input(shape=(MAX_TEXT_LENGTH,), name=\"EncoderInput\") \n",
    "enc_emb = enc_embedding_layer(encoder_inputs) \n",
    "\n",
    "\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM1') \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM2') \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM3') \n",
    "encoder_output3, state_h3, state_c3= encoder_lstm3(encoder_output2) \n",
    "\n",
    "#LSTM 4 \n",
    "encoder_lstm4=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM4') \n",
    "encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder \n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name = 'DecoderInput') \n",
    "#dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_embedding_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name='DecLSTM1') \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(len(y_word_index)+1, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "EncoderInput (InputLayer)       [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncoderEmbeddingLayer (Embeddin (None, 100, 300)     291910800   EncoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM1 (LSTM)                 [(None, 100, 400), ( 1121600     EncoderEmbeddingLayer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM2 (LSTM)                 [(None, 100, 400), ( 1281600     EncLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM3 (LSTM)                 [(None, 100, 400), ( 1281600     EncLSTM2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderEmbeddingLayer (Embeddin (None, None, 300)    20589300    DecoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncLSTM4 (LSTM)                 [(None, 100, 400), ( 1281600     EncLSTM3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecLSTM1 (LSTM)                 [(None, None, 400),  1121600     DecoderEmbeddingLayer[0][0]      \n",
      "                                                                 EncLSTM4[0][1]                   \n",
      "                                                                 EncLSTM4[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 400),  320400      EncLSTM4[0][0]                   \n",
      "                                                                 DecLSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 800)    0           DecLSTM1[0][0]                   \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 68631)  54973431    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 373,881,931\n",
      "Trainable params: 61,381,831\n",
      "Non-trainable params: 312,500,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "#model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 971102 samples, validate on 278845 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_train,np.hstack((np.zeros((y_train.shape[0],1)), y_train[:, :-1]))], \n",
    "                  y_train,\n",
    "                  epochs=10,\n",
    "                  batch_size=242, \n",
    "                  validation_data=([x_dev,np.hstack((np.zeros((y_dev.shape[0],1)), y_dev[:, :-1]))], y_dev)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-1e2df9b0b8f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_hidden_state_input = Input(shape=(MAX_TEXT_LENGTH,hidden_units))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_embedding_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = y_word_index.get('START', 0)\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        print(output_tokens)\n",
    "        #print(h)\n",
    "        #print(c)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        #print(sampled_token_index)\n",
    "        sampled_token = y_index_word.get(sampled_token_index, '.')\n",
    "\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (MAX_HEADLINE_LENGTH-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0 ):\n",
    "            newString=newString+y_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+x_index_word[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " determine if you qualify for a spouse UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "qualify for medicaid \n",
      "for an individual and for a couple if one spouse goes into a nursing care for the purposes of medicaid the individual going into care can only have in non exempt assets and the spouse remaining at home can keep half of the overall assets anything over half the assets plus must be reduced in order to qualify for medicaid this is called the spousal rule medicaid also has monthly income limits that are set on a state by state basis in new york this amount is a month for an individual living alone and a month for a couple \n",
      "______________________________________\n",
      " click on the layer icon UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "play around with the sliders \n",
      "every image will differ normally photoshop will figure out the right amount of shadow and highlighting to apply from the beginning on its own but you can change it like in shadows amount can be set between tone between and radius between \n",
      "______________________________________\n",
      " check the eggs UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "look at the color of the down \n",
      "look at the down coloration of each chick you should be able to make a judgment without even handling the chick if the mother is a barred hen of some type she will produce male chicks that are black or dark brown with a white spot on the head and female chicks with solid black or dark brown down if the mother is a silver or breed she will produce male chicks that are either silver cream white or smoky in color the female chicks will be gold buff or red \n",
      "______________________________________\n",
      " get a bicycle UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "choose a sharp corner with a short straight before it \n",
      "something within your comfort level for speed \n",
      "______________________________________\n",
      " play with the game UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "don t leave the table when it is your turn to play \n",
      "in a casino this can be seen as an attempt to cheat in a home game it can be seen as a power play to make the other players wait on you either way unless you really have to go to the bathroom it is a breach of poker etiquette \n",
      "______________________________________\n",
      " keep your loved one updated UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "find a way to keep in touch \n",
      "keeping family and friends updated on your loved one s fight is essential although it might be best to tell them about the diagnosis in person updating them individually can be tedious consider setting up an email blast or a webpage that your family and friends can check to stay in touch there are also pre made webpages you can personalize see tips section for examples to keep everyone updated fundraise and or ask for help \n",
      "______________________________________\n",
      " take a course UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "take mit s free online game building course \n",
      "of course many of these types of games are already freely available online mit on the other hand hosts a free nine week online course on building educational games enroll in the course and spend hours a week completing coursework and projects that will teach you to create in depth effective learning games visit the website to register and begin the course called design and development of games for learning for free as with many courses you have the option to pay for a verified certificate upon completion while taking the class is free the cost for this certification is \n",
      "______________________________________\n",
      " do kegel exercises UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "do pelvic exercises \n",
      "of urine as you pee the muscles you squeeze to accomplish this are the muscles you will be working curing kegels start out by squeezing your pelvic floor muscles for two to five seconds then release for seconds do this ten times to complete one set do one set three to four times daily increase the time you squeeze and hold your muscles to second intervals continue to do three to four sets daily kegels can be done just about anywhere and at any time do them while driving sitting at your desk watching tv or whenever works for you \n",
      "______________________________________\n",
      " use confetti or paper to make the icing UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "hole punch lots of junk mail into small pieces \n",
      "both catalogs and envelopes can be used use as confetti tuck the confetti pieces inside balloons before blowing them up for a fun effect \n",
      "______________________________________\n",
      " click on the button labeled button UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "provide the value of the variable to assign value labels click the cell in the values column for the variable in question \n",
      "a small button with three dots on it appears click that button the value labels dialogue box appears \n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 20):\n",
    "    print(decode_sequence(x_test[i].reshape(1,-1)))\n",
    "    print(seq2summary(y_test[i]))\n",
    "    print(seq2text(x_test[i]))\n",
    "    print('______________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'purchase a leave in conditioner '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2summary(y_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' wear a sparkly necklace UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(x_test[20].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hang ocean themed jewelry in your room '"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2summary(y_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buy ocean mermaid jewelry for example a necklace with a seashell on it '"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2text(x_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_fd_111019_400units_punct.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_fd_111019_400units_punct.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_full_data_111019.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: AttentionLayer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8d8183b4262d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_from_disk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    190\u001b[0m             custom_objects=dict(\n\u001b[1;32m    191\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    193\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m       \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m     \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m       \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m       \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 181\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: AttentionLayer"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "json_file = open('model_full_data_111019.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model_from_disk = model_from_json(loaded_model_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
